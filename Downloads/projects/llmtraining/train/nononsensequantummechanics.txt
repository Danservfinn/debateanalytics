Transcribed from: nononsensequantummechanics.pdf
Method used: Tesseract OCR
==================================================

e - <

Jakob Schwichtenberg
No-Nonsense

Quantum
Mecnanics

A Student-Friendly Introduction

Second Edition e

FROM THE AUTHOR OF THE BESTSELLING TEXTBOOK
PHYSICS FROM SYMMETRY


WHEN THINGS GET TOUGH, THERE ARE TWO THINGS THAT MAKE
LIFE WORTH LIVING: MOZART, AND QUANTUM MECHANICS.

VICTOR WEISSKOPF

IT 1S OFTEN STATED THAT OF ALL THE THEORIES PROPOSED IN THIS
CENTURY, THE SILLIEST IS QUANTUM THEORY. IN FACT, SOME SAY
THAT THE ONLY THING THAT QUANTUM THEORY HAS GOING FOR IT
IS THAT IT 1S UNQUESTIONABLY CORRECT.

MICHIO KAKU

THE TRUTH ALWAYS TURNS OUT TO BE SIMPLER THAN YOU THOUGHT.

RICHARD FEYNMAN

JAKOB SCHWICHTENBERG

NO-NONSENSE
QUANTUM
MECHANICS

NO-NONSENSE BOOKS

no-nonsense
e e e e

books: *:° "es
First printing, September 2020

Copyright © 2020 Jakob Schwichtenberg
With illustrations by Corina Wieber

All rights reserved. No part of this publication may be reproduced, stored in, or introduced into
a retrieval system, or transmitted in any form or by any means (electronic, mechanical, photo-
copying, recording, or otherwise) without prior written permission.

UNIQUE ID: 05B568174.AF4CAA3587004553587D48385092COD28FABD618413FDEQ904C6F53F

Each copy of No-Nonsense Quantum Mechanics has a unique ID which helps to prevent illegal sharing.

BOOK EDITION: 2.7

Dedicated to my parents

Preface

Quantum mechanics is nearly a century old and hundreds of
books on the subject have already been written. Despite the
sheer volume of material on the subject, quantum mechanics
unfortunately remains a challenging subject to learn.

When I first learned quantum mechanics, I remember being
utterly lost. I struggled for months to understand even the
easiest concepts.

In some sense, this is entirely normal. For example, you may be
familiar with the famous quote usually attributed to Niels Bohr:
"If you are not completely confused by quantum mechanics,
you do not understand it." This sentiment is echoed by Roger
Penrose, who explained that his "general attitude" to quantum
mechanics is that "it makes absolutely no sense!"

It follows that learning quantum mechanics is necessarily diffi-
cult and confusing, right?

I no longer believe this to be true. This change of heart served
as my motivation to write this book.

To be clear: quantum mechanics is not an easy subject. It takes
some time to get used to. You need to learn a completely new
formalism. However, this new formalism is not as difficult as
most authors would lead you to believe; you don’t need to
spend months in a state of confusion. Also, rest reassured that

1 This is known as the "Curse of
Knowledge".

my goal is not to promote some crackpot alternative to quan-
tum mechanics in order to remove all "quantum paradoxes"

and "quantum mysteries". Instead, a large part of this book is
devoted to topics which are covered by most other textbooks.
However, my goal is to introduce them as gently as possible
and, in some sense, I wrote the book I wished had existed when
I started learning quantum mechanics.

So what exactly makes this book different?

> First, it wasn’t written by a professor. As a result, this book
is by no means an authoritative reference. Instead, this book
is written more like a casual conversation with a more expe-
rienced student who shares with you everything he wished
he had known earlier. I’m convinced that someone who has
recently learned the topic can explain it much better than
someone who learned it decades ago. Many textbooks are
hard to understand, not because the subject is difficult, but
because the author can’t remember what it’s like to be a be-
ginner’.

> Second, this book focuses solely on the fundamentals and
contains no fluff. Most other books on quantum mechanics
bury the essential concepts behind tedious calculations and
complicated formulas.

> Third, this book is unique in that it contains lots of idiosyn-
cratic hand-drawn illustrations. Usually, textbooks include
very few pictures since drawing them is either a lot of work
or expensive. However, drawing figures is only a lot of work
if you are a perfectionist. The images in this book are not as
pretty as the pictures in a typical textbook since I firmly be-
lieve that lots of non-perfect illustrations are much better than
a few perfect ones. The goal of this book, after all, is to help
you understand quantum mechanics and not to win prizes
for my pretty illustrations.

> Finally, my only goal was to write the most student-friendly
quantum mechanics book and not, for example, to build my

reputation. Too many books are unnecessarily complicated
because if a book is hard to understand, it makes the author
appear smarter.” To give a concrete example, nothing in this
book is assumed to be "obvious" or "easy to see". Moreover,
calculations are done step-by-step and are annotated to help
you understand faster.

With that said, the actual content and structure of the book is
also somewhat non-standard:

In the first part, we will talk about the essential features of
quantum mechanics and how we can describe them mathemat-
ically. We start with a "Bird’s Eye View" of quantum mechanics
and then gradually refine our understanding.

Afterwards, we will discuss concrete examples and applica-
tions. We will stick to the most fundamental examples that
show how quantum mechanics works in practice. In most more
advanced examples, we don’t learn anything new. Instead, the
same lessons are buried behind more complicated calculations.
I will, however, comment on several important advanced exam-
ples with which you should become familiar.

Next, we will talk about alternative formulations of quantum
mechanics.3 Most other textbooks focus solely on the wave
function formulation and ignore the alternatives. However, just
as it is worthwhile to learn both the Lagrangian and Hamilto-
nian formulations of classical mechanics, learning these alterna-
tive formulations can be extremely beneficial. This is especially
true when we try to understand what quantum mechanics really
means, which is the topic of the penultimate chapter.

In the final chapter, we will discuss where you can learn more
depending on what aspect of quantum mechanics interests you
the most.

So, without any further ado, let’s begin. I hope you enjoy read-
ing this book as much as I have enjoyed writing it.

?To quote C. Lanczos: "Many of
the scientific treatises of today

are formulated in a half-mystical
language, as though to impress
the reader with the uncomfortable
feeling that he is in the permanent
presence of a superman."

3 Again: Be reassured that I will
not talk about crackpot theories but
only well-established alternative
formulations like the path-integral
formulation.

10

Karlsruhe, June 2018 Jakob Schwichtenberg

PS: I update the book regularly based on reader feedback. So if
you find an error, I would appreciate a short email to
errors@jakobschwichtenberg.com.

Acknowledgments

Many thanks are due to all readers of earlier versions of this
book who suggested improvements, especially Florian Col-
batzky, Andreas Pargner, Sean Tarzy, Namkyu Park, Robert
Welters, Ronnie Webb, Jim Bagarazzi, Jalen Cates, Philip Lim,
Fabian Waetermans, Kainen Utt, Patrik Iannotti, Corina Wieber,
Salvador Ortega, Bill Courtney and John D. Nelson.

Before we dive in, we need to talk about two things. First, a
crucial question:

11

Why should you care about Quantum Mechan-

ics?

The strongest argument in favor of quantum mechanics is that
it correctly predicts experimental observations. Physicists and
philosophers can argue all day long about how beautiful some
theory is, but the only thing that matters in the end is that it
agrees with experimental evidence.

Just as classical mechanics describes a ball rolling down a ramp,
quantum mechanics describes, for example the hydrogen atom‘.

In addition, quantum mechanics is the little brother of quantum
field theory which is the best theory of the fundamental inter-
actions that we have. And it is almost impossible to understand
quantum field theory without learning the basic concepts in
quantum mechanics first.

Quantum mechanics is an essential tool in the repertoire of
any competent physicist. While it will not help you to describe
the ball that rolls down a ramp any better, it will allow you to
describe new physical systems which you can’t describe with
classical mechanics.>

The second thing we need to talk about is the meaning of a few
special symbols which we will use in the following chapters.

4 We will talk about lots of quantum
systems in Part II.

5 That was quick. As promised I
tried my best to remove all fluff.
Most books discuss in the first few
chapters how quantum mechanics
came about historically. This story
is extremely interesting. But this

is not a history book and there are
already lots of great books on the
history of quantum mechanics. See,
for example,

J. E. Baggott. The quantum story : a
history in 40 moments. Oxford Uni-
versity Press, Oxford England New
York, 2011. ISBN 978-0199566846

12

Notation

t Three horizontal lines = are used to indicate a definition.

t> The most important equations and results are highlighted
like this:

(1)

> We often use the shorthand notation 0; = 2 for the partial
derivative where i € {x,y,z}. (The symbol € means that the
element to its left is contained in the set on its right. So here,
i is either x, y, or Z.)

> It is conventional in quantum mechanics to denote opera-
tors using a hat: O. This notation helps to make clear when
we are dealing with an operator and when with an ordinary
number. However, often it is clear from the context that we
are dealing exclusively with quantum operators. When the
context is clear, we will neglect the hats to clean up the nota-
tion.

> Moreover, square brackets denote the commutator of two
operators A and B: [A,B] = AB — BA.

> €j, denotes the three dimensional Levi-Civita symbol, which
is defined as follows:

1 if (i,j,k) € {(1,2,3), (2,3,1), (3,1,2)}
Eijk = 40 ifi=jorj=kork=i (2)
—1 if (i,j,k) € {(1,3,2), (3,2,1), (2,1,3)}

> The absolute value of a quantity p is denoted by |].

That’s it. We are ready to dive in (after a short look at the table
of contents).

13

Contents

Part I What Everybody Ought to Know About Quan-
tum Mechanics

1 Bird’s-Eye View of Quantum Mechanics 25
2 Essential Quantum Features 33
2.1. The Heart of Quantum Mechanics .......... 33
2.2 What Does "Quantum" Mean? ............ 38

2.3 Uncertainty .......... 0.00.00 00 0000. 43

3 The Quantum Framework 47
3.1 Intermezzo: Essential Statistics ............ 51
3.2 Statistical Tools in Quantum Mechanics ....... 54
3.3 Wave Functions ..................0.. 60
3-4 Quantum Operators ...............05. 66
3.4.1 Intermezzo: Symmetries............ 67

3-4-2. The Most Important Quantum Operators .. 71

3-5 How Operators Influence Each Other ........ 73
3-6 How Quantum Systems Change ........... 75
3-7 Why Quantum Mechanics is About Waves .... . 79
3.8 Intermezzo: Eigenvectors and Eigenvalues .... . 82
3-9 AngularMomentum .................. 84
310 Spin... ee eee 85
3.11 Quantum Numbers................... g1

4 The Classical Limit 95

5 Summary 99

Part II Essential Quantum Systems and Tools

6 Tricks and Ideas We Need All the Time
6.1 Let’s Separate Time and Space ............
6.2 Why Quantum Waves areSmooth ..........
6.3 Classification of Solutions ...............

7 Quantum Mechanics in a Box
7.1 ThelInfinite Box ...............-.2.0-.-
7.2 The FiniteBox................-20-0-

7.3 The Hydrogen Atom ...............--.,

8 Scattering off a Box
8.1 The Step Potential................0.0..0.
811 E<U .. ee ee eee
81.2 E>U ow... ee eee

8.2 The Box Potential .................0...

g Harmonic Quantum Mechanics
g.1 The Magical Method ..................

10 Quantum Systems with Spin
10.1 Spin Measurements ..............0000.4
10.2 Spin Addition ..................005.

11 Further Systems

107
108
110
111

115
115
121
127

131
134
136

137
138

141
144
153
155

161

163

12 When the Going Gets Tough, the Tough Lower Their Stan-

dards

12.1 Perturbation Theory ..................
12.1.1 General Perturbation Formulas........
12.1.2 The Perturbed Infinite Box ..........

12.2 What Other Tools Do We Have? ...........

Part III What Your Professor is Not Telling You About

Quantum Mechanics
13 Mathematical Arenas

14 The World Beyond Wave Functions
14.1 The Pilot Wave Formulation..............

169

187

199
199

14.2 Path Integrals .................0008. 204
14.2.1 The Origin of the Classical Path ....... 215
14.3 Phase Space Quantum Mechanics .......... 219
14.4 Heisenberg Formulation ................ 229
14.5 Which Formulation Is The Best? ........... 231
15 What Does It All Mean? 233
16 Get an Understanding of Quantum Mechanics You Can Be
Proud Of 241
One Last Thing
Part IV Appendices
A Taylor Expansion 249
B_ Fourier Transform 253
C Delta Distribution 257
Bibliography 261

Index 265

17

Part I
What Everybody Ought to Know About
Quantum Mechanics

"The universe is full of magical things patiently waiting for our wits to
grow sharper.”

Eden Phillpotts

PS: You can discuss the content of Part I with other readers, find exercises to check your
understanding and give feedback at ww.nononsensebooks . com/qm/part1.

Now it’s time to get serious. Our plan for the next chapters is
the following:®

The first chapter in this part of the book is a bird’s-eye view of
quantum mechanics. Our goal is not to understand everything
immediately but to get an overview as quickly as possible. Af-
terward, we will discuss all concepts in more detail. We start
with a short discussion of the most famous quantum experi-
ment which is known as the double slit experiment. This exper-
iment tells us that we need waves to describe particles. From
this result, we can conclude that some fundamental quantities
allow only a discrete set of values. We say they are quantized.
The results of the double slit experiment additionally indicate
that there is a fundamental uncertainty in quantum systems.
For example, it is impossible to measure the momentum and the
location of a particle at the same time with arbitrary precision.

Then we start to develop a framework that allows us to describe
these features of quantum systems in mathematical terms. The
first essential ingredient is a new type of objects, called "kets".
We use kets to describe the system in question. In addition, we
need operators that yield, for example, the momentum of the
system if we act with them on a given ket. The quantum uncer-
tainty tells us that we need statistical tools and this observation
leads us to another type of objects, called "bras", which are sim-
ply "conjugated" kets. These new objects then also allow us to
understand that wave functions are merely a convenient way to
write down the coefficients which we get if we expand a ket in
the position basis.

Afterward, we will use group theory and Noether’s theorem

to derive the explicit form of the fundamental quantum me-
chanical operators.” The explicit form of the quantum operators
allows us to derive the two most famous equations of quan-
tum mechanics: the canonical commutation relation and the
Schrédinger equation. The former encodes the quantum uncer-
tainty while the latter describes how quantum systems evolve in
time. Using these equations, we can understand that the mea-
sured values for basic quantities (e.g., momentum or energy)

CONTENTS 21

® Don’t worry if most things here
don’t make sense to you at first
glance. The only goal in this chapter
is to give you a general idea of what
we will do in this first part. We will
discuss all the concepts mentioned
here in detail in the following
sections.

7 Group theory is the part of math-
ematics that allows us to describe
symmetries.

22 NO-NONSENSE QUANTUM MECHANICS

equate to the eigenvalues of the corresponding quantum op-
erators. After a short general discussion of operators and their
eigenvalues, we will move on to another crucial physical quan-
tity: angular momentum. In quantum mechanics, there are two
kinds of angular momentum. One kind encodes orbital angular
momentum, which describes how two objects revolve around
each other. The second kind describes spin, which a unique
quantum mechanical concept akin to internal angular momen-
tum. In the final chapter of this part, we discuss the connection
between classical mechanics and quantum mechanics.

The following diagram is our travel guide. Whenever you feel
lost, come back here. It is not necessary to study it in detail at
the moment —a short look will suffice for now.

Double Slit Experiment

Quantum Waves

ao

Quantization Statistical Tools Quantum Uncertainty

|

The Quantum Framework

an
| Group Theory + Noether’s Theorem

Wave Functions Quantum Operators
| oo genes
Schrédinger Equation <————> Time Evolution Quantum Numbers
Classicgl Limit |
Newton’s Second Law Angular Momentum

Spin

CONTENTS

The next chapter, as promised above, is a whirlwind tour of
quantum mechanics. We will talk about all fundamentally im-
portant concepts in just a few pages. It will be quite a ride. So
please, get another cup of coffee, take a deep breath and then
let’s dive in.

23

Bird’s-Eye View of Quantum
Mechanics

As mentioned in the preface, quantum mechanics is quite sim-
ple at its heart. Certain applications, however, can be extremely
difficult and complicated. For this reason it’s easy to lose the
forest for the trees. To prevent this, we will start by putting

all fundamental concepts into context. Afterward, we will talk
about the various concepts in more detail and gradually refine
our understanding until we are ready for real-world applica-
tions.

Let’s start with a really broad categorization.

There are three kinds of puzzle pieces that we need to master to
develop a proper understanding of quantum mechanics

1. Concepts (e.g., state vectors, operators, wave functions).

2. Equations (e.g., Schrédinger’s equation, canonical commuta-
tion relations).

3. Tools (e.g., eigenfunctions, eigenvalues, expectation values).

26 NO-NONSENSE QUANTUM MECHANICS

*We will discuss specific systems in
Part II.

? Examples of measurable quantities
are: momentum p, energy E, and
angular momentum L.

3 For example, fx yields the momen-
tum in the x-direction and 2, yields
the position on the z-axis.

There are, of course, many other concepts that are commonly
discussed in introductory quantum mechanics courses. How-
ever, these are only important if we want to describe specific
systems and not if we only want to understand the general
structure of the theory."

Therefore, in this overview chapter, we focus solely on the fun-
damental concepts, tools, and equations. Don’t worry if not
everything is immediately clear. Our goal is only to get an
overview and each idea mentioned in this chapter will be dis-
cussed in more detail later in the book.

First, let’s talk about the various concepts that we need to de-
scribe quantum mechanics.

In quantum mechanics, we describe a given system using a state
vector |). Such a state vector is commonly called a ket.

In our quantum framework, quantities we can measure are
represented by quantum operators O.? This fact is encoded in
canonical commutation relations like

(1.1)

Here, p; denotes the momentum operator in the i-direction and
%; denotes the position operator in the j-direction.3 The most
important point is that in quantum mechanics, quantities like
momentum and position are not represented by mere numbers.
This is necessarily the case since numbers always commute (e.g.,
3x5-5x3=0).

We act with these measurement operators on a given state vec-
tor and, as a result, obtain the value we would measure in an
experiment:

O \Ospec) = Ospec |Ospec) , (1.2)

where O is an operator and Opec is a number.

BIRD’S-EYE VIEW OF QUANTUM MECHANICS 27

For example, let’s imagine that we have prepared an electron
kg m
s
scribe the electron using the ket 3.2158), By acting with the

momentum operator p on our state vector, we get the momen-

such that it has momentum 3.21

. In our framework, we de-

tum of the system

p|3.218™) — (3.21 “gm 32188 ™) (1.3)
s s s
However, we only get such a simple result if our system is in an
eigenstate of the operator in question. For each operator, there
is a specific set of so-called eigenstates. These eigenstates are the
basic building blocks of all state vectors that we use to describe
quantum systems. Formulated more technically, we can use the
eigenstates of a given operator as basis vectors for the vector
space which contains our state vectors.

A state vector represents an eigenstate of a particular operator
if measuring the associated quantity always yields the same
result.4 Mathematically, this means that if we act with the op-
erator on an eigenstate, then we simply get the original state
vector multiplied by a number and not something more compli-
cated. For example:

operator x eigenstate = eigenvalue x eigenstate .

In contrast, our state vector is usually a linear combination of
eigenstates.> For example, we can expand |) in terms of its
eigenstates {|0;)} as

[%) = Yai loi) = ay Jor) + a2 |o2) +... (1-4)

where a; € C are the probability amplitudes, which encode
the probability of measuring the corresponding value 0;. The
general relationship between a probability amplitude and the
corresponding probability is:

probability to measure 0; = |a;|*.

For example, the probability of measuring the value 02 is |a2|*.
This means that if we prepare our system in the same initial
state multiple times and then measure, say, the momentum,

4 This may seem trivial, but in
quantum mechanics it isn’t always
the case.

5 This is completely analogous to
how we can write a general vector 3
in terms of basis vectors

G = Vxby + Vyly + 0222.

28 NO-NONSENSE QUANTUM MECHANICS

° Hermitian conjugation means the
combination of complex conjugation
and transposition. Hermitian
conjugation is denoted by a dagger
t, complex conjugation is indicated
by a star x, and matrix transposition
is denoted by a T.

7 Here 6;; denotes the Kronecker
delta. Moreover, take note that we
only get the probability amplitudes
if all eigenstates are properly
normalized.

we will not always get the same result. Instead, we sometimes
(with probability |a;|*) measure the value p; and sometimes
other values like po.

To make sense of a system which is not in an eigenstate, we
need one additional tool known as conjugated state vectors or
simply "bras" (¥|. A bra is a Hermitian conjugated ket:®

(¥| = pe)" = ([¥)*)". (1.5)
Using an eigenstate bra (0;|, we can project out the required
probability amplitude a; from any ket directly:7
Eq. 1.
(01%) 2 (oj1 (hai lei) )
1
2
= )'4; (0;|0:)
i
> (oj|o;) = 5,
= Daisy
i
2 Lfisij = fi
= ij. (1.6)

This works because eigenstates are usually orthogonal, which
means that a product like (0;|0;) yields zero except for i = j.

Therefore, if we are interested in the probability of measuring a
value of 3.218 for the momentum, we multiply our general
ket with the corresponding eigenstate bra:

kgm
Ss

(3.21 kgm

|¥) = ai (3.21 \0;) = 43.21 - (1.7)

This tells us that the probability of obtaining such a value is
|43,21|7

Additionally, we can use bras to calculate expectation values.
An expectation value is the arithmetic mean of the values ob-
tained from many trials of a given experiment. In our frame-
work, we can calculate expectation values by "sandwiching" the
corresponding operator between a bra and the corresponding

ket which describes the system

BIRD’S-EYE VIEW OF QUANTUM MECHANICS 29

expectation value = (¥|O/®) . (1.8)

Take note that here, we don’t have an eigenstate as a bra but
instead the bra (¥| corresponding to the ket |Y) .

The main idea is that by calculating such a product we get a

sum over all possible values times the corresponding probabili-

ties:°

(HOPE) “E* (F (jlat) O( Tailoi) )
j i

= rhage (0;|O|0;)
= rhage (0;|0;|0;)
= Lda (0;|0;)
= LLoajaids

= Doilail*.

a; and aj are numbers
the operator O acts on |0;)
0; is a number

(oj|o;) = dj

In words, this means that we multiply each possible outcome

0; with the probability |a;|? to measure this value and then sum

over all these terms. Formulated differently, calculating the

expectation value essentially yields a probability-weighted sum

of all the possible values. The result of such a weighted sum

helps us to understand what we will measure on average.

Another important observation is that for each operator, we

get a different set of eigenstates.? This means that we can also

expand a general state vector in terms of different eigenstates:

[%) = 2b; loi) = bi or) + ba |o2) +... (1-9)

8 Using the expansion of our general
ket in terms of eigenstates (Eq. 1.4)
and the connection between bras
and kets (Eq. 1.5), we can calcu-

late directly the expansion of the
corresponding bra:

(¥| = [¥)"
= (Laila)!
= Ea loi)"
= Da (oi ,

where we used that for a number
we have at = a®* since there are
no rows or columns that could be
transposed.

9 Take note that for operators which
commute

AB-BA=0

there is a common set of eigenstates.

30 NO-NONSENSE QUANTUM MECHANICS

*° In some sense, an integral is
simply a sum over a continuous set
of values.

*tIn principle, a vector is a little
arrow sitting somewhere in space.
Only by using a specific coordinate
system and therefore specific

basis vectors like @,, éy, @,, we can
describe the vector using concrete
numbers #@ = (3,2,3)7. Take

note that for a different choice of
coordinate system or a different set
of basis vectors (e.g., spherical basis
vectors), we get different numbers.

where |6;) are the eigenstates corresponding to a different oper-
ator O.

The key idea is that if we are interested in, for example, the
momentum of the system, we expand our general state vector
in terms of momentum eigenstates. If we are instead interested
in the energy of the system, then we would expand the state
vector in terms of energy eigenstates, and so on. The numbers
a; and b; that we get by expanding a general state vector tell us
directly the probability to measure a given result. Formulated
differently, expanding a general state vector in this manner
yields coefficients (a; or bj) which are directly related to the
probability of measuring a given value.

The set of possible outcomes is not necessarily discrete. In the
case of a continuous set of possible outcomes, we must replace
the sum in Eq. 1.9 with an integral:°

[¥) = [a a(o) |o) .

Take note that our discrete coefficients a; are replaced by a func-

(1.10)

tion a(o). However, the basic idea is still the same. For each
possible measurement outcome 0, we get a specific probabil-
ity amplitude a(o). The probability of measuring the value o is
ja(o)?.

The function w(x) that we get by expanding a state vector in
terms of position eigenstates

p¥) = f dx p(x) |x)

is usually called the wave function.

(1.11)

Analogous to how we can describe a given vector @ using the
specific coefficients for some given basis, we can use (x) to
describe the system."*

The time-evolution of quantum systems is described by the

BIRD’S-EYE VIEW OF QUANTUM MECHANICS 31

Schrédinger equation:

292

na?
ihds [¥) = + [¥) + V(2) [¥) . (1.12)

Formulated differently, the Schrédinger equation is the equation
of motion for our state vectors and equivalently, for our wave
functions
ho?
ihd; (x,t) = — Fm P(e t) + V(£)p(x,t). (1.13)

With this equation at hand, the main task in quantum mechan-
ics is to solve it for different systems (i.e., different potentials
V(2)). As a result, we get wave functions (x,t) which describe
the quantum system in question. The square of the absolute
value of such a wave function tells us where we can expect to
find the particle in the system.

For example:

Moreover, we can use it to calculate which energy levels are

possible and which momenta we can expect to measure.”? 2 We will discuss how exactly this
works in Part II.

After this, almost certainly overwhelming, first glance at what
quantum mechanics is all about, let’s take a step back and talk
about these concepts in a bit more detail.

2

Essential Quantum Features

The underlying message to take away from this chapter is that
nature works very differently at small scales than we would
expect from our everyday experiences.

We will start with a short discussion of the three most impor-
tant features of quantum mechanics:

1. We need waves to describe particles.
2. Some physical properties are quantized.

3. Quantum systems have an inherent uncertainty.

Afterward, we will talk about how we can describe these unin-
tuitive features using an intuitive physical framework.

2.1 The Heart of Quantum Mechanics

Richard Feynman once remarked in his lectures that one experi-
ment "has in it the heart of quantum mechanics. In reality, it contains
the only mystery".*

* Richard Feynman. The Feynman
lectures on physics. Basic Books,
a member of the Perseus Books
Group, New York, 2011. ISBN
978-0465025015

34 NO-NONSENSE QUANTUM MECHANICS

The experiment he was referencing is astonishingly straight-
forward. All we need is a beam of electrons, a wall with two
little slits in it, and a screen behind the wall that detects the
electrons. This experimental setup is known as the double slit
experiment.

Before we discuss the experiment with actual electrons, there
are a few preliminary things that we should talk about.

First, if we shoot a beam of bullets (rather than electrons) to-

wards a double slit and observe the pattern behind it, the re-
sults is rather dull:

‘bullet
gun

Most bullets end up in the middle of the screen and progres-
sively fewer if we move away from the middle. We can under-
stand this pattern by considering the same experiment with just
one slit:

O_O 37
bullet

gun


ESSENTIAL QUANTUM FEATURES

The result of the double-slit experiment is simply a sum of the
results obtained from each single-slit experiment.

If we replace the bullet with a wave (e.g., a water or sound
wave), the result shown on the observing screen is much more
interesting:

%
6,
&Y
%e

wave generator

interference
pattern

The pattern we see on the screen is known as an interference
pattern. This pattern arises because the wave goes through both
slits and we can imagine that at each slit a new wave originates.
Behind the double slit, the new waves propagate and overlap,
resulting in the interference pattern observed on the screen.

So, what does all this have to do with quantum mechanics?

Well, we usually think of particles like electrons as analogous to
very tiny bullets. Therefore, when we shoot electrons towards

35

36 NO-NONSENSE QUANTUM MECHANICS

? We will talk a bit about how we
possibly can interpret this crazy
behavior in Chapter 15.

a double slit, we would expect results similar to those obtained
using bullets.

The crazy thing is that if we perform the double slit experiment

with electrons, we actually see an interference pattern on the
screen!

. electron

electron gun

interference
pattern

While for waves we measure the intensity (the height) of the
waves, for electrons we count how many of them end up at each
particular point on the screen.

We measure discrete events on the screen ("click, click, click,. . .").
But if we plot how many electrons ended up at each location,
we see the same pattern that we observe for water waves.

We can also observe the same behavior for light. Since the
concept of electromagnetic waves is somewhat familiar, this
is maybe not so surprising.

However, the crucial point is that if we shoot a tiny amount
of light onto a double slit, we observe discretized, particle-
like "packets" of light on the screen. These light particles, or
photons, are particles precisely in the same sense as electrons.

Physicists have experimentally observed this behavior, although
we still struggle to understand it. There is no problem, how-
ever, in describing the phenomenon and this is what quantum
mechanics is primarily about.?.

ESSENTIAL QUANTUM FEATURES 37

So the bottom line is:3

While electrons as well as other elementary particle

are discrete objects, we need waves to describe them.

Before we move on, I want to warn you about one thing. Many
textbooks include much discussion of things like the mysterious
wave-particle duality. Many people unfamiliar with quantum
mechanics may wonder how an electron could be a particle and
a wave at the same time.

Please ignore this kind of idle speculation. The situation is not
as crazy as some would lead you to believe. Electrons, photons,
and all other elementary particles are particles. Period. This is
what every experiment tells us. Our detectors make "click, click,
click".

Waves are merely one convenient mathematical tool for describing
the behavior of these particles.4 Since most people have experi-
ence with waves, using them as a mathematical tool allows us to
develop some intuition for the behavior of quantum systems.

However, this wave description is only a mathematical tool. It
is also possible to describe everything in quantum mechanics
completely without using waves at all.5 So please, don’t let
yourself get confused by such discussions.

In the following two sections we will talk about the two most
important features of quantum mechanics. We can directly
understand both when we use waves to describe particles.

3 This is not 100% correct. Waves
are the simplest way to get a first
grasp on what quantum mechanics
is all about. We will discuss in
Section 12.2 how we can describe
quantum behaviour without waves.

+ These waves were historically
called "matter waves", a term
introduced by French physicist
Louis de Broglie.

5 We will talk about this in detail in
Chapter 14.

38 NO-NONSENSE QUANTUM MECHANICS

1. $e
2 {ee
Set Qe"

iy

Pe 7 @ ©
Ba,%
6e=1.602x 10-9 C

7 A special type of speculative
models known as "grand unified
theories" has been suggested as a
solution to this conundrum.

8 Something like 10° is a huge
number:
10’ = 10 x 10 x ...10
= 10000000000000000

2.2 What Does "Quantum" Mean?

In classical mechanics, we can measure for basic quantities

like energy or angular momentum any value we can imagine.
This is not always the case for quantum mechanical systems. In
many quantum systems, basic quantities only arise in discrete
chunks, or quanta. As such, we say that these properties are
quantized.

A famous example is electric charge. Any measurement of
electric charge yields an integer multiple of the basic charge e:

Q=Nxe,

where N is an integer and e is the absolute value of the charge
of an electron.® In particular, this means that a measurement

of electric charge of some object in nature possibly yields 2e

or 977e, but never something like 2.12e or 34.76e. In this sense,
electric charge is quantized. Why this happens is a different
question and, unfortunately, we don’t know the answer yet.”
But this is what makes quantum mechanics so interesting. There
are still lots of fundamental things we do not understand.

No theoretical physicist predicted the quantization of electric
charge. It was also not immediately discovered when physicists
were developing electrodynamics because the charges of macro-
scopic objects (e.g., a metal sphere) are typically on the order of
Qsphere © 4.806 C. Compared to the charge of a single electron,
these macroscopic objects have a huge amount of charge.

As a result, it seems as if we can produce spheres with arbitrary
charges. This is an illusion. If we measure the electric charge

of a macroscopic object very, very precisely, we notice that even
such macroscopic charges are integer multiples of e:8

Qspneret ¥ 4.806 C ~ 3000 - 10'%e
Qspherea © 5.01 C % 3127-10'%e. (2.1)

ESSENTIAL QUANTUM FEATURES 39

The fundamentally discrete chunks of electric charge are tiny
compared to the charges of macroscopic objects. When we
change the charge of a sphere, we get a discrete sequence like

Qsphere1 = 4.80652986239999955569404683720 C
Qspherel+ie = 4.80652986239999955585426449928 C
Qsphere1+2e = 4.806529862399999556014482161367 C
Qsphere1+3e = 4.80652986239999955633491748552 C

Qu phere1-+2948745599054545¢ = 4-80700230352594876390867348334 C

If we are only concerned with the first four digits, we can con-
clude that we can produce any value of the charge that we like.
It’s only when we measure the charge extremely precisely that
we notice that changes occur in discrete steps.?

The same thing also happens for other fundamental physical
quantities. In many quantum systems, we can no longer mea-
sure any arbitrary value for the energy or angular momentum.*°
Instead, they only appear in discrete chunks and are therefore
quantized.

A famous example of quantization can be found in the discrete
energy levels populated by the electrons in an atom. Nothing
in classical electrodynamics tells us otherwise. In quantum
mechanics, however, only a discrete set of energy levels is al-
lowed. We can observe this by measuring the radiation emitted
whenever an electron jumps from one energy level to a lower
one. The energy of the radiation is precisely the energy differ-
ence between the energy levels. The energy of the electron does
not change continuously from one value to another. Instead,

it jumps directly. This is where the notion of quantum jumps
comes from.

Okay, what does all this have to do with the fact that we need
waves to describe particles?

9 We can understand this quantiza-
tion since when we charge a sphere
we add or remove electrons from it.
Each additional electron contributes
an additional charge e. This is why
we have discrete steps. However,

a mystery is why, for example,
protons do not have some random
value of the charge, but exactly the
charge —e.

*° Tn speculative theories like loop
quantum gravity, even space and
time are quantized.


40 NO-NONSENSE QUANTUM MECHANICS

™ We will discuss this example in
detail in Chapter 7.

% This is a result of the boundary
conditions imposed by the box and
is completely analogous to what
we have discussed for the rope
example.

Well, waves naturally quantize physical properties!

To understand this, let’s consider a rope which we hold under
constant tension:

No matter how the two hands try to make the rope vibrate, the
rope will only vibrate with a quantized set of modes. The two
hands fix the rope at both ends. As a result of this constraint,
the rope can only vibrate with fixed modes.

It is physically impossible to make the rope vibrate with a mode
outside of this fixed set.

The same thing also happens when we describe particles using

waves. For example, let’s consider an electron confined in a
box.*?

If we describe the electron using a wave, we notice that only
very particular wave shapes are allowed:'?

ESSENTIAL QUANTUM FEATURES 41

n=d
n=2
n= {

The frequency of the wave associated with a given particle is

directly related to its energy as 3 We will discuss the origin of this
formula later. For the moment,
we are only interested in the basic
message and want to build some
(2.2) intuition.

where h is a constant known as the Planck constant, E is the

energy of the particle and v is the frequency of the correspond-

ing wave"4. This means that our particle in a box can’t have “4 In slogan form: The higher the
arbitrary energy values. Since only a discrete set of modes is frequency, the higher the energy.
allowed, the particle can only take on a discrete set of energies.

This is how energy becomes quantized in quantum mechanics!

Similarly, we can understand why there are only discrete energy
levels in atoms. As a naive picture, imagine electrons orbiting
the nucleus. Classically, any orbit is allowed. However, as soon 5 Imagine in the picture of the

box above that the points x = 0

as we describe electrons with waves, this is no longer the case.
’ 8 and x = L coincide. The fixed

The electron "orbits" correspond to standing waves around the radius r is known as the Bohr

nucleus. For a fixed radius r, we are effectively dealing with radius. Physically, the Bohr radius
: : 15 . : represents the most statistically

something like a box*>. The wave must coincide at the endpoint 5. ely distance between the nucleus

and the starting point, therefore allowing only specific wave and the electron.
modes:

42 NO-NONSENSE QUANTUM MECHANICS

*6 This explanation is known as
the Bohr model. Be warned that
this slightly outdated model is not
entirely correct, but works well for
the hydrogen atom. The details

in a real atom are, of course, a lot
messier. However, the Bohr model
still gives a nice intuitive feeling
of how quantization happens in
quantum mechanics.

7 Take note that the energy of a
free particle, for example, is not
quantized. The energy is only
quantized for bounded systems
like a box. However, the electric
charge is always quantized. We will
discuss this in a bit more detail in
Chapter 5.

This is why atomic energy levels are quantized.'®

To summarize: Many familiar quantities like energy are not al-
ways continuous. In certain quantum systems, they only appear
in discrete chunks.*7

Whenever this is true, we say the corresponding quantity is
quantized. This fact is not observable in everyday life because
the intervals between allowed values are tiny. Quantization is a
consequence of the "wave nature" of particles.

ESSENTIAL QUANTUM FEATURES 43

2.3. Uncertainty

A second crucial feature of quantum mechanics is that there is
an intrinsic uncertainty.

A somewhat naive (but helpful) explanation of quantum uncer-

tainty goes as follows:%8 *8 The quantum uncertainty is often
also called Heisenberg uncertainty
. .. and the following explanation is
Imagine that we want to measure the position of an electron by actually how Werner Heisenberg
taking a picture of it. To take this picture, we need to bounce liked to explain it.

light off the electron’s "surface", since without light we can’t see
the electron. However, the light we bounced off of the electron
unavoidably caused the electron to move a bit. As a result, the
momentum of the electron is changed each time we measure

its position. What this means is that we can’t know the position
and momentum of an electron at the same time with arbitrary
precision. We have to decide which property we want to know
exactly. We can either measure the position exactly or measure
the momentum exactly, but we cannot measure both at the
same time. There is a limit to how much we can know about an
electron.

Again you may wonder: What does this have to do with our
wave description of particles?

In the previous section, we saw why quantization is a direct
result of this new description. Now we will see that quantum
uncertainty is also a direct consequence of the "wave nature" of
particles!

Once more, let’s consider a rope. We can generate a wave in a
long rope by shaking it rhythmically up and down:

( Ax bc hn,


44 NO-NONSENSE QUANTUM MECHANICS

19 Such waves with well-defined

waves lengths are known as plane
waves. The expansion of a gen-

eral bump in terms of such plane
waves is exactly the idea behind

the Fourier transform. For more
information on this see Appendix B.
The uncertainty we end up with
this way is a general feature of
waves and known as the bandwidth
theorem.

If someone were to ask us where the wave is, we wouldn’t have
a good answer since the wave is spread out. But if we get asked:
"What's the wavelength of the wave?", we could easily answer
this question and state: "It’s around 6cm."

We can also generate a different kind of wave in a rope by jerk-
ing it only once.

This way, we get a narrow bump that travels down the line. For
this kind of wave, we can easily answer the question: "Where
precisely is the wave?". But we have a hard time answering the
question: "What's the wavelength of this wave?", since the wave
isn’t periodic and it’s completely unclear how (or if) we can
assign a wavelength to it.

Analogously, we can generate any kind of wave in between
these two edge cases and there is always a trade-off. The more
precisely the position of the wave is localized, the more ambigu-
ous the wavelength becomes, and vice versa.

To make this idea more precise, we can think of a localized
wave as a superposition of dozens of other waves with well-
defined wave-lengths*?.

If we add lots of waves with different wavelengths, they will
average out almost everywhere. But we can arrange the waves

such that, in a small region, they don’t cancel each other out.

This is true for all waves. Since in quantum mechanics, we
describe particles using waves, it also applies here.

In quantum mechanics, the wavelength is directly related to its

ESSENTIAL QUANTUM FEATURES 45

momentum h
A=- (2.3)
P
The larger the momentum p, the smaller the wavelength A of
the wave that describes the particle. Therefore, a spread in

wavelength corresponds to a spread in momentum.”° 2° Once more we use a formula
without deriving it. We do this to

. . . . develop some intuitive understand-
What this means in physical terms is exactly what we talked ing of quantum waves first and

about above: We can’t know the location and momentum of postpone the actual derivation to a
: : : os later chapter.
particles with arbitrary precision:

| wins \ <I
VAAN Aa
AAVAVAVAVA\

The uncertainty relation that we arrive at tells us:

The more precisely we determine the location of

a particle, the less precisely we are able to

determine its momentum and vice versa.

Before we move on, let’s summarize what we have learned so
far.

The double-slit experiment tells us that we need waves to de-
scribe particles. This "wave nature" of particles then leads us to
two essential features of quantum systems: quantization and
uncertainty.

46 NO-NONSENSE QUANTUM MECHANICS

Since only special waveforms are allowed for a particle ina
box, we end up with a discrete set of allowed states. In physical
terms, this means that only a discrete set of energy values is al-
lowed for a particle in a box. As a result, we say that the energy
of this system is quantized.

Moreover, we have learned that for waves there is always a
trade-off between the localization of the wave and how well we
can determine its wavelength.

We can think of a localized wave bump as a sum of many waves
with well-defined wavelengths. In other words, a localized
waveform corresponds to a superposition of waves with differ-
ent wavelengths and, therefore, not to one specific wavelength.
In turn, a waveform with well-defined wavelength (a plane
wave) is not localized anywhere but spreads out all over space.

In quantum mechanics, there is a direct relationship between
wavelength and momentum. In addition, the localization of the
wave encodes information about the location of the particle in
question.

Taken together, this tells us that (thanks to the "wave nature”
of particles) we can’t simultaneously measure both the location
and momentum of a particle with arbitrary precision.

Now it’s time to develop a framework that will allow us to
describe all these weird features of quantum systems.

3

The Quantum Framework

We will start this chapter by developing a general framework
to describe nature. Afterward, we will see how easily we can
describe quantum mechanics using this general framework.

The most important ingredient that we need is something that
describes our physical system in question. We invent a new
mathematical symbol that does the job: |Y).

Everything about the physical system is encoded in |). The
standard name for this type of object is a state vector or ket’.

Each different possible state of our system corresponds to a
different ket |'¥1),|'¥2),....

Think about an atom. An electron surrounding a nucleus can
have different energies. It can be in the ground state (the state
with the lowest energy), but it can also be in an excited state.
In our framework, for example,

> |¥1) denotes the configuration with the electron in the
ground state and

* Okay admittedly, this sounds
horribly abstract. But I promise

this notation is clever and will
make a lot of sense in a moment. In
particular, the name "ket" will make
more sense in a moment.

48 NO-NONSENSE QUANTUM MECHANICS

> |¥2) corresponds to the configuration with the electron in the
next highest excited state.

tt, 7 Ih?

These are simply labels for different states. For most systems,
there are infinitely many possible states. For example, an elec-
tron at position x = 0 is a different state than the same electron
at position x = 0.1. Since there are infinitely many possible loca-
tions, there are infinitely many states for a free electron. Again,
this may sound a bit scary, but we will see in a moment how to
deal with this situation.

So far, so good. But how are these abstract objects related to
anything we can measure in experiments?

There are only a few ingredients missing. The next thing that
we need is a way to extract information from our kets. Suppose
we want to know the momentum of our system. To get this
information from our ket |'¥1), we "ask" it:

pl¥1) =? (3-1)

The object f is called the momentum operator. Again, we sim-
ply invented a mathematical symbol that does the job. The oper-
ator p acts on our ket and yields the momentum of our system:

p|¥1) = pil¥1) - (3.2)
Here, p; € R is the momentum of the system in the configura-
tion described by |'¥;). If we ask the same question when the

THE QUANTUM FRAMEWORK

system is in a different configuration, then we get a different
answer:

P|¥2) = p2|¥2) - (3.3)

Yes, it’s that simple! We act with # on the object that describes
our system, |”), and get back the momentum that we can mea-
sure in an experiment.

Admittedly, the situation is not always that simple. In the pre-
vious section, we talked about uncertainty — one of the most
important features of quantum mechanics. The presence of this
uncertainty means that we won't always get answers that are as
simple as obtained in the above examples. Instead, there is al-
ways some variance. Even if we manage to prepare our system
perfectly such that it definitely has momentum p;, measurements
of the system’s position yield a range of values. Therefore, we
need to add something to the framework that allows us to deal
with uncertainty.

But first, what exactly does uncertainty mean?

Well, in the example we discussed above, it means that mea-
surements of the momentum will not always yield p;. Given a
set of equally prepared atoms, we will sometimes measure the
value p; and other times the value p2. There is a variance in our
measurements.

How can we implement this in our framework? Naively, we
write

|¥) =a|¥1)+b|¥2), (3-4)

where a and b are numbers that encode how often we measure
pi and p2, respectively. If we act with # on this new ket, we get
an answer we don’t immediately understand:

B Eq. 3-4 .
piv) * p(a[¥i) +b [¥2) )

= ap |¥1) + bp |¥2)
> pl¥i) = pil¥i), Eq. 3.2
= ap; |'¥1) + bp2 |¥2) . (3.5)

49

50 NO-NONSENSE QUANTUM MECHANICS

?If you are already familiar with
expectation values and standard
deviations, feel free to skip the
following section.

We can only understand a result like this in a statistical sense.
This is what the quantum uncertainty demands of us. Quan-
tum mechanics results often only make sense from a statistical
perspective. Therefore, we need to add statistical tools to our
framework.

Before we can do this, we need to talk for a moment about
statistical tools in general?.

THE QUANTUM FRAMEWORK 51

3-1 Intermezzo: Essential Statistics

One of the simplest but at the same time most important statis-

tical tools is the so-called expectation value}. The expectation 3 Alternative names for the expec-
tation value are: expected value,

value of a quantity is the average value that we expect when we ;
mean value, or simply the average.

repeat a given experiment many times. We use it whenever we However, in the context of quantum

are forced to make probabilistic judgments. mechanics, it is conventional to use
the word "expectation value”.

To understand what an expectation value is, imagine the follow- + Think flipping a coin or tossing a

ing situation: die.

A friend offers to play a game. She flips a coin. If it lands on
tails, she pays you $1.50. But if it lands on heads, you have to
pay her $1. By calculating the expectation value for this system,
you can decide whether you should agree to play this game.

> The probability that a coin lands on heads is p = 50%. In
this case, the outcome for you is: x; = —$1.

> Equally, the probability that a coin lands on tails is pz = 50%.
In this case, the outcome for you is: x2 = +$1.5.

The expectation value is defined as the sum over each outcome
times the probability of the outcome
2

expectation value = )° x;P,
i=l

>)
= x1 P, + x2P2
= —$1 x 50% + $1.50 x 50%
>)
= $0.25. (3.6)

So if we play this game many times, we will make a profit. On
average we make $0.25 per game. For example, let’s say you
play the game only twice, win once, and lose the second time.
For the win in the first game, you get $1.50. For the loss in the
second game, you lose $1. In total, you have therefore won $0.5
in two games. This equals $0.25 per game. Of course, here the

52 NO-NONSENSE QUANTUM MECHANICS

5 Maybe you already noticed the
similarity of this notation to our
previous notation for the kets |"f).
If not, don’t worry, because the
similarity will become a lot more
obvious in a moment.

6 This strange looking definition
will make sense in a moment. And
as an aside: The same definition
without the square-root is known as
variance.

7 For example, for x = {3,—5,9} we
have

Ya? = (8) + (5)? + 9)

=115

whereas
2
(Dx) =(-5+9)
i

= 49.

system is so simple that we could have guessed this without
calculating anything. But for more complicated systems, the sit-
uation quickly gets messy. Quantum systems, in particular, have
many possible outcomes with potentially different probabili-
ties of occurring. This makes it much more difficult to predict
anything without referring to something like the expectation
value.

To summarize: the expectation value is the expected average out-
come of repeated probabilistic events. A common mathematical
notation for the expectation value of a quantity x is (x).5

There is one additional statistical notion that we need all the
time in quantum mechanics. It tells us how much the system,
on average, deviates from the expectation value. In other words,
this notion tells us how much our measurements spread out. If
it is zero, we measure the same value all the time. If it is non-
zero, it’s possible to measure different values. The notion I’m
talking about is called the standard deviation. It tells us exactly
how much our measurements (on average) spread around the
expectation value:®

Ax = (x2) = (x)? G7)
The second term under the square root is simply the expectation
value squared. For the first term, we again calculate an expec-
tation value, but this time we square each possible outcome
before we weigh it with the corresponding probability

(x?) = Pah. (3.8)

Compare this with

2
(x)? = (Esa) . (3-9)

Yes, it makes a difference whether we square the whole sum or
each term of the sum!7

To understand this definition, let’s return to the example from

THE QUANTUM FRAMEWORK

above. The standard deviation for our coin flipping game reads
Ax 437 ,/(x2) — (x)2

> Eq. 3.8 and Eq. 3.9

2
i i

> Eq.36
= yor — ($0.25)?
| >)
= \/ ((-$1)? x 0.5 + ($1.5)? x 0.5) — ($0.25)
>)

= $V/1.625 — 0.252 = $1.25.

There are two important things to take note of:

> The result isn’t zero. As I already emphasized above, it
makes a difference whether we square each term in the sum
or the complete sum. Otherwise, the standard deviation
would always be zero.

> If we only know that the expectation value of some game
is $0.25, then we are missing a lot of information. Naively,
we could think that we are only betting tiny amounts of
money since $0.25 is a tiny number. However, imagine that
we make our example more extreme. In this new game, if
the coin lands on heads, you have to pay $10,000. And if
it lands on tails, you get $10,000.50. The expectation value
is again (x) = $0.25. But the game is much more extreme
now. I wouldn’t like to play it. While the odds are still in
your favor, there is also a real chance that you lose a lot of
money. This kind of information is encoded in the standard
deviation. For this modified game, the standard deviation is
Ax = $10,000.25, making it immediately clear that a large
sum of money is at stake.

Before we move on, here’s one more comment on the idea be-
hind the definition of the standard deviation: The logic behind
squaring each possible outcome in the first term on the right-
hand side is to avoid that terms cancel because they have op-

53

54 NO-NONSENSE QUANTUM MECHANICS

5In the example $* with $.

posite signs. This is exactly what happens when we calculate
the expectation value. In the coin example, if the outcome was
heads we had to pay $1 which mathematically means x; = —$1.
Thus, in the formula for the expectation value, the two terms
canceled almost completely since they have different signs. But
now we want to get information about the spread in our mea-
surements. Hence, we need to define a notion that takes the
absolute distance from the expectation value into account. We
accomplish this by squaring each outcome and only then mul-
tiplying each term by the corresponding probability. We then
also square the expectation value such that it has the same units
as the thing we just calculated. Otherwise, we would compare
apples with pears®.

Now, we have everything we need to get back to quantum me-
chanics.

3.2 Statistical Tools in Quantum Mechanics

After this short detour, let’s recall what we have already learned:
We describe our system with an abstract object |’) called a ket.
If we want to know, for example, the momentum of the system,
we act with the momentum operator # on this object. What we
get this way is the value that we would measure for the mo-
mentum. In general, however, we are dealing with inherently
uncertain quantum systems. Hence, we usually don’t get back a
simple number if we act on a ket with the momentum operator.
For example, consider the ket in Eq. 3.4:

|¥) =al¥1)+b|¥o) . (3-10)
For this ket, we have
P\Y) = apy |¥1) + bp2 |¥2) - (3.11)

In physical terms, this means that we sometimes measure p1
and sometimes we measure p2. The situation is therefore anal-
ogous to the coin example that we talked about in the previous
section. Thus, it makes sense to introduce expectation values in

THE QUANTUM FRAMEWORK 55

quantum mechanics. Before we can calculate expectation values,
we need to add a few more ingredients to our framework.

The multitude of new concepts and ideas can be overwhelming
at first, so don’t worry if not everything is clear immediately. It
takes some time to get used to new concepts. If you feel over-
whelmed, just keep reading. After a while, everything will start
to fall into place.

I will simply list all of the new ideas and concepts that we need.
Afterward, we will talk about them one after another in more
detail. Ready?

1. The two ingredients which we need to calculate an expecta-
tion value are a list of possible outcomes plus the probabili-
ties with which they occur. If we look at Eq. 3.11, we see that
the possible outcomes for this particular ket are p; and pp.
But what are the corresponding probabilities of measuring
these values? For our example ket in Eq. 3.11, the probability
of measuring p, is |a|? and the probability of measuring p2
is |b|?. So the correct formula for the momentum expectation
value is

(p) = |a)?pr + [bP pa, (3.12)
analogous to what we discussed in the previous section.

2. In quantum mechanics, given a concrete ket |‘¥), we calculate
the expectation value of an operator like p as follows:

(¥| ple) 92° (ar (a) +b" Fo] ) p(a[%1) + 1%) )

= (a* (¥1| + b* (¥o| ) (ap [¥1) + bp [¥2) )
P
= (a* (¥1| + B* (Fol ) (apr [¥1) + bp2 [¥2) )
> aa= al’, b*b = [b/,
= |al?py (¥1|¥1) + a* bp (¥1[¥2) + b*apy (¥2|¥1)
+ |b|*p2 (¥2|¥2)
> 5 2 (¥il¥2) =0, (¥1/%1) =1,...
= |al"p1 + |p. (3.13)

56 NO-NONSENSE QUANTUM MECHANICS

9 We will talk about the new sym-
bols like (¥;| and why the coef-
ficients a and b appear complex
conjugated in a moment.

10 Momentum basis kets are those
with definite momentum. A general
state is a linear combination of
momentum basis kets.

Here we used lots of new ideas that we will discuss in detail
below.?

3. Anew type object appears in the definition of the expecta-
tion value in Eq. 3.13: (¥|. We call this kind of object a bra.
This name together with the name ket is a wordplay on the
brackets we use. A bra is nothing completely new. Given a
ket, we can immediately compute the corresponding bra:

(¥| = |¥)* = ((¥)*)?. (3-14)

The star + denotes complex conjugation and the superscript
T denotes transposition. The object t is called dagger and
we use it to denote a transformation known as Hermitian
conjugation. We calculate the Hermitian conjugate of an
object by first complex conjugating and then transposing

it. So, in words, Eq 3.14 means that a bra is the Hermitian
conjugate of the corresponding ket.

4. Additionally, in Eq 3.13 we used the fact that our objects (¥1|
and (¥2| are normalized basis vectors. This means that they
are orthogonal and thus (¥;|¥2) = 0. Moreover, since they
are normalized we have (‘¥;|;) = 1. This is what we used to
get to the last line in Eq 3.13.

Now let’s talk about these ideas one after another in detail. We
will start at the bottom of the list.

4. As mentioned above, kets (like |%1) and |'¥2)) that corre-
spond to definite values of a given observable are basis
vectors. This is in contrast to general kets, which do not
correspond to one definite value (here p; and p2) of, say, the
momentum operator but instead to a superposition of pos-
sible outcomes. Above, we have expanded the general ket in
terms of momentum basis kets’©

|¥) = a|¥1) +b |¥2) . (3-15)

This is completely analogous to how we can expand an arbi-

THE QUANTUM FRAMEWORK 57

trary vector in terms of the basis vectors

1 0 0
0 0 1
For example,
1 1 0 0
B= ]3| =1e, + 3é)+5e,=1])0]+3]1]+5]0
5 0 0 1
(3-17)

A useful property of such basis vectors is that they are or-

thogonal"’. Two vectors are orthogonal when their scalar " This is not always the case, but for
the moment we will only work with

roduct is zero. For example, é, -&, = 0 and, in general
P Pie, €x * €y 7m 8 ’ orthogonal basis vectors.

é -€; = Ofori # j. In addition, they are normalized. This
means that the scalar product of such a basis vector with

itself yields one:’? é; - é = 1. ” Again, this is not necessarily the
case. But here, we restrict ourselves
to normalized basis vectors.

This is why we used in Eq. 3.13 that (¥y|¥2) = 0, (Y2|¥1) =
0 and in addition, (¥;|¥1) = 1, (¥2|¥2) = 1.

. Next, we need to talk about the new objects that we intro-
duced above: (¥|. We introduce these bras specifically to
calculate expectation values and concrete probabilities. Ex-
pectation values and probabilities are scalar quantities (i.e.,
ordinary numbers) and not vectors or matrices. So in other
words, bras are tools that we add to our framework in order
to combine them with our kets |") and get back a scalar. The
whole point of bras is that if we combine them with a ket, we
get back a number.

Again, we can better understand this idea by considering
the analogous situation for more familiar, ordinary vectors.
For each such vector, we can define a "dual" vector such that
the product of a vector and a dual vector yields a number.

In other words, vector and dual vector together yield the
scalar product. While a normal vector is a column vector,
the corresponding dual vector is a row vector. Then, with
the rules of matrix multiplication (row times column), a dual

58 NO-NONSENSE QUANTUM MECHANICS

%3 The notion of scalar product
means that we multiply two quan-
tities and get back an ordinary
number. "Scalar" is a different name
for an ordinary number. There are
other ways to multiply objects that
do not yield an ordinary number
like, for example, the cross product.
An alternative name for the scalar
product is inner product.

4 We will see later why this is the
case. For the moment we could say
that we simply want to stay general
and for this reason, include the
complex conjugation which does
no harm if the kets are real. But

to spoil the surprise: Our kets are
complex since kets that describe
physical systems are solutions of
the Schrédinger equation. And so-
lutions of the Schrédinger equation
are, in general, complex.

15 Because for z = a+ ib, we have
z* = a-—ib and therefore

z*z = (a+ib)(a—ib) =a +b
which is real.

vector and a normal vector together really yield a number
(and not another vector or a matrix):

1
ag = (13, 5) 3] =35.
5

A bra is completely analogous to a row vector while a ket is
analogous to a column vector. The idea is that a bra and a ket
together yield a number. In other words, this is a convenient
way to write the scalar product.’3 The transformation that
turns a column vector into a row vector is called transposi-
tion. Similarly, to get the corresponding bra from a given ket,
we transpose it and additionally complex conjugate it. This
conjugation is necessary since kets are, in general, complex.'4
For complex vectors, we need the additional complex conju-
gation because we want to interpret the scalar product of a
vector with itself as the length of the vector squared:

length? =0-3. (3.18)

A complex result wouldn’t make sense. The complex conju-
gation makes sure that we end up with something real. For
this reason, the scalar product of complex vectors is defined
with an additional complex conjugation that makes sure we
end up with a real number.*>

This is also why we defined a bra in Eq. 3.14 as (¥| = [¥)* =
(|¥)*)7, and thus why a* and b* appear in Eq. 3.13.

. Next, let’s take another look at our first calculation of an

expectation value in quantum mechanics (Eq. 3.13) which I
have rewritten here for convenience:

(E| pI¥) = (a Fi] + BY (¥a|) (apr [¥1) + bp |¥2))
= |a)?py (¥1/¥1) +a*bpe (Fi [¥2) +b* aps (FoI¥1)
=1 =0 =0

+ |b po (¥2|¥2)
=1

= |a|*p1 + |b|?p2. (3.19)

THE QUANTUM FRAMEWORK 59

The final result has the structure that we talked about in the
previous section. We weigh each possible outcome (here p;
and p2) with the corresponding probability (here P(p,) = |a|*
and P(p2) = |b|?).

1. The last thing we need to talk about is why our probabilities
are given by P(p,) = |a|? and P(p2) = |b|*. Naively, we
would have guessed that the probabilities of measuring p1
or p2 are merely a and b, respectively. But kets are, in gen-

eral, complex.%® This means that coefficients like a and b are, *6 We will see why this is the case in
in general, complex numbers. Since complex probabilities Section 3.6. As already mentioned

, _. ; ; above, the crucial point is that
make no sense, we can’t use coefficients like a and b directly. physical kets are solutions of the
Instead, we can use |a|* and |b|? which are certainly real. So Schrédinger equation and solutions

of the Schrédinger equation are, in

in particular for our example ket in Eq. 3.11, the probability general, complex.

of measuring p; is |a|? and the probability of measuring p2
is |b|?. The coefficients obtained by expanding a ket in some
specific basis, like a and b from above, are called probability
amplitudes.

With all this in mind, we can tackle another question typically
asked in quantum mechanics: What’s the probability of mea-
suring, say, the value p;? For our simple example above, we
already know that the probability to measure py is |a|?. We are
interested, however, in figuring out how to extract this informa-
tion from any general system. The crucial idea is to use the fact
that the state of the system with definite momentum py is |¥1).
Let’s see what happens when we multiply our state |’) by the
bra that corresponds to |f;):

(HF) 4 (| (a1) +b /¥2) )

2
=1 =0
2

=ax1+bx0=a.

We get exactly the result that we wanted: a. To get the proba-
bility, all we have to do is to square the absolute value of this
result.

60 NO-NONSENSE QUANTUM MECHANICS

This trick always works. A given ket |’) possibly consists of
dozens or even infinitely many terms when expanded in terms
of basis states. But to get the probability of measuring one spe-
cific momentum value, we simply have to multiply it by the
corresponding conjugated basis state, e.g., (¥1|.

What we really do here is to project out exactly the term that we
want from the sum. Since the basis vectors are orthogonal, the
term that survives when multiplied by (‘¥;| is the one that we
are interested in.

This whole procedure is analogous to how we can determine
how much a given vector spreads out, say, in the z-direction. All
we have to do is multiply the vector by the z basis vector @;:

AY
a
I|
we
a
I|
a
fa)
fas)

—
MN”
uw
I|
on

We can make the analogy even more explicit by using the nota-
tion from Eq. 3.17:

=1x04+3x0+5x1=5. (3.20)

3-3. Wave Functions

A question you certainly have at this point is: What does all
this have to do with the waves we talked about previously?
Well, the wave functions everyone is talking about are simply
the probability amplitudes for one specific basis. Again, let’s
consider the arbitrary ket |'¥) that describes our system. But
now, let’s say we are interested in possible locations and not

the momenta. This means that we have to switch our basis and
express |’) in terms of position basis states.

How can we do this?

THE QUANTUM FRAMEWORK 61

The magical tools which help us switch between bases are
called projection operators. These projection operators aren’t
unique to quantum mechanics. Projection operators also exist
for ordinary vectors. In the previous section, we used the most
common basis vectors é;, ey, é, (Eq. 3.16). However, an equally
good (orthogonal and normalized) choice for the basis vectors

is:17 7 The factors i are normalization
constants that make sure that our

1 1 1 1 0 vectors have length 1.
4=——I1), &=—]|]-1], &=|0. 21
VAN) 2 v2NG =| (3.21)

How can we calculate what our vector @ = (1,3,5)? looks like
in this basis? We already discussed how we can determine how
much a given vector spreads out in any given direction. For
example, to find out how much @ spreads out in the z-direction,
we multiplied it by é, (Eq. 3.20). Here, Eq. 3.21 defines new
axes relative to the old ones. Therefore, to find out how much
3d spreads out in the direction defined by @1, we calculate the
scalar product of the two vectors.

a-3= (11,0) =

awn

Analogously, we can calculate how much @ spreads out in the
other two new directions:

T
1 1
a 7 3) = 2

0
3 -3= 0
1

This tells us that, in the new basis he 3.21), our vector @ reads

4
v= —~é; abi + Bie |

as:

Va

SIS

new basis
The general method to rewrite a vector in a new basis is there-
fore:

62 NO-NONSENSE QUANTUM MECHANICS

1. Calculate the scalar product of the vector with each new basis
vector.

2. Multiply each result with the corresponding basis vector.

3. The vector in the new basis is the sum of all terms calculated
in step 2.

So mathematically, we have

Dnew basis = Ve) (@-d) . (3.22)
a number
To convince you that this formula is really correct, let’s again
consider our example from above:

Bnew basis = WONG . a)
i

= (21) (@1 +d) + (@2)(@2- 3d) + (@3) (83 - 9)

=¢, 4.44 2 45% Vv
V2 V2

We use exactly the same method in quantum mechanics. We
have the ket in the momentum basis,

[¥) =a|¥1) +b /¥o) , (3.23)
and want to calculate how it looks like in the position basis:
['¥) = c|x1) +4 |x2) - (3.24)

In other words, we want to calculate the coefficients c and d.
For simplicity, we assume that only two locations, x; and x2, are
possible. In addition, we use a more suggestive notation: |x1)

is the configuration of the system where we will definitely find
our particle at location x,, similar to how |¥;) corresponds to
the configuration with momentum p,. Using the algorithm we
just discussed, we calculate

|¥) = » xi) (xi|'¥)

= |x1) (x1]"F) + |x2) (x2/F)
2 c= (x/¥),d = (x2/¥)
=c|x1) +d|x2),

THE QUANTUM FRAMEWORK 63

where we defined the probability amplitudes in the position
basis

c = (x|¥)
d = (x2|¥).

In general, there is a continuum of possible locations and not
just a discrete set. Luckily, we can take this into account by
simply replacing this sum with an integral:18:

pe) = f dx |x) (xl)
2 (x/¥) = ¥(x)

= [ axe(x) |x), 6.25)

where we defined ¥(x) = (x|¥). This function ¥(x) is anal-
ogous to the coefficients we have discussed previously (i.e., a,
b,c, and d). But we now have one coefficient for each location
x.19 The physical interpretation of ¥(x) is again as a probability
amplitude. To make the connection to our previous notation
explicit, we can write

This probability amplitude ¥(x) has a special name: the wave
function. Completely analogous to what we discussed before, if
we square the absolute value of (x), we get the probability to
find the particle at a given location.?°

78 An integral is, in some sense, the
continuum limit of a sum. If we
make the steps in a sum smaller and
smaller, we end up with an integral.

19 Take note that |") and therefore
also ¥(x) depend on the time t.
Here we suppress this dependence
to unclutter the notation. We will
revisit this time dependence later
on. Keep in mind, however, that
wavefunctions generally depend not
only on position, but also on time.

0 This is not entirely correct. What
we get is the probability to find

the particle within the interval

[x,x + dx], since ¥(x) is defined
under an integral. Thus to get a
probability, we not only have to
take the absolute square but also
integrate over some region. In the
image below, the absolute square of
a wave function at different points
in time is shown. The absolute
square indicates the probability of
finding the particle in question at
different locations. The higher the
amplitude of the absolute square

of the wave function, the higher

the probability. When we are 100%
certain where our particle is, the
wave function of the particle is the
delta distribution (see Appendix C).
In some sense, the delta distribution
can be thought of as an infinitely
thin/localized but also infinitely
high function that, however, yields
exactly one if we integrate it all over
space.

64 NO-NONSENSE QUANTUM MECHANICS

A general rule that is useful to
remember is that bra times ket
yields a number (or function):
(x|¥) = ¥(x). And ket times bra
yield an operator: |x) (x|. This is
analogous to how the usual scalar
product of two vectors yields a
number: 3-#@ = 3'@ € R, while
owt yields a matrix. (Remember
the general rule for multiplying
matrices: "row times column".)

2 Using that (¥| = \y)* (Eq. 3-14)
and

\¥) = / dx¥ (x) |x)
(Eq. 3.25) we find immediately

(¥]) = [a (x| ¥t (x)

Take note that we could equally
write ¥*(x) instead of ¥*(x) since
Y¥ (x) is an ordinary function and
therefore transposing it makes no
difference. Moreover, the symbol
6(x — x’) is called delta distribu-
tion and is for integrals what the
Kronecker delta 6;; is for sums. For
more information, see Appendix C.

(3.27)

The name wave function will make more sense in Section 3.7, in
which we will see that functions like ¥(x) really exhibit wave-
like behavior. One crucial observation is that everything we
need to know about the system is encoded in the function ¥ (x).

This is analogous to how we usually only write down the coef-
ficients of a vector 0 = (1,3, 5)7 without referring to the basis
explicitly: 1é, + 3éy + 5é,. Similarly, we use in quantum mechan-
ics ¥(x) and don’t write f dx¥(x) |x) all the time.

The trick we used in Eq. 3.25 is generally applicable; it works
for any complete basis, not just the position basis. So instead of
expanding our ket |’) in terms of the position basis vectors |x),
we can also expand it in terms of momentum basis states:

re) = [ dp |p) (ol)

= | ap¥(p)|p). 6.26)

The function ¥(p) is known as the momentum representation
of the wave function.

Take note that by comparing the left-hand side with the right-
hand side in the first row of Eq. 3.25, we can conclude that the
operator f dx |x) (x| is the identity operator, ie., an operator
that does not change anything."

Analogously, from the first row in Eq. 3.26, we learn that the
operator f dp |p) (p| is also an identity operator: f dp |p) (p| =
1. This is important since it means that we can always insert

f dx |x) (x| or f dp |p) (p| in our equations without changing
anything. In a moment, we will talk about an example where
this is indeed useful.

An important idea is that by using a given wave function Y (x),
we can immediately calculate important quantities like the
expectation value:??

THE QUANTUM FRAMEWORK 65

(¥O}¥) 2° (16 [ ax¥(x) |x)

> Eq. 3.27
= fax! (x ¥4(2)0 f ae¥(x) |x)

>
= fax! [ax (9a) O4 (9) 9)

>

= / dx! / ax¥* (x! O¥ (x) (x'|x)

> (lx) =4(x-2')
= [ax [axet (x) O¥(x)0(2- x’)

2 fax’ f(x!)o(x x’) = f(x)
- / ax¥* (x)O¥(x). (3.28)

To get to the last line, we used that if we act with O on our
wave function ¥(x), we get a number and that we can move
numbers around freely. In addition, the basic states |x) are
orthogonal and normalized. Therefore, a scalar product like
(x'|x) yields zero except when x’ = x. This is analogous to
how the scalar product between two basis vectors é; - é; yields
zero, except when i = j. So when we integrate over x’, all terms
vanish except for where x = x’. This is what the Dirac delta
distribution 5(x — x’) encodes, similar to how the Kronecker

delta 6;; picks the element from a given sum where i = j.*3 2 The Kronecker delta and the Dirac
delta distribution are discussed in
. ; Appendix C.
We can also perform the same steps as in Eq. 3.28 without the
operator O and with a bra that is different from the ket:
(@/¥) = / dx! (x!| &*(x') / dx ¥ (x) |x) using Eq. 3.25 and Eq. 3.27
2
= / dx! / dx (x!| O*(x')¥(x) |x)
2

_ / dx' / dx &* (x!)¥(x) (x"|x)

> (x"|x) = d(x — 2’)
= [ax [ axo*(x)y¥ (x52 - x)

2 fax’ f(x/)o(x-2') = f(x)
= [axot(y¥). (3.29)

This is how the scalar product of two kets looks if we use an
explicit basis. Note that this is completely analogous to the

66 NO-NONSENSE QUANTUM MECHANICS

24 There are, in fact, two famous
theorems by Emmy Noether that
are relevant in this context. The one
I’m talking about is her first one
that deals with global symmetries.
Her second one is about local
symmetries.

scalar product of two complex vectors in an explicit basis:

BZ = DY (wha) - (zi)
to]

2
= LD Lew zie %
ij
2 Gi Gj = Oi
tJ
2 Lifiby = fi
]

i

Don’t worry if not everything is perfectly clear at this point.
Everything we have discussed here will make a lot more sense
as soon as we discuss explicit examples. Our goal is to get an
overview and not to understand everything perfectly.

Two crucial questions remain unanswered:

[> What do these quantum operators we’ve been discussing
really look like?

> How do quantum systems evolve as time passes?

This is what we will talk about next.

3-4 Quantum Operators

So far, we have talked about quantum operators in quite ab-
stract terms. We simply introduced a symbol f and proposed
that it does the job:

P\¥1) = pi |¥1) - (3-30)

Luckily, there is an important concept that will allow us to move
beyond these abstractions: Noether’s theorem.74

Discussing the theorem in full detail would lead us too far
astray. But all we need is the punchline:

THE QUANTUM FRAMEWORK

Symmetries lead to conserved quantities.

The most important examples:

> If the system does not change under rotations, we know im-
mediately that angular momentum is conserved. In other
words, if we can rotate our system without changing any-
thing, then angular momentum is conserved.

> If the system does not change under spatial translations
x — x +, we know immediately that momentum is con-
served. This means that if we change the position of the
whole system and nothing changes, then momentum is con-
served.

> If the system does not change under temporal translations
t — t+, we know immediately that energy is conserved.
Formulated differently, if the system behaved yesterday ex-
actly as it does today, energy is conserved.

This is one puzzle piece. The second piece we need is how
symmetries are described mathematically.

You are probably wondering what all this has to do with quan-
tum mechanics. As we will see after the next section, actually, a
lot! The mathematical ideas in the next section are exactly what
we need to find the explicit form of quantum operators. Most
importantly, this explicit form allows us to derive the famous
canonical commutation relation, and the Schrédinger equation.

So let’s talk about symmetries in mathematical terms.

3.4.1 Intermezzo: Symmetries

The role and description of symmetries in physics is a huge

67

topic.?5 So there is no way we can cover all the details. How- 5 In fact, I’ve written a whole book

ever, I will try to emphasize the basic ideas that are necessary to 0 &*@tly this topic:

Jakob Schwichtenberg. Physics
from Symmetry. Springer, Cham,
Switzerland, 2018. ISBN 978-
3319666303

68 NO-NONSENSE QUANTUM MECHANICS

6 The identity transformation is the

transformation that changes nothing
at all. For example, for rotations, the
identity transformation is a rotation

by 0°.

understand quantum mechanics.
First of all: what is a symmetry?

Imagine a friend stands in front of you and holds an object in
her hands. Then you close your eyes and she performs a trans-
formation of the object (e.g. a rotation). Then you open your
eyes again. If you can’t tell if your friend changed anything at
all, the transformation she performed is a symmetry of the ob-
ject. For example, if she holds a perfectly round, single-colored
ball in her hands, any rotation is a symmetry of the ball. In con-
trast, if she holds a box in her hand, only very specific rotations
are symmetries of the box. Doing nothing is always a symmetry.

The bottom line is:

A symmetry is a transformation that

leaves the object in question unchanged.

The part of mathematics which deals with symmetries is called
group theory. A group is a set of transformations which fulfill
special rules plus an operation that tells us how to combine the
transformations. The rules are known as group axioms and we
can motivate them by investigating an intuitive symmetry like
rotational symmetry. We will not discuss details like this since
we don’t need them for what follows.

Also, we only need one special part of group theory, namely
the part that deals with continuous symmetries. An example of
a continuous symmetry is the one I just mentioned: rotations
of a ball. Rotations are continuous because we can label them
with a continuous parameter: the angle of rotation. In contrast,
there are also discrete symmetries. The most famous examples
are mirror symmetries.

There is one property that makes continuous symmetries espe-
cially nice to deal with: they have elements which are arbitrarily

close to the identity transformation.”©

THE QUANTUM FRAMEWORK 69

For example, think about the symmetries of a circle. Any ro-
tation about the origin is a symmetry of a circle. Therefore, a
rotation extremely close to the identity transformation, say a
rotation by 0.000001°, is a symmetry of the circle.

In contrast, an arbitrary group has, in general, no element close
to the identity.

For example, think about the symmetries of a square. The set
of transformations that leaves a square invariant comprises four
rotations: a rotation by 0°, 90°, 180° and 270°, plus some mirror
symmetries. But a rotation by 0.000001° is not a symmetry.

Mathematically, we write an element g close to the identity I as:

g(e) =I+€G, (3-31)

™N cA
where € is a really, really small number and G is an object, (L+¢ A = ]
called a generator, that we will talk about in a moment. In the € ¢¢

smallest possible case, such transformations are called infinites-
imal transformations.

Such small transformations barely change anything. However, if

we repeat an infinitesimal transformation many times, we end QG A
up with a finite transformation. e >

VI

Let’s return to our discussion about rotations. Many small ro-
tations in one direction are equivalent to one big rotation in the
same direction.

Mathematically, we can write the idea of repeating a small
transformation many times as follows

h(0) = (I+ eG)(I+€G)(I+ 6G)... = (1+ eG), (3.32)
where N denotes how often we repeat the small transformation.

If 6 denotes some finite transformation parameter, e.q., 50° or
so, and N is some huge number that makes sure we are close to

70 NO-NONSENSE QUANTUM MECHANICS

27 This is one possible definition of
the exponential function. We derive
another definition in terms of an
infinite series in Appendix A.

28 Here 0, is a shorthand notation
for the derivative 2.

29 If you're unfamiliar with the

Taylor series expansion, have a look

at Appendix A.

the identity, we can write Eq. 3.31 as

g(9) =1+ <a. (3-33)

The transformations we want to consider are the smallest pos-
sible, which means N must be the biggest possible number,
ie, N — oo. To get a finite transformation from such an in-
finitesimal transformation, one has to repeat the infinitesimal
transformation infinitely often. Mathematically we can write
this as

=f 8 GN
h(@) = lim (I+ 9G)", (3-34)
which is in the limit N — oo the exponential function?”
_~ i 8 GN _ 0G
h(@) = lim (I+ 7G)" =e”. (3-35)

The bottom line is that the object G generates the finite transfor-
mation h. This is why we call objects like this generators.

What do these generators explicitly look like?
Let’s consider a function f (x,t) and assume that our goal is to

generate a spatial translation such that Tf(x,t) = f(x +a,t).
The generator

Gxtrans = Ox (3.36)

does the job:78
aG a? 2
e trans f (x, t) = (1 + aGxtrans + > Gxtrans +.. F(x, t)

2
= (1+ad_+ a +...) f (x,t)
Here we used the series expansion of e* = DP x. In the last

step, we used that in the second to last line we have exactly
the Taylor expansion of f(x + a,t).?9 Alternatively, consider an

THE QUANTUM FRAMEWORK

infinitesimal translation: a > € with e < 1. We then have

2
e€Cxtrans F (x, t) = (1 + €Gytrans + 5 Gxtrans” +.. f(x, t)
> exe)...
= (1+ €Gyxtrans) f (x,t)
> Eq. 3.36
= (1+ 0x) f (x,t)

>)
= f(x,t) +edxf(x,t) = f(x+e,t). (3.37)

Here 0; f (x,t) is the rate of change of f (x,t) in the x-direction.
If we multiply this rate of change by the distance € that we
move in the x-direction, we end up with the total change

of f (x,t) if we move by e€ in the x-direction. Thus, f(x,t) +
€0, f (x,t) really is the value of f at the location x + e.

The bottom line is: Gytrans = 0x generates spatial translations.

Completely analogously, Gitrans = 0: generates temporal transla-
tions:
f (x,t) 9= efCttrans F (x, t) = f(x,t+a).

What we have learned here is that generators are the crucial
mathematical ingredient that we need to describe continuous
symmetries. We can describe any continuous symmetry by
acting many, many times with the corresponding generator on
the function in question.

So we can summarize:

The core of each continuous symmetry

is the corresponding generator.

This idea is already everything we need to determine explicitly
what the most important quantum operators look like.

3.4.2 The Most Important Quantum Operators

We now put the puzzle pieces together. The pieces we have so
far are:

71

72 NO-NONSENSE QUANTUM MECHANICS

> Weare looking for quantum operators. When we act with,
for example, the momentum operator on the ket |'¥;) that
describes our system, we want to get p|¥1) = pi |¥1).

> Noether’s theorem tells us: there is a deep connection be-
tween symmetries and the most important physical quanti-
ties: momentum, energy, etc.

> Group theory tells us that the essential objects which are
responsible for these symmetries are the corresponding gen-
erators.

The crucial idea is to take Noether’s theorem seriously. Instead
of saying that we get a conserved quantity if there is a sym-
3° Note that there is an additional metry, we say the operator responsible for the symmetry (the
imaginary unit i. This is just a
convention that physicists like to
use. The translation of a function operator).
then works like this: e/Ctans f(x, t).
So all we have done is introduce
two additional i that cancel since In slogan form:
i? = —1. The reason why physicists

like to introduce the imaginary quantum operator + generator of symmetry
unit i is that we want to interpret

the eigenvalues of our quantum

operators as something that we can This may seem like quite a stretch, but we will see that this idea
measure in experiments. Without

the additional i the eigenvalues
would be imaginary. Hence, we
introduce an additional i to make
them real. However, this is really
just a convenient way to make

the framework easier to use. In Momentum is connected to symmetry under spatial transla-

addition, we have an additional . : pe ge
a 30
inus sign for the momentum tions. Therefore, we make the identification:

operator. This is motivated by
the Minkowski metric of special momentum /; + generator of spatial translations (—ihd;)
relativity. However, it is clear that

we could also absorb it into the
parameter e. (3.38)

Analogously, energy is connected to symmetry under temporal
translations. Therefore

energy E <> generator of temporal translations (ifd;)

(3-39)
Take note that we have introduced a new fundamental constant:

generator) also describes the conserved quantity (the quantum

works incredibly well in the next section.

Now, let’s make the above statement explicit.

3‘ This constant already appeared h.3* This constant is known as the Planck constant and encodes
in the formulas for the relationship

between the wavelength and the

momentum and energy (Eq. 2.2 and

Eq. 2.3).

the magnitude of quantum effects.3* We can understand the
need for a new constant by observing that momentum has di-
mensions [p] = kg - m/s. However, 0; has the unit33 [d;] = 1/m.
Similarly, 0; has the unit [0;] = 1/s, while energy has the unit
[E] = kg-m?/s?. Therefore, we need something to get the
same units on the right-hand and left-hand side of the equa-
tions. Using the units of energy, momentum and the differential
operators we can conclude that [fh] = kg - m*/s since34

m ! . m? 1 m
IP) =e = [ihe] = ke RBS
m? 1 |, 24 m2

The Planck constant is one of the most important fundamental
constants and we need to extract its value from experiments:

h = 1.055 - 10-*4 kg - m*/s. Since there is no symmetry con-
nected to the conservation of position, the position operator
stays as is3> £. In addition, using the definition of angular mo-
mentum (L = Xx p), we can, in principle, write down the
angular momentum operator by simply replacing 7 with the
corresponding quantum operator #. However, there is an im-
portant subtlety that this approach neglects. As such, we will
postpone further discussion of this fact until Section 3.10.

Now, equipped with the ideas discussed in this section, we

are able to derive one of the most important equations in all of
physics.

3-5 How Operators Influence Each Other

As already emphasized above, the crucial new thing in quantum

mechanics is the inherent uncertainty. This uncertainty comes
about since the momentum changes every time we measure
position and the position changes every time we measure mo-
mentum. Mathematically, this statement means that it makes
a difference whether we first measure the momentum or first
measure the location: <p |¥) 4 p%|¥). We can also write this

THE QUANTUM FRAMEWORK 73

3? To be precise ht is the reduced
Planck constant (speak: "h-bar")
defined by # where h is the real
Planck constant. The additional
factor 271 makes sure that we really
get the momentum and energy, as
we will see in Section 3.7.

33 Recall 0, = 2 . The symbol dx,

in some sense, simply means a tiny
amount of x and therefore has the
same unit as x. Therefore, 0, « 1/0x
has the unit 1/m.

34 Square brackets around a quantity
means that we are talking about the
units of the quantity.

35 This may seem confusing at first.
But all this operator does if we

act with it on a function f(x) is to
multiply it by x, ie., f(x) = xf (x)
since x really is the location we
evaluate f(x) at.

74. NO-NONSENSE QUANTUM MECHANICS

statement as (Pp — p) |¥) 4 0. The shorthand notation for this
expression is

[A,B] = AB- BA. (3.40)

We usually call this the commutator of A and B.

To get an intuitive understanding for what it means for oper-
ators to have a non-zero commutator, compare the situation
where you first put on your socks and then your shoes with
the situation where you first put on your shoes and then your
socks. The outcome is clearly different — the ordering of the
operations "putting shoes on" and "putting socks on" therefore
matters. In technical terms, we say these two operations do not
commute. In contrast, it makes no difference if you put on your
left sock first and then your right sock or your right sock first
and then your left sock. These two operations do commute.

Now, using the explicit quantum operator p; = —ihd; (Eq. 3.38),
we can actually derive that [p;,£;] 4 0:

(pi, 2] |¥) = (pik; — £;Bi) |)
= (—iho;8; + £;ihd;) |'¥)

= —(ihd;2;) |¥) — 2; (hd PYY) + £,ibB EY

= —ihd; |¥) .

2 Bq. 3-38
> product rule

2 8; = 6

(3.41)

In the last step, we used that, for example, dyx = 0 but dyy =

» The Kronecker delta jj is zerofor 1.36 We didn’t assume anything about |'¥), so the equation is
i # j and one fori = j. If you’re
unfamiliar with it, have a look at . . . .
Appendix C. it, which makes the equation a bit shorter. However, we always

valid for any |¥). Therefore, we can write the equation without

have to remember that there is an implicit ket in such equations
and we are only too lazy to write it all the time. In conclusion:

(3.42)

This little equation is known as the canonical commutation re-
lation. As the name already indicates this equation is extremely

THE QUANTUM FRAMEWORK 75

important. In fact, many textbooks and lectures use it as a start-
ing point for quantum mechanics.37

The canonical commutation relation encodes an incredibly im-
portant property of quantum mechanics: It makes a difference
in which order we measure the position and the momentum!
This is exactly the quantum uncertainty we talked about pre-
viously.38 In physical terms, it means that we can’t measure

the position and the momentum of a particle at the same time
with arbitrary precision. We can now also understand how this
comes about in our framework. We identified the momentum
operator as the generator of spatial translations (Eq. 3.38). Thus,
each time we measure the momentum, we perform a tiny spa-
tial translation. Therefore, what we’ve discovered here is exactly
what we discussed already in Section 2.3, namely that each time
we measure the location of an electron, we have to push it a
little bit with a photon.

The next cool thing we can do using the explicit quantum oper-
ators is to derive how quantum systems change in time. This is
described by the second most important equation of quantum
mechanics, which we will discuss in the next section.

3-6 How Quantum Systems Change

So far, we have treated quantum systems as if they were static.
In the real world, however, systems generally change over time.
Therefore, we need something that allows us to understand how
a quantum system evolves as time passes. Mathematically, what
we need is an equation of this form:

a|¥) =...

Here, 0; |'¥) is the rate of change of |) if we move with respect
to t. In other words, 0; |‘) describes how |) changes as time

37 Formulated differently, many
textbooks use this equation as the
fundamental postulate of quantum
mechanics. For example, using this
equation, we can derive what the
momentum operator looks like etc.

38 We talked about the quantum
uncertainty in Section 2.3. The con-
nection between the commutation
relation and uncertainty can be
made mathematically precise. Using
mathematical results such as the
Cauchy-Schwartz inequality and the
explicit definition of the standard
deviation it is possible to derive for
two general operators A and B the
following equation

(aA)?(A8)? > 15-14 B)L,
where AA and AB are the standard
deviations of the two operators.
Therefore, using Eq. 3.42 we find

(ap)*(A2)? > | ([pa))| = 8.

A measurement without any vari-
ance would mean Af = 0 plus

Az = 0. This equation tells us that
this is impossible. It’s impossible
to measure the position and the
momentum of a particle at the same
time with arbitrary precision. If we
reduce, for example, the variance
in our position measurements, we
automatically get a larger variance
in our momentum measurements.

76 NO-NONSENSE QUANTUM MECHANICS

39 The index i is necessary because,
in general, we are dealing with
systems that can change in 3-spatial
dimensions. The index takes on the
values i = {x,y,z} or equivalently
i= {1,2,3}.

4° If there is more than one dimen-
sion, we have 2;.

passes — exactly what we need! On the right-hand side, we
need something that contains specific details about the system
in question. Thus, the right-hand side will be different for each
system. Then, as soon as we have such an equation, we have to
solve it to understand how |¥) depends on t.

Luckily, we don’t have to guess. All we have to do is take a sec-
ond look at what we derived in the previous section. The main
actor here, 0, is almost exactly the quantum energy operator
iho; (Eq. 3.39), only without the imaginary unit and Planck’s
constant. Therefore, we know that we have the energy on the
right-hand side of the equation:

iho; |¥) = E|¥) .

Is there anything else we know about energy?

In classical mechanics, the total energy is given as the sum of
kinetic energy and potential energy:

E=T+V= kineticenergy + potential energy. (3.43)

The usual formula for the kinetic energy is

1

T= 5m = 7 (3-44)
since p = mv. We can turn this equation into a quantum equa-
tion by replacing the classical momentum, p, with the quantum
momentum operator, fp; = —ihd;, which we derived above.39
The potential energy usually only depends on the position:
V = V(x). Therefore, we can turn it into a quantum operator by
letting x — £.4°
Returning to our equation,

ihd, [¥) = E|¥),

we can use the usual formula E = T + V and replace the classi-

THE QUANTUM FRAMEWORK 77

cal variables with the corresponding quantum operators:

ihd, [¥) = E|¥)

2 Eq. 3-43
=(T+V)|¥)

_ P ro) py Eq. 3.44
(F+vm)

» _ introducing operators

a2
=> hd |¥) = (5 + vi) I)
> Eq. 3.38
- ( +v(e)) l¥)
2

The resulting equation,

h
ihdy|¥) = — SE |¥) + VCR) IY) ,

(3-45)

is the famous Schrédinger equation. Our main job in quantum
mechanics will often be to solve the Schrédinger equation for a
given potential V(x) and specific boundary conditions.

We will discuss the most important quantum systems in Chap-
ter 5. Note that for historical reasons, the energy operator on
the right-hand side of the Schrédinger equation is known as the
Hamiltonian operator,

; hd? ;
H= (= +V(%)]. (3.46)
The more general form of the Schrédinger equation,
iho; |¥) = Al) (3.47)

is valid even for relativistic systems and quantum field theories.

All we have to do is modify AH appropriately.4

4 In fact, we can simply replace the
classical energy-momentum relation
(E = Fy with the relativistic
version ( E? = (pc)? + (mc?)?).
Then again we replace p with the
corresponding quantum operator
and end up with an equation

that describes how relativistic
quantum systems evolve in time.
The resulting equation is known

as Klein-Gordon equation and is
the correct equation of motion for
(spinless) relativistic particles.

78 NO-NONSENSE QUANTUM MECHANICS

A convenient alternative way to describe the time-evolution of
quantum systems is with the so-called time evolution operator
U(t). We define this operator through the following formula

|'F(x,t)) = U(E) |¥(x,0)) . (3-48)

In words, this means that if we act with this operator on some
ket |‘¥(x,0)), the resulting ket describes the system at time f:
|¥(x,t)). This operator is not merely an abstract thing. We can
write it down explicitly by putting Eq. 3.48 into our Schrodinger
equation:

iho, |¥ (x, t)) = H|¥(x,t))
> Eq. 3.48
iho,U(t) |¥(x,0)) = HU(E) |¥(x,0)) .

This equation holds for any |'¥(x,0)) and we can therefore write
it without it:

ihd,U(t) = HU(t)

uty

This is a differential equation for U(t) and the general solution

ih

is

U(t) = eh Joa) (3.49)
since
. 0;U(t) _
ih u(t) =H
2
yeh Jo HHH)
eof Ig at H(t)
2 Eq. 3-49
F t _i rt #’)
ih -= 2: | dt'H(t') | ——_——~ =H
h 0 _1 t t')
—s
2
H=H Vv

So the time-evolution operator is simply a convenient way to
write the information encoded in the Schrédinger equation a bit
differently.

THE QUANTUM FRAMEWORK 79

We can now answer one additional question: Where in the
quantum framework can we see that quantum mechanics is
about waves?

Actually, by looking at the Schrédinger equation! The crucial
point is that the Schrédinger equation is a wave equation. This
means that its solutions behave like waves. We will see this
explicitly for the simplest kind of system in the next section.

3-7. Why Quantum Mechanics is About Waves

Let’s consider a quantum system without any potential (V(%) =
0). The time evolution of the system is described by the equa-
tion

re
Eq. 3.45 with V=0: iho; |¥) =

¥).

Before we solve this equation, we should choose a specific ba-
sis to make things simpler. For this example, we will use the
position and therefore the wave functions that we introduced
in Section 3.3. Also, to unclutter the notation, we will restrict
ourselves to one spatial dimension. We are then left with

242
ind, |'¥) = -= O= bp)
2 Bq. 3.25
inde f dxp(x,t) |x) = t) |x)
2
re
iho, (x,t) = t).

This is a legitimate approach, as long as we remember that
(x,t) is defined under an integral. Hence, it describes a den-
sity. Since the coefficients in front of the kets are probability
amplitudes, the wave function (x,t) is a probability ampli-
tude density. To get probabilities*?, we have to take the absolute
square and then integrate it over some spatial region. The result

Sy
Figure 3.1: Time evolution of a
plane wave. Since, in general, a
wave function is complex and
therefore hard to visualize, only the
real part is shown.

ARM OI

Figure 3.2: Time evolution of a wave
packet. Again, only the real part is
shown.

” After all, probabilities are what
we really can measure in experi-
ments.

80 NO-NONSENSE QUANTUM MECHANICS

43 If you wonder why this is the
case, remember Euler’s formula:
e* = cos(x) +isin(x). The well-
known cos(x) and sin(x) are os-
cillating functions that perfectly
describe waves. In other words,
the real and imaginary parts of a
function proportional to e'* describe
an oscillation that spreads out all
over space with equal amplitude.
(Hence the prefix plane wave.)

Figure 3.3: Construction of a wave
packet as a superposition of plane
waves.

we obtain is the probability to find the particle in the region that
we integrated over. One solution to this equation is

p(x, £) = e HEtpx)/h (3.50)
since
no?
ihdyp(x,t) = Fm be #)

oo 2 Eq. 3.50
LA ox e(Et—px)/h

ihdpe Et px) /h _
2m

> d,eP* = ipe'P*

2,
PY i(Et—px)/h

—i(Et—px)/h _
Ee om

PP -i(Et—px)/n PP -i(Et—px)/n J

om = on , (3.51)

where in the last step we used the fact that E is just the nu-

2
merical value for the total energy of a free particle: E= F. A
function of the form e~(£t-?%)/f is known as a plane wave.43

An important observation: the Schrédinger equation is linear
in . This means that we don’t have any terms like #, w® etc.
A direct consequence of this property is that if we have two
or more solutions 1, 2, ..
additional solutions:

., we can immediately write down

Ysup = af, + by. +... (3-52)

This is known as a superposition. We can see that a super-
position is also a solution by putting it into the Schrédinger

equation (Eq. 3.47):
A Psup = ihorPsup (this is Eq. 3.47)
d Eq. 3-52

Hay, + bia +...) = iho: (ap, + bp. +...). (3-53)

The functions 1, 2, 3,... are solutions, which means

Ay, = Ey, Hippo = Est, (3.54)

and

hor, = Eyy~1, thos. = Eoypr. (3.55)

THE QUANTUM FRAMEWORK 81

Putting this into our equation above for the superposition
(Eq. 3.53) yields
Hayy + bya +...) = ihd: (ap, + by +...)

2
— aH, + bHy2 +... = aihds, + bihdyypy +...

this is Eq. 3.53

> Eq. 3.54, Eq. 3-55

aE; + bEgp2 +... = aE, + bDEg~2 +... V

Thus, the linear combination sup = a1 + bi. + ... is really a
solution, too.44

This observation is important since we can construct wave pack-
ets through suitable linear combinations of plane waves.

One possibility is a Gaussian wave packet, where A() is a
Gauss distribution:49

Yowp(X,t) = [apap eon
= / dp poei(P-P)? /40° gil PE—-Et)/f

You can see an example of such a Gaussian wave-packet in the
margin.

A wave packet is what we use to describe a particle which is lo-
calized within some region. By “localized within some region",
we mean that we have some idea of the particle’s location. In
contrast, if we know nothing about a particle’s location, it could
be anywhere and hence the corresponding wave function is not
localized but spreads out all over space. Such a situation can

be described by a plane wave which spreads out all over space
with equal amplitude. But for real particles that we want to de-
scribe in experiments, we always have at least some idea where
they are located. Hence, only suitable linear combinations of
plane waves (wave packets) are useful to describe real particles.

Take note that solutions of the Schrédinger equation are complex
functions. Therefore, as promised above, we can understand
that physical kets are generally complex.4® This explains why
we need to take the complex conjugate of physical kets to con-
struct the corresponding bras. In addition, it is important to

4 Again: This only works because
there is no term y or #. In other
words, because the Schrédinger
equation is linear in . If you don’t
believe this, try to do the same
calculation with an additional
term y or y in the Schrodinger
equation.

45 Again, we imagine that an in-
tegral is something like a finely
grained sum.

46 A physical ket is one that is
a solution to the Schrédinger
equation.

82 NO-NONSENSE QUANTUM MECHANICS

47 Reminder: A = i and E = hv.

4 Recall that ft is the reduced Planck
constant defined by h = h/2z.

We can understand here why we
introduced this new constant with
an additional factor 277.

remember that solutions of the Schrédinger equation only rep-
resent probability amplitudes. To get probabilities, we have to
take the absolute square of them.

Another thing we can now understand is the relations in Eq. 2.2

and Eq. 2.3.47 In general, a plane wave has the form: Ae +t,
where A is the wavelength and w is the angular frequency of
the wave. Comparing this with our solution to the Schrédinger

equation in Eg. 3.50 (¥ = e!(P*—F#)/*) tells us that4®

27. P
Ah
D)
_ hn
p= A h
h ° "2
~ 4°
We also find that
wat
hh
D)
E=hw
> w=2nv
=hv,

where v is the "ordinary" frequency of the wave, while w is the
angular frequency.

Before we move on, we should talk about one concept (which
we have already used several times) in more detail.

3.8 Intermezzo: Eigenvectors and Eigenval-
ues

The concepts of eigenvalues and eigenvectors are used through-
out the world of quantum mechanics. The eigenvectors, @, and
eigenvalues, A, of a matrix, M, are exactly those vectors and
numbers that fulfill the equation

Mt = Az. (3.56)

The important thing is that we have exactly the same vector 0
on both sides. This means that the vector @ remains, up to a
constant A, unchanged if we multiply it by the matrix M. For
each eigenvector, we have a corresponding eigenvalue.

This is just a definition. Why should we care about eigenvalues
and eigenvectors?

Two reasons:

t> We can describe rotations with rotation matrices and the
eigenvector of a given rotation matrix is exactly the rotational
axis.

The structure
operator x vector = number x same vector

is exactly the structure that we use in quantum mechanics.

A matrix is an operator just like the quantum operators we
talked about above.49 The bottom line is that eigenvectors are
the states with definite values for the physical quantity repre-
sented by the operator. For example, if |") is an eigenvector
of the momentum operator p, we have: p |¥1) = pi |'¥1).>°

The corresponding eigenvalue p; is the value that we mea-
sure. Many operators in quantum mechanics are not repre-
sented by matrices, but by differential operators.51 However,
the structure O |¥) = o|¥) is completely analogous. If O is
a differential operator, the only thing that changes is that the
eigenvectors become eigenfunctions.

There are sophisticated algorithms to calculate the eigenvectors
and eigenvalues of a matrix or the eigenfunctions of a differen-
tial operator. But a full discussion would lead us too far astray.
You can find a full description of these algorithms (at least for
matrices) in any linear algebra textbook.5?

Now it’s finally time to return to the angular momentum opera-
tor, as promised at the end of Section 3.4.

THE QUANTUM FRAMEWORK 83

49 We will talk about a quantum
operator that is indeed represented
by a matrix in the following section.

5° Note that a general ket is not
an eigenvector of the momentum
operator. For example:

[¥) =a|¥1) +b[¥2)
=> p\¥) = ap [¥1) + bp |¥2)
= apy [¥1) + bp |¥2)
# c(a|¥1) +b [¥2)).

The crucial observation is that we
don’t have the same vector on the
left-hand and right-hand side. We
can’t write ap, |¥1) + bp2 |¥2) as
some number times the original
vector (a |'¥1) + b|¥2)) since, in
general, p; # po.

5 Think: something with a deriva-
tive such as 0,. Examples are the
momentum operator —ifdx or the
energy operator iho.

5 The part of mathematics that
deals specifically with these kinds
of problems is known as spectral
theory.

84 NO-NONSENSE QUANTUM MECHANICS

-

L=XxP

“7
—~

rd

as

54It is convenient to write the
operator in index notation. In

index notation, the cross product

A x B reads as €;;,AjB;, where ej
is the Levi-Civita symbol. For the
definition of the Levi-Civita symbol,
see Eq. 2.

55 Explicitly this equation reads,

for example, [L,, Ly] = ih, and
[Ly, Le] = iby and (Lz, Lx] =
inLy. To calculate this you have to
remember that there is an implicit
ket |'¥) behind each term which we
are too lazy to write all the time.

3.9 Angular Momentum

In Section 3.4.2, I mentioned that the angular momentum op-
erator follows directly from the classical angular momentum
L = x x P if we replace j with the corresponding momentum
operator —ihd.

In addition, we learned in Section 3.5 that the order in which we
measure position and momentum affects the outcome. This cu-
rious property of quantum mechanics is encoded in the canoni-
cal commutation relation (Eq. 3.42)°3.

We can find a very similar relation for the angular momentum
operator. Using the explicit form of the angular momentum
operator,>+

Lj = eign jPr
> Eq. 3.38
= € ij j(—ihd,)
= — ihe jj jx,

we can calculate the angular momentum commutation rela-

tion:>>
[Li, Lj] = ihe jh

This equation is also known as the angular momentum al-

(3-57)

gebra. The crucial point is that measurements of the angular
momentum along different axes affect each other. In particular,

a measurement of the angular momentum along the x-axis af-
fects the angular momentum along the y- and z-axes. This is

in contrast to the momentum and location operators, wherein
measurements along different axes do not affect each other since,
for example, 0,y = 0 and 0,0, = dy0x.

In practice, this means that we can’t determine the angular mo-
mentum of a given particle along different axes with arbitrary
precision. Each time we measure it along one axis, we lose in-
formation about the angular momentum along other axes.

However, the craziness of angular momentum in quantum me-
chanics does not stop here. Next, we'll talk about an important
subtlety of the angular momentum operator in quantum me-
chanics. As we will see in a moment, this subtlety leads us to a
new and incredibly important quantity. Unfortunately, the full
story is far too long to include it here. If you are interested, you
can find all of the details in my book "Physics from Symme-
try".>© The following section will only sketch the full story.

3-10 Spin

For many systems, we can use the "naive" operator obtained
by using L = x x f and replacing jf with —ihd. The resulting
operator is exactly the generator of rotations. For example, let’s
say we have a function f(%) and want to describe it in a rotated
coordinate system. We can achieve an infinitesimal rotation as
follows:

f(#) > (1+eL)f(X).

However, this is not always the full story.

Sometimes, we need to describe our quantum systems with
objects that have more than one component:>7

Yy (x , t)
¥(x,t) = .
A) (se )
A crucial point is that each component of these objects is a

function of x and t. This means that acting on such objects with
symmetry generators results in two things:5®

1. On one hand, they change the spatial and temporal coordi-
nates x —> 1+ Gx, where G denotes a generator. This is ex-
actly the kind of transformation we talked about previously:
¥(x) > ¥(x + €) (Eq. 3.37).

2. But on the other hand, transforming multi-component objects

can also mix these components:

THE QUANTUM FRAMEWORK 85

56 Jakob Schwichtenberg. Physics
from Symmetry. Springer, Cham,
Switzerland, 2018. ISBN 978-
3319666303

57 Think: like a vector. The reason
why we need such objects with
more than one component is that
they are necessary to describe cer-
tain quantum systems. For example,
you maybe already know that elec-
tromagnetic waves can be polarized.
This means that there are internal
degrees of freedom and we there-
fore need objects with more than
one component to describe them.
As already mentioned above, elec-
tromagnetic waves are transmitted
by particles (photons) and therefore
we need objects with several com-
ponents to describe these quantum
particles. We will talk about another
example in a moment.

58 For the other operators there is no
such subtlety since translations do
not mix components.

86 NO-NONSENSE QUANTUM MECHANICS

59 An example: We want to look

at a vector with four components
Ao
Ay
Az
A3
perspective. Formulated differently,
we want to describe it in a rotated

coordinate system. The result could

Ay = from a different

Ag
oa , Ay
be something like Ay = Al =
A3
Ao
~A2 | | 4! and A, describe th
A, | 4 u describe the

As
same field in coordinate systems
that are rotated by 90° around the z-
axis relative to each other. Through
the transformation the components
get mixed.

6 Think: Something with a deriva-
tive 0; in it.

® Orbital angular momentum is an
important quantity, for example,
when an object revolves around a
second one. Think: Earth and the
sun.

® Think along the lines of a spin-
ning ball, although you shouldn’t
take this picture too seriously. This
is in contrast to orbital angular
momentum which only exists when
two objects revolve around each
other.

®3 The correct name for the two-
component objects that we deal
with in quantum mechanics is
spinors. Spinors are somewhat
strange objects and not simply
two-dimensional vectors. However,
a full discussion and a derivation
of these generators is too long to
include it here. If you’re interested
you can find all the details in my
book "Physics from Symmetry".

Y¥1(x,t) Y2(x,t)
(see ) ~ (Fe )

The most familiar example is when we rotate a vector. Under

a rotation, the vector components get mixed.59? And when the
components depend on the position x, these functions are modi-
fied, too.

The generator that causes the mixing of the components is a
matrix. The generator that causes the rotation of the argument
of a function is a differential operator.®°

Our goal is to find a general quantum operator that describes
angular momentum. Identifying the quantum operators for en-
ergy and linear momentum (and the corresponding generators)
was relatively straightforward.

However, we now have a generator composed of two parts.
Which part is the correct one?

Actually, both! For the angular momentum that we know from
classical mechanics, the naive operator I, = ¥ x (—ihd) is correct.
To avoid confusion, this type of angular momentum is referred
to as orbital angular momentum. The second, equally im-
portant operator is identified with the generator responsible
for mixing the vector’s components (i.e., a matrix). Since both
quantities are required when we consider rotations, they can’t
be too different. In fact, the quantity described by this second
operator is commonly interpreted as internal angular momen-
tum, or spin.®? The total angular momentum of the system is
simply the sum of the orbital angular momentum and the spin.
Specifically, the correct generators of spin for two-component
states®3 are

(3-58)

™1= ¢ ; , Q= (‘ 0) , 3= ( ‘) - (3.59)

THE QUANTUM FRAMEWORK 87

Here we use the labels 1, 2, and 3 instead of x, y, and z. For

example, the operator $3 reads

, hh h 0
S-5n-(3 “

The corresponding eigenvectors are

(3.60)

(3.61)

with eigenvalues A and — A respectively. These eigenvectors
are our basic spin states. The eigenvalues are the values that we

measure. Let’s say our system is in a state described by

¥(2,1) = ("5")

(3.62)

and we want to measure the spin in the 3-direction. Therefore,

we calculate

_ fh (p(xt)
~2\ 0 ]°

This is exactly the structure we talked about in the previous
sections. We act on the object that describes our state with the
operator and get back what we will measure in an experiment.
In this case, we would measure the value f/2 for the spin in the

3-direction.

Systems are usually in a superposition of different spin states.
A convenient notation is |) for the state with spin h/2 and |{)
for the state with spin —h/2.°4 A general state can therefore be 6 The state with spin f/2 is usually

expressed as

|¥) =a|t)+bll).

As before, the coefficients a and b are directly related to the

called "spin up" state and the state
with spin —h/2 "spin down’ state.

probability of obtaining spin values of h and — LF respectively®S 6 Explicitly, |a|? is the probability

of measuring f/2 and |b|? the
probability of measuring —h/2.

88 NO-NONSENSE QUANTUM MECHANICS

The most famous quantum exper-
iment is the double slit experiment
that we already talked about in
Section 2.1.

° Historically silver atoms were
used for technical reasons. The
angular momentum of silver atoms
depends dominantly on the angular
momentum of a single electron.
Since an experiment with sin-

gle electrons was too difficult at
the time, this was the next best
thing they could do. Nowadays,
physicists are able to repeat the
experiment with single electrons.
The result is the same.

Now comes the crucial point.

In contrast to the classical mechanics regime, under which an-
gular momentum can assume any value, quantum mechanical
spin can only take on one of two values. Either we measure the
value #/2, or we measure the value —f/2. There is nothing in
between. In other words:

Spin is quantized!

Historically this was a huge surprise for every physicist. The
quantization of angular momentum was discovered experi-
mentally and not predicted by any theorist. The discovery was
made by the second most famous quantum experiment:® the
Stern-Gerlach experiment. The experimental setup is shown

=

Classically, we would expect a continuous distribution of atoms
on the screen since particles with different spin alignment,
relative to the magnetic field, get deflected differently. But what
was observed is that the atoms ended up in just two distinct
regions. This indicates that only two spin orientations relative to
the magnetic fields are possible.

Today, with the power of hindsight (and a more complete un-
derstanding of quantum mechanics), this result is no longer
completely mysterious. As we have seen above, this result can
be derived using techniques similar to those we used to derive
other quantum features.

THE QUANTUM FRAMEWORK 89

However, this is not the only curious property of spin. We al-
ready learned that measurements of momentum and location
along the same axis affect each other. We also learned that mea-
surements of angular momentum along different axes affect each
other. Now we should check to see how repeated spin measure-
ments along various axes affect the outcomes we obtain.

Mathematically, these properties are encoded in the canonical
commutation relation (Eq. 3.42)° and the angular momentum

commutation relation (Eq. 3. 57)°9.

Using the explicit matrices for the spin operators (Eq. 3.58), we
can calculate the commutation relations as:

(3-63)

For example, we have

($1, $2] = 281

—§

h ch
2\ {9 iz
0) \i# 0

Wy»
fang
Y
N

|
7 NI fon)
Nis O
o |
~
Nast =
N 7 Ns
aN
Nis ©
oO NIE
NLS

> matrix products

I|
| aN
— o as,
FO Ne
Ne

lI
a
oN

|
ye >
Ne

2 Eq. 3.58, Eq. 3.59

= ihS3

») €12% = 0 except for k = 3
= the yo%5,

)
= ihe 47353

€;j denotes the totally antisymmetric Levi-Civita symbol.

Reminder: [p;,£;] = —ihd; and the
square brackets denote, in general,
commutators: [A,B] = AB — BA.

A commutator encodes if it makes

a difference if we first apply B

and then A or first A and then B.
Formulated differently, a non-zero
commutator indicates that it makes
a difference in what order we apply
two operators.

6 Reminder: [2,;, Lj) = ihejxL.

90 NO-NONSENSE QUANTUM MECHANICS

” This is what the angular momen-
tum commutation relation (Eq. 3.57)
and the canonical commutation
relation (Eq. 3.42) tell us.

The general commutation relation in Eq. 3.63 is known as the
spin algebra. It tells us, for example, that it makes a difference
whether we first measure the spin in the x direction and then
in the y direction or the other way round. Take note that this
relation is completely analogous to the angular momentum
algebra, which provides additional evidence that spin is some
type of angular momentum. We will talk a bit more about spin
in Section 10.1.

An important side-note is that not every object has spin. How-
ever, almost all elementary particles have a non-zero spin. The
only exception is the recently observed Higgs boson. For elec-
trons (and also, for example, protons, neutrons or quarks),

we need two-component objects. We say they have spin 1/2,
for reasons that we will discuss in more detail in Section 10.1.
Other elementary particles (photons, for example) have spin 1,
and we need four-component objects (four-vectors) to describe
them. The corresponding spin operators that allow us to extract
the spin values of photons are therefore (4 x 4) matrices.

So what we have learned in the previous sections is that in
quantum mechanics, it’s impossible to know the location and
the momentum at the same time with arbitrary precision. More-
over, we have learned that we can’t know the full angular mo-
mentum vector I. = (Lx, Ly, L,)', since each time we measure
one component, we lose information about the other compo-
nents.7°

Thus, we have to be a bit more careful in quantum mechanics
which quantities we use to describe our systems and this is
what the next section is about.

THE QUANTUM FRAMEWORK

3-11 Quantum Numbers

In classical mechanics, we simply use a vector L = (Ly, Ly,Lz)?
to describe the angular momentum of an object. Similarly, we
usually specify the location and the momentum of objects to
describe them. In quantum mechanics, we can’t know Ly, Ly
and L; at the same time with arbitrary precision. At most, we
can know one of them precisely. We pick just one component

of the angular momentum and use it to specify the state of our
system. Conventionally, we choose Lz. There is no physical
reason behind this since it is completely our choice what we call
the z-axis and what the x-axis or y-axis.

However, it turns out that there is a bit more we can know
about the angular momentum of a given system. We can also
measure the total angular momentum in addition to one com-
ponent! Classically, the length of the angular momentum vector
(squared) is given by [? = L2 + Li + L2. This quantity tells

us the total magnitude of the angular momentum vector. The
corresponding quantum operator is defined analogously

P=f+i+ti. (3.64)

This quantity is important because we can measure it without

affecting the individual components. Again, this property is

encoded in a commutation relation: [27,£;] = 0. In words, this

means that we can know [? and one [; at the same time with

arbitrary precision”’. 7! Mathematically, we say that £2
commutes with Ly, Ly and Ly.

So to summarize, we specify the angular momentum of a given

quantum system using the z-component of the angular momen-

tum, L,, and the total angular momentum, £2. It is conventional

to use the label m for the angular momentum in the z-direction:

L, |m) = hm |m)
and the label / for the total angular momentum:7? 7 Don’t let yourself get confused
why we have /(/ + 1) instead of
217, _ #2 simply /. There is a long story
L ) =h I(1+1) 1) : behind this, but it’s mainly just a

convention.

g1

92 NO-NONSENSE QUANTUM MECHANICS

73 For example, for the hy-
drogen atom we have E, =

1 e 2 1 fe 4
_ 7 Me Tregh 3 or fora parti-
n2 nh?

cle in a box we have E, = "357 --

74 We have these additional labels
since the spin operators commute
with the angular momentum
operators [$;,2;] = 0. In other
words, we can measure the orbital
angular momentum and spin at the
same time with arbitrary precision.

75 Take note, for example, that the
wave functions we discussed in
Section 3.3 are only functions of x
and t. However, we can switch the
labels through a Fourier transform.
The result of such a transformation
is a ¥(p,t), i.e., a wave function that
only depends on the momentum.
For more on this, see Appendix B.

In addition, the energy operator H often commutes with L, and
£2, so we can use it as a third label. The conventional label for
the energy eigenvalues is n.73

So in summary: We often label our states using the three la-
bels m, 1 and n: |n,m,1l). Labels like this are known as quantum
numbers. It is somewhat an art to pick the right quantum num-
bers for a given problem. However, the basic task is always to
find operators that commute with each other, [A,B] = 0, since
precise and simultaneous measurements are only possible if the
operators commute.

The whole business becomes even more complicated if we are
dealing with a particle with spin. Then, we have in addition
to the labels above an additional label for the spin in the z-
direction and one for the total spin.”4 In addition, for some
systems, it is important to determine the relative contributions
of the spin and orbital angular momentum to the total angular
momentum.

Similarly, we have to decide between position and momen-
tum labels since [p,%] # 0. Our choice always depends on the
problem and experiment at hand. Sometimes we pick the mo-
mentum and sometimes the location. However, we can never
use both labels at the same time.75

Next, we turn to an important question that remains unan-
swered: how is quantum mechanics connected to classical me-
chanics?

Both yield excellent results which agree with what we observe
in nature, however for different kinds of systems. Quantum
mechanics describes the behavior of elementary particles,
whereas classical mechanics describes how macroscopic ob-
jects behave. But a macroscopic object like a ball also consists of
(many, many) elementary particles. So it therefore must be pos-

THE QUANTUM FRAMEWORK 93

sible to derive the laws of classical mechanics using the laws of
quantum mechanics by averaging over many many elementary
particle systems. This is what the next section is about.

4

The Classical Limit

As indicated at the end of the previous chapter, there must be a
connection between quantum mechanics and classical mechan-
ics since classical objects consist of many many quantum objects
(e.g., electrons). We already know the most important concept
that allows us to average a large number of elementary parti-
cles: the expectation value. And this is simply a reformulation
of the idea that we need here. The following statement for the
momentum expectation value is exactly Newton’s second law of
classical mechanics*

p[¥) = — (¥axV(2

(4-1)

This equation is known as Ehrenfest’s theorem. We will discuss
below why it is true. In words, this theorem tells us that the
quantum mechanical expectation values obey Newton’s classical
equations of motion.”

Now, let’s derive Eq. 4.1. We start with the expectation value for
a general operator O (Eq. 3.28)3

(¥IO|¥) = [ Pxvroy.

t Recall that the definition of a force
is F(x) = —d,V(x) and Newton’s
second law is F = &p = &:mv = ma,
at least if the mass m is constant.

(A system where this is not the

case is, for example, a rocket which
progressively gets lighter through
the burning of fuel.)

? Strictly speaking, this is not
always true. It is only correct for
simple systems where for the
potential we have (¥|0xV(2) |¥) =
0xV((¥|2#|¥)). This equation is
true for potentials that are at most
of second order in x. If the potential
contains higher order terms like x?
etc. we can see immediately that it
is no longer correct:

V =a+bx+cex* + dx?
OxV = b + 2cx + 3dx*
(0,V) = (b+ 2cx + 3dx*)
# b+ 2c(x) + 3d(x)?.

We already learned in Section 3.2
that it makes a huge difference
whether we square an expectation
value: (x)? or if we calculate the
expectation value of a squared
quantity: (x2) 4 (x)! For example,
for (x?) we only sum over positive
values since we squared them, while
for (x)? there are also negative
values in the sum and we only
square the result of the sum. In
contrast, if the potential is of second
order in x we have no such problem
since in 0,V no term proportional to
x? appears.

For systems with higher order
potentials our Eq. 4.1 is only valid
for small excitations in a region
of the potential where we can
approximate it by a polynomial
which is at most second order in x.

3In this chapter, we consider the
general case with three spatial
dimension. Hence we have d°x in
the definition of the expectation
value instead of dx, which we used
in the one-dimensional case.

96 NO-NONSENSE QUANTUM MECHANICS

In addition, we need the Schrédinger equation (Eq. 3.47) :

d 1

and the complex conjugated Schrédinger equation

yt = a¥tHt this is (Eq. 4.2)
1 > Ht=H
=-=¥9'H, (4:3)

ih
Taking the time derivative of the expectation value then yields

d

» df ga wte
“(0) = 4, [ ex¥to¥

d A d »
_ 3 t +t
= fa «(Groves (5) *
af(ad
t —
+¥0(4) ).

Next, we use 40 = 0, which is correct for many operators. For
example, forO = p = —ihV # O(t). In addition, we use the
Schrédinger equation to rewrite the time derivatives of the wave

> product rule

function and its complex conjugate. This yields

46) — fax ((49*) oye (46) ¥a¥0(4
gO) = [x (Ga) Ove Y (5:0 ¥+¥0 (Sy

£0=0
d—s\ » a/d
_ 3 4 wt t a
= fa “(Ge )ovey o(5%))
1 1 > Eq. 4.2, Eq. 4.3
= [ex ((-3¥"#) O¥+¥t6 (a) )
ih ih
1 p)
=| [| @x(-¥HOY + ¥'OHY)
1 p)
=5 / &x¥* (6, H]¥
p)

- =((0, H]). (4.4)

THE CLASSICAL LIMIT 97

Since we have derived the expression for the expectation value

(Eq. 3.28) , we can express this more concisely:4 4 Recall that in general, the com-
mutator of two operators yields a
d,s 1a generator. For example, the com-
dt (O) = ih ({O, H]). (4-5) mutator of the momentum and
position operator yields the trivial
Now we can evaluate this equation specifically for the mo- identity operator: [f;,2;] = —ihé;

. ae . (Eq. 3.42), or the commutator of the
mentum operator and, in addition, use the explicit form of the spin operators yields another spin
Hamiltonian operator: operator: [5;, 5] = ihe je5, Eq. 3-63.

d 1
— (P) = = ([p, H])
dt ih 5
= 5 (pF +)
ih 2m
5 2 [A,B+C] =[A,B] + [A,C]
1,. p R
= 5 (|p, 5—| + [B, V))
ih 2m a 20
1 ) (66) =0= [p67] =0
= = ((p.V))

> Eq. 3.28
1 f 33-9
= = [4 x¥*[p, V]J¥
> [A,B] = AB-BA
= = / Bx¥t pV¥ — = / Bx¥tV PY
1 1 2 Eq. 3:38
=5 / Px¥* (—iNV)V¥ - = / Bx¥*V(—inV)¥
> product rule
—_ / Bx¥t (VV)¥ — / Bx¥tVV¥ + / Px¥tVV¥

>)
=- / Bx¥t (VV)¥
= (-VV) = (F). (4.6)
This is exactly the equation stated at the beginning of this sec-

tion.

Now, it’s time to summarize what we have learned so far before
we move on to discuss concrete quantum systems.

5

Summary

We started with a short discussion of the famous double slit
experiment. The key lesson we have learned here is that we
need waves to describe particles.

One immediate consequence of this observation is that for some
quantities, only a discrete set of values is possible. We say they
are quantized.

A second consequence of our need for waves to describe par-
ticles is that we get a fundamental quantum uncertainty. For
example, each time we measure the momentum, we change
the location and vice versa. Therefore, it’s impossible to know
the momentum and location of a particle at the same time with
arbitrary precision.

After this preliminary discussion of the most important features
of quantum mechanics, we started to think about how we can
describe them within a physical theory.

The basic idea was to introduce an abstract object, |”), which
describes the system in question. In addition, we introduced
quantum operators that we can use to extract information about

*One example we discussed was
the number of wave crests you can
produce in a rope.

100 NO-NONSENSE QUANTUM MECHANICS

? Given a ket, we can immediately
calculate the corresponding bra.

A bra together with a ket denotes
the scalar product between two
abstract vectors. This is analogous
to (0)|32) = @, - 3. Here we have
(3, | = af (“row times column"). But
in quantum mechanics we deal with
complex vectors and therefore have
(¥h = [¥1)" = (1).

3 Recall that this is completely
analogous to how we can calculate
how much a vector spreads out in
the, say, z-direction. All we have
to do is multiply it by the @, basis
vector.

the system. For example, if we want to know the momentum of
a system, we use the momentum operator Pp:

P\¥1) = pi l¥1) -

However, we often do not get such a simple answer. Instead,
if we measure the momentum of equally prepared systems,
we could possibly end up with different results. Each possible
result occurs with a certain probability. In our quantum frame-
work, we describe such a situation using a linear combination
such as

|¥) =a|¥1)+b|¥2)4+...,

where |¥;) is a state with momentum 1, |¥2) is the state with
momentum p2. The coefficients a and b are directly related

to the probability of measuring p; and p2, respectively. For
example, |a|? is the probability of measuring the value p1.

Afterward, we took a short side trip into the world of statistics.
We discussed two of the most important notions that we need
all the time in quantum mechanics: the expectation value and
the standard deviation.

We then discussed how we can calculate the expectation value
for quantum systems explicitly. The basic idea is that we "sand-
wich" the corresponding operator between a ket |”) and a bra
(¥|. For example, the momentum expectation value reads?

(¥| plY) -

In addition, we have learned how to calculate the probability

of measuring one specific value. All we have to do is multiply
the ket which describes our system by the bra which describes
the system in a state with this particular value. For example,
the probability of measuring p; is 3 | (¥1|'¥) |?. We then talked
about wave functions. A wave function is the set of coefficients
that we find when we expand our state |’) in the position basis:

pe) = f dx¥(x) |x). (5.1)

Afterward, we thought about the crucial question: what do
quantum operators explicitly look like?

As a first step, we recalled the basic message of Noether’s the-
orem: symmetries lead to conserved quantities. For example,
symmetry under spatial translations leads to conservation of
momentum. Then we took another short side trip to talk about
symmetries in general. The key lesson we learned was that the
basic mathematical objects needed to describe continuous sym-
metries are called generators. By acting with these generators
on an object, we can achieve an infinitesimal transformation.
Repeating this tiny transformation many times, we can gener-
ate any transformation we like. We then connected these two
puzzle pieces and proposed that the quantum operators are
precisely these generators. For example, the quantum momen-
tum operator is simply the generator of spatial translations:

= —ihd,. The second most important example is the quantum
energy operator E = ihd;. We concluded that this is the correct
explicit form of the operator since symmetry under temporal
translation leads to conservation of energy.*

These ideas allowed us to derive the two most important quan-
tum equations:

> The canonical commutation relation: [p;,2;] = —ihd;j. This
equation tells us that it really makes a difference whether we
first measure the momentum of our system or first measure
the location.5

252
> The Schrédinger equation: iid; |¥) = ia |[¥) + V(#) |¥).

This equation tells us how quantum systems evolve in time.
In addition, it allowed us to understand how waves play

a role in our framework. The crucial observation was that
solutions of the Schrédinger equation behave like waves.

Finally, we talked about the third most important quantum
operator: angular momentum. Noether’s theorem tells us that
angular momentum is conserved if the system does not change
under rotations. Following the same logic as above, we use

the generator of rotations as our quantum angular momentum
operator. However, there is a subtlety since a rotation possibly
has two effects. If we describe our system with an object that

SUMMARY 101

4 A temporal translation means
that we shift the time when our
experiment happens: to t+a.

5 Reminder: [A,B] = AB — BA.

102 NO-NONSENSE QUANTUM MECHANICS

6 The complete generator of rota-
tions is given by a combination of
these two generators.

7 Recall that 0; denotes the Pauli
matrices. This second generator
only looks like this if our system
has spin 1/2 and we can therefore
use two-component objects to
describe it. For spin 1 systems, for
example, we need a four-component
object and (4 x 4) matrices for the
generators.

has more than one component we need not only to modify the
argument of our function, ¥(x) = ¥(Rx) (where Rx denotes
the rotated coordinates), but also take into account the potential
mixing of coordinates:

Y¥1 (x,t) , Yo(x,t)
Yo(x,t) Wi(x,t)]
Therefore, we have two generators of rotations®.

> One generator is given by a differential operator L = x x
(—ihd) and is responsible for the transformation ¥(x) >

[> The second generator is given by a matrix, for example, 40;
and is responsible for the mixing of the components.”

Consequently, we therefore have two different quantum oper-
ators for angular momentum. The first one relates to orbital
angular momentum, which describes how one objects revolves
around another. The second one describes some kind of internal
angular momentum known as spin. Spin is unusual in the fact
that it can take on only a discrete set of values; a consequence of
the fact that the corresponding operator is given by a matrix. In
other words, spin is quantized.

Now it’s time to see how all this works in practice. In the fol-
lowing sections, we will talk about the most important quan-
tum systems and how to describe them using the tools that we
learned in the previous sections.

Part II
Essential Quantum Systems and Tools

“A mathematician may say anything he pleases, but a physicist must be at
least partially sane.”

Josiah Willard Gibbs

PS: You can discuss the content of Part II with other readers, find exercises to check your
understanding and give feedback at ww.nononsensebooks . com/qm/part2.

> The harmonic oscillator. This example is extremely important

SUMMARY

In the following chapters, we will discuss several quantum sys-
tems in detail. However, we will only discuss a small number
of systems since these are enough to understand almost all cru-
cial aspects of quantum mechanics. In particular, the quantum
systems we will discuss in this part are:

> A particle in a one-dimensional box with infinite walls. This

example demonstrates nicely how and why energy is quan-
tized in some quantum systems.

A particle in a one-dimensional box with finite walls. This ex-
ample is similar to the previous one, but we can additionally
learn how quantum particles can tunnel into regions that are
classically forbidden.

The hydrogen atom. This system is, in some sense, a three-
dimensional "box". The most important new aspect is that
angular momentum plays a role.

A particle that scatters off a box. While the previous three
examples are all about bound states, this example illustrates
how we can describe scattering states.

While there are infinitely many variations of these problems
(i.e., differently shaped boxes), the systems in the list above
are absolutely sufficient to grasp the fundamental features of
quantum mechanics. Afterward, we will talk about everyone’s
darling:

* Quantum field theory is what

105

we end up with if we combine the
fundamental lessons of quantum

since many potentials look exactly like the potential of the mechanics with the fundamental
harmonic oscillator for small displacements. Also, there are lessons of Einstein’s theory of
special relativity.

two different ways to treat the oscillator. The first method is

completely analogous to what we did in the other examples. 2 Think: like a mattress. At each
point in space we have a spring

However, there is a second method which is a lot more clever ‘ , ;
(i.e., a harmonic oscillator) and

and essential if you want to understand quantum field the- all these springs are connected.

ory.’ In fact, (and this may be oversimplifying a bit) we can It is indeed possible to derive the

say that quantum fields are just collections of many harmonic

continuum limit.

correct Lagrangian for a scalar field
by starting with a discrete set of
oscillators.” coupled harmonic oscillators (=

a mattress) and then taking the

106 NO-NONSENSE QUANTUM MECHANICS

Before we start, let’s discuss a few general things that are ex-
tremely useful to keep in mind.

6

Tricks and Ideas We Need AIl
the Time

What we do in quantum mechanics is usually the following:

We solve the Schrédinger equation

_ We
2m

ihdas¥ (x) = ( + V(x)) ¥(x)

for some given potential V(x) and boundary conditions. Bound-
ary conditions are always an essential physical input. The
boundary conditions determine, for example, if a particle moves
towards our box from the left or right or whether it is confined
within the potential.

The solutions then tell us which energy values are possible and,
for example, where it is most likely to find our particle.

Now, one of the things we should talk about before we start
with concrete examples is a clever trick that simplifies the task
of solving the Schrédinger equation tremendously.

108 NO-NONSENSE QUANTUM MECHANICS

* Reminder: For a particle ina
potential V(x), the Schrédinger
equation reads

oe Wey

mor ~~ 2m a *V(
The operator H is the energy
operator and it is directly related to
the classical energy = kinetic energy
plus potential energy.

xy¥.

6.1 Let’s Separate Time and Space

For any system where the potential does not depend on time,
we can split the Schrédinger equation into two simpler equa-
tions and solve them separately. This trick is known as separa-
tion of the variables and works as follows.

First, we split our wave function into two parts:
¥(x,t) = T(t)p(x). (6.1)

The first part T(t) describes how the wave function changes
over time, while the second part (x) how the wave func-
tion depends on the location. We now put this ansatz into the
Schrédinger equation:*

ihds¥ (x,t) = HY (x,t)
> Eq. 6.1
ihd:T(t) p(x) = HT (t)p(a)

4, OFT (t) _ Hy(x)

TH) p(x) ©
In the last step we used that H only contains the spatial deriva-

tive 02 and T(t) only depends on ¢ and not on x. In addition,
we used that the left-hand side only contains the derivative 0;
while p(x) only depends on x.

Now, what we are left with is on the left-hand side something
that only depends on t, and on the right-hand side something
that only depends on x. Still, both sides must be equal. This

is only possible if both sides are constant. If, for example, the
left-hand side is non-constant this would mean that we could
change its value by varying t. Since the right-hand side does
not depend on ¢ at all, there is then no way that both sides are
equal. Both sides of the equation are thus constant and equal to
the energy, E. Then we are left with two equations, as promised:

ott =E= Hyp (x)

Tt) = = pa)
nT) — pang HYCH)
ray =F and aay =F

TRICKS AND IDEAS WE NEED ALL THE TIME 109

These may be written a bit differently:
ihd;T(t) = ET(t) (6.2)
Hy(x) = Ep(x). (6.3)
The first equation is easy to solve and does not depend on the
specific problem at all. All information about the system is
encoded in H. So the first lesson is that, as long as V (and

therefore also H) does not depend on t,? the explicit time-
dependence of the wave function is given by

(6.4)

This equation can be derived as follows:

ihd,T(t) = ET(t)

ihosexp (-+) = Eexp (-5)
 [ —iE iEt iEt
ih (=) exp (-+) = Eexp (-5)
iEt iEt
Eexp (-5) = Eexp (-5) v

The second lesson is that all specific information about the

this is Eq. 6.2
») Eq. 6.4

») are!At = jAei4t

system are encoded in the solutions of the second equation
which only depends on x:3

This equation is known as the stationary Schrédinger equation

(6.5)

or time-independent Schrédinger equation. After we have
solved it for a specific problem (i.e., a specific H), all that is left
to do is to remember that the full solution reads

Yt) =9O)TO=vaep(-F). 66)

A solution of the stationary Schrédinger equation w(x) is
known as a stationary solution or a stationary state.

2 Remember that this was the crucial
restriction we mentioned at the
beginning. The whole trick we

used only works if H does not
depend on t. Otherwise, the ansatz
¥ (x,t) = T(t)p(x) does not help us.

3 Take note that this equation is
really of the same type as the
equations we considered all the
time (an eigenvalue equation). The
energy operator H acts on p and
what we get back is the energy E.

110 NO-NONSENSE QUANTUM MECHANICS

4 As already mentioned in Sec-
tion 3.8, the general mathematical
theory that deals with this kind
of problems is known as spectral
theory.

5 There is an important exception to
this rule. If we deal with a system
with a potential that is infinite at at
least one point, the first derivative
is allowed to jump at this point.
The reason for this is that if we
introduce something non-physical
like an infinite potential energy,

an infinite kinetic energy becomes
possible. Such models are nothing
we can observe in nature but only
useful as toy models that help us to
understand important aspects in a
simplified setup.

It is clear that this kind of problem can become arbitrarily com-
plicated for complicated potentials V(x). However, there is
often not much new physics to be learned in such complicated
problems and we will stick to the simplest potentials.4

The next thing we need to talk about before we start discussing
concrete quantum systems is an important restriction which
tells us which solutions of the Schrodinger equation make sense
physically.

6.2 Why Quantum Waves are Smooth

While lots of solutions are mathematically possible, in physics
only a few of them make sense. An incredibly important re-
striction on physically allowed solutions is that wave functions
have to be smooth. Formulated differently, we demand that
wave functions have no jumps or discontinuities. This restric-
tion follows since the momentum operator is proportional to
the derivative operator 0,. So if there are any jumps in the wave
function, the derivative (and thus also the momentum) at these
points is infinite. An infinite momentum is not physical and
therefore no jumps are allowed. Therefore, we can conclude that
wave functions have to be smooth everywhere.

A

Analogously, the first derivative of the wave function, 0,¥, must
be smooth, too. This restriction follows since the formula for the
kinetic energy is T = p?/2m = —h’ 0 /2m. Therefore, a jump in
the first derivative would mean that the kinetic energy is infinite
at these points.°

Now we are almost ready to dive in and calculate explicitly what

TRICKS AND IDEAS WE NEED ALL THE TIME 111

happens in quantum systems. There is just one more thing we
should talk about. The following classification is immensely
helpful to make sense of the solutions that we calculate in the
following sections.

6.3 Classification of Solutions

In Section 3.7, we already talked about one possible solution
of the Schrédinger equation. In particular, we investigated the
Schrédinger equation

na2

iho: ¥ (x, t) =- om

¥ (x,t) + V(k)¥ (x,t) (6.7)

when there is no potential V(£) = 0 and found that in this case,
solutions are of the form

W (x,t) =e Et px) /h (6.8)

We call this kind of solution a plane wave since it describes a
wave that spreads out all over space with constant amplitude.®

Now if there is a potential, then we need different solutions.
However, the solutions depend not only on the potential V(%)
but also on the energy of the particle E. To understand this, let’s
consider the stationary Schrédinger equation (Eq. 6.5):

242

Ey(x) = — 2 p(x) + V(2)H(2).

2m

(6.9)

The free solution of the stationary Schrédinger equation (i.e. the
solution for V(%) = 0) follows directly from our result in Eq. 6.8:

p(x) = eltPx)/h

where p = V2mE.

Now, what happens if the potential is non-zero?”

> If the energy of the particle is Jarger than the potential (E >
V), we again get an oscillating solution but with a different
frequency:8

® Reminder: such plane waves do
not describe physical particles since
they spread out all over space. To
describe a real particle we need to
use superpositions of plane waves.
A suitable superposition of plane
waves yields a wave packet which
we can use to describe a particle.

7 Take note that potentials do not
necessarily have the same value
everywhere. Hence the solutions
we discuss below can be valid

for different regions of the same
system. For example, imagine a box
where the potential is zero inside
and non-zero outside the box.

8 We will check this explicitly in
a later section. Here, we are only
interested in the general structure.

112 NO-NONSENSE QUANTUM MECHANICS

° This will make a lot more sense
as soon as we discuss concrete
examples.

p(x) = eltPx)/h

where p = \/2m(E — V).

If the energy of the particle is smaller than the potential E <
V, our solution also reads

p(x) = eltPx)/f

However, we need to be careful since upon closer inspection
this solution is qualitatively completely different. This fol-
lows since the term under the square root in p = \/2m(E — V)
is negative for E < V. This means that for E < V, we can fac-
tor out a —1 from under the square root:

p = \/2m(E—V) = \/(-1) x 2m(V - E)
= V—1,/2m(V — E) =i,/2m(V -E).

We then define p = \/2m(V — E) and then find

p=ip. (6.10)
Therefore, we can write the solution as follows:

The crucial point here is that, for E < V, the argument of
the exponential function is no longer imaginary. While an
exponential function with imaginary argument describes an
oscillating wave, an exponential function with real argument
describes exponential growth or exponential decay. In phys-
ical terms, this usually means that our wave function quickly
becomes tiny in regions where E < V.9

A third possibility is that the potential is infinite:

V(%) = oo. In this case, the only possible solution of the
stationary Schrédinger equation is (x) = 0. In physical
terms, this means that the probability to find a particle in a
region where the potential is infinitely high, is zero.

With this in mind, we can understand the following general
classification of solutions of the Schrédinger equation.

TRICKS AND IDEAS WE NEED ALL THE TIME 113

> If the energy of the state is smaller than the potential in the
system at infinity (E < V(oo) and E < V(—oo)), we are deal-
ing with a bound state. Such states describe a particle which
is stuck inside some kind of box. This interpretation comes
about since, as discussed above, solutions for the Schrédinger
equation with E < V describe either an exponential decay or
exponential growth. In the former case, we get a vanishing
wave function at x = oo. In the latter case, we get an infinite
value for the wave function. An infinite value of the wave
function makes no sense. Therefore, states with E < V(0o)
and E < V(—oo) cannot "come from infinity", but describe
particles confined within some fixed region. We label bound
states using a discrete index n. We use discrete labels since the
energy levels within a box are quantized and therefore there
is a discrete set of possible states. A general solution is a sum
of such solutions.

> If the energy of the state is larger than the potential at infinity:
E > V(oo) or E > V(—co), we are dealing with a scattering
state. We can understand this interpretation by recalling
that for E > V we get oscillating solutions. Therefore, such
states describe waves that come "from infinity" and then
slow down under the influence of some potential or even get
reflected. We label scattering states using a continuous index
k. A general solution is an integral { dk over such solutions.*°

Now with this in mind, we are finally ready to discuss the most
important examples explicitly.

PS: Please, don’t worry if not every step in the following chapters

is clear at first glance. Just keep reading and things will make more
and more sense if you see them explained multiple times for different
problems. There will be quite some repetition in the following sections.
This is on purpose to help you internalize the basic methods. So the
goal is not that you understand everything immediately, but instead
that you slowly get used to how people talk about quantum systems.

*° An important subtlety is that
since such wave functions do

not vanish at infinity, they are
non-normalizable. This tells us
immediately that a pure scattering
wave function is not in their own
right physically realizable. Instead,
only suitable linear combinations
(wave packets) are physically
realizable. However, often it is
sufficient to investigate the basic
building blocks ( = plane waves)
that our wave packets consist of.
This is good news since dealing
with wave packets is a messy
business and seldom possible
without a computer.

7

Quantum Mechanics in a Box

7.1 The Infinite Box

One of the most famous quantum systems is a particle confined
in a (1-dimensional) box with infinitely high potential walls.
Inside the box, the potential is zero; outside it’s infinite:

V(x)

SQA QQ QDS
WG


116 NO-NONSENSE QUANTUM MECHANICS

* Here we will not use the stationary
Schrédinger equation (Eq. 3.45)
since it is instructive to see at least
one example worked out with

the explicit time dependence.
However, in the following sections,
we will start directly with the
stationary Schrédinger equation.
This is possible because the time
dependence is always the same for
these systems since the potentials
do not change over time.

Z
Z
Y,
Y
4,
Z|
/
4
Z
/,
V

XMM ONO

Figure 7.1: A classical ball in a box
would simply bounce between the
walls.

? We talked already about the free
particle solution in Section 3.7.

3 Recall: If there are any jumps in
the wave function, the momentum
of the particle p,¥ = —ihd;¥ is
infinite because the derivative at the
jumping point would be infinite.

The potential is defined piece-wise as

0, O<x<L
v-{ (7.1)

co, otherwise
and therefore, we have to solve the Schrédinger equation’

, no2
iho; ¥ (x,t) = — om ¥ (x,t) + V(x) ¥ (x,t)

piece-wise.

> Inside the box, the solution is equal to the free particle solu-
tion, because V = 0 forO< x <L

> Outside the box, since V = oo, the only possible, physical
solution is ¥(x,t) = 0.

We can rewrite the free particle solution?
W(x, t) _ Ae i(Et—px)/h 4 Be~i(Et+px)/h
= (Csin((px)/h) + Dcos((px)/h))e#/",
using the non-relativistic energy-momentum relation

E=P +) p=V2mE (7.2)

¥ (x,t) = (Csin((px)/h) + Dcos((px)/h))e#t/"

ame x) + Dcos( A" x))et#¥/" .

Next, we use that the wave function must be a continuous func-
tion.3 Therefore, we have the boundary conditions

> Eq.7.2

= (Csin(

¥(0,t) = ¥(L,t) =0. (7.3)

Since cos(0) = 1, we can conclude immediately that D + 0.
Furthermore, we can derive that the conditions in Eq. 7.3 imply

2mE 1: nm
> = TL’ (7-4)

QUANTUM MECHANICS IN A BOX 117

with arbitrary integer n = 1,2,3,..., because only then

¥n(x,t) = (Csin(— ame x) + Deos( 2 x)) HEH"
nr Eth ») D=0
= Csin (Tx) et (7.5)
and both boundary conditions are satisfied:
¥(0,t) =0
check: ¥,(0,t) = Csin (0) en iEnt/h
> sin(0) =0
=0 Vv

and

¥,(L,t) =0
check: ¥,(L,t) = Csin (+ L) en iEnt/h

2

= Csin (nz) e~tEnt/h

> sin(nz)=OforneZ V(X

=0 Vv

We can rewrite Eq. 7.4 to find a condition for the energy

1 neh?
En = om” (7-6)

The possible energies are therefore quantized, which means that

the corresponding allowed energy levels are integer multiples of

242
the constant: a

Take note that we have a solution for each n and that linear
combinations of the form

¥ (x,t) = AV1(x,t) + BY2(x,t) +...

are solutions, too.

We can calculate the normalization constant C by using the fact
that the probability P for finding the particle anywhere inside

MN XY QHQQUYNYY OOS RAN XQ OY

OXY MNO

Zz.

Zz
Z,
Yj
Z
y,
Z
Z
4

RX dd)) QONYSS
RX Qn ~ »«a»:|»!As

Figure 7.2: Wave functions in the
infinite box. Take note that our
wave function is, in general, a
complex function and plotting

a complex function is difficult.
Therefore, the absolute square

of the wave function is shown.

This absolute square indicates the
probability to find the particle at the
given locations.

118 NO-NONSENSE QUANTUM MECHANICS

4 We integrate from —oo to oo.
However, the wave function is zero
outside the box. Therefore we end
up with the non-zero part of the
integral, which goes from 0 to L.

the box must be 100% = 1 and that the probability outside is
zero, because there we have ¥ = 0. Therefore,

L
1= [ dx¥*(x,t)¥n(x,t)

. 2 Eq.75
=| dxC? sin( x)etiEt/Mgin( 27 x) @-iEt/I
0 L L
: >)
_ 2 2 7
=C [ dx sin’ ( r x)
. >)
C E oo]
— } nT
200 4 |
>)
>(L_ sin(7#4L)
=O Na qin
L >)
27
=C A
and we can conclude
2
2 =
CaF. (7.7)

With all this in mind, we can calculate the expectation value
of the position operator for various states of the system. Let’s
assume that the particle is in the ground state:

2
1 (x,t) = i zsin (<x) etFnt/h eg. 75withn=1). (7.8)

The corresponding position expectation value reads (Eq. 3.28):4

QUANTUM MECHANICS IN A BOX

L
(¥,|2/¥1) = [ dx¥ (x, t)8¥ (x,t)

> Eq.78
L 2 7U Ent/h ‘
_ 4 (7 -iEnt
=[ ts( [sin (Fs)e x
2. (TM \ -iEgt/h
x (7s (7)
>)
= 2 [axsin’ (Fx) x
~ Lo L
eS
_ 12
=7
>)
_L

In words, this result tells us that the most probable position for
the particle in the ground state ¥; (x,t) is exactly in the middle.

Moreover, we can calculate the standard deviation (Eq. 3.7)

Ax = (x2) (x)?

What we still need here, is the expectation value of the squared

position operator ((x*)). So we calculate5 5 You can do the integra-
tion, for example, using
http://wolframalpha.com.

2 Eq.7.9

L
(¥,|22/¥1) = [ dx¥ 1" (x, t)82¥4 (x,t)

' > §Eq.78
E 2. (@_\ .-iEnt/h ) 42 (2 (Tl) iE gt/h

=) dx (ls (Fx)e x psn (Fx)e
D)

= 2 ” ax sin? (2) x?

L L
0.1413

D)

~ 0.28L?. (7.10)

119

120 NO-NONSENSE QUANTUM MECHANICS

With this information at hand, we find

(x2) = (x)?
2 £Eq.79
2

> Egq.7.10

= 4/0. 28L2 — —
2

Lv 0.28 — 0.25
2
=0.17L.

This result tells us that, on average, we will find the particle
17% of the total box-width away from the middle.

Completely analogously, we can calculate the expectation value
and standard deviation for all other possible states. For ex-
ample, for the second lowest state ‘2, the expectation value is
again exactly in the middle of the box ((¥2|£/¥2) = 5). But
the standard deviation is now larger: Ax ~ 0.27L. This tells us
that if the particle is in this state, it fluctuates a lot more. This is
exactly what we would expect from a state with higher energy
(Ez > E}).

QUANTUM MECHANICS IN A BOX

7.2 The Finite Box

The system we discussed in the previous section was somewhat
oversimplified. There are no infinite boxes in nature. Therefore,
it makes sense to have a look at a similar system with finite po-
tential barriers. Specifically, the potential we are now interested
in reads

0, -a<x<a
V= .
Vo, otherwise (7-11)

and looks like this picture:

Our only task is to solve the stationary Schrédinger equation
(Eq. 6.5)

PY 2m

qe =e VO EI
since the potential does not change over time. The potential
is defined piece-wise and therefore again, we have to solve

121

122 NO-NONSENSE QUANTUM MECHANICS

®t is also possible to investigate the
system for a particle with E > Vo. In
this case, the particle scatters off the
box. Such scattering processes are
the topic of the next section.

the Schrédinger equation piece-wise. We have three relevant
regions here:

> ikx<-a
> Il: -a<x<a
> IIx>a.

We assume that the particle inside this box has an energy that is
lower than Vo (i.e., E < Vo). Physically, this means that we con-
sider a particle that is bound inside this potential.© An important
new aspect is that the wave function does not vanish outside
the box. In particular, this means that ¥ is non-zero in the re-
gions I and III. Inside the box, we have again the oscillating
free solutions that we already discussed in the previous section.

W(x) =C sinax+D cosax -a<x<a,
where we have introduced « = ame to unclutter the notation.
7 We will check this explicitly below. | However, the solutions in the regions I and III now read’
W(x) = Ae*+Be PR x<-a
Wii(x) = Eel®¥+Fe? x>a, (7.12)
where again we introduced a shorthand notation:
B = \/2m(Vo — E)/h?. (7.13)
Let’s check that these functions are indeed solutions in the two
® The check for ¥ 11; works com- regions where the potential is non-zero:®
pletely analogously.
2m
—,¥;= = (W-E)¥
dx2 I he ( 0 ) I
> Egq.7.12
ca (A ef +B ef) = 2m (y, _ (A eb +B ef)
dx2 iG
2
2m
Bp (A PF 4B ef) = = (Yo) (A eX +.B ef)
’ > §Egq.7-13
2m(Vo —E _ 2m _

QUANTUM MECHANICS IN A BOX

These solutions are non-zero but still very different from the
solution in region II. Take note that there is no imaginary unit
in the exponential functions here since E < Vo and thus B

is real. An exponential function with the imaginary unit in
the argument is an oscillating solution?, while one without it
describes exponential decay (or growth).

A crucial property of wave functions is that they must be nor-
malizable. This means that if we integrate the absolute square of
a wave function all over space, the result must be 1 since a prob-
ability of more than 1 = 100% doesn’t make sense.*? We can use
this immediately to conclude that B = 0 and E = 0. The reason
for this is the following observation: the Region I goes from —oo
to —a and B is the coefficient in front of e~5*. However, e~*

for x —+ —oo becomes infinite. There is no way to normalize a
wave function that becomes infinite somewhere. Therefore B
has to be zero. For the same reason, E has to be zero since it is
the coefficient in front of e** in the region III that goes from a to
oo. Therefore, the wave function in the region III reads:

Yi(x) = Fe P* (7.14)

For the moment we are only interested in the general form of
this solution. There are two important aspects. Firstly, the solu-
tion is non-zero. So while the particle has an energy that is too
low to overcome the potential barrier (E < Vo) the probability
to find it outside the box is non-zero. Classically, this is impos-
sible! This phenomenon is usually called quantum tunneling or
simply tunneling. The particle can tunnel through the potential
barrier and get into regions that are classically forbidden.

quantum
tunneling

classical turning point

123

9 Again remember Euler’s formula:

e* = cos(x) +isin(x).

Vo

PE RRRQAYQADOO AAS

SOOO OOOO,

-O®

10 Recall that wave functions de-

avi

avid

avod

V.

%

NY QOS

MH YAY

RQOXMMNA

scribe probability amplitude den-
sities. If we integrate the absolute
square of a wave function over some

spatial region, we get the prob-
ability to find the particle inside

this region. If we integrate all over

space, the probability to find the
particle must be 100% since the
particle has to be somewhere.

124 NO-NONSENSE QUANTUM MECHANICS

™ Reminder: this is necessary since
otherwise the momentum and
kinetic energy would be infinite.
Moreover, note that we need to

be careful what 0,'¥1;;(a) means.

It means that we first take the
derivative and then put in x = a.
Otherwise, there is no x dependence
and the result would be zero. We
indicate this as follows:

0x¥111(4) = 0x¥111(x) .
This notation makes it clearer that

we first take the derivative and only
then put in x =a.

The second important observation is that the function e~5*
describes an exponential decay. Thus while the probability to
find the particle outside the box is non-zero, the probability
becomes quickly tiny if we move away from the box.

The next thing we can do is to determine the allowed energy
values, analogous to what we did in the previous section. To do
this, we again use the requirement that our wave function and
its first derivative must be smooth everywhere:**

¥1(—a) = ¥n1(—a)
dx ¥1(—a) = dx¥11(—a)
¥n(a) = ¥in(a)
Ax¥ 11(a) = ax ¥y11(a)
We are not interested in the most general solution (which is
quite complicated), but only in general features of the solutions.

Therefore, we only consider the case where the wave function
inside the box (region II) is symmetric:

W(x) =D cosax. (7.15)

In this case, we only have to solve a system of two equations
since the symmetry implies that if the function is smooth at a it
is automatically smooth at —a, too. We are therefore left with

1
¥ir(a) = ¥r1(4)
1
Ox ¥11(@) = 0x¥111(4),
in which we now put our explicit solutions
!
¥i1(4) = ¥irr(4)

> Eq. 7.15 and Eq. 7.14
;
D cosaa = F e F*,

In addition, for the second condition, which tells us that the first
derivatives have to be smooth, we find

ax¥1i(x)| = ax¥i1(x)|

a a E
; ) Eq.7.15
= 0,F e~*

a

0xD cos ax

‘ ») 8, cos(ax) = —asin(x), d,e8* = peP*

—Da sina = —BF e P*,

QUANTUM MECHANICS IN A BOX 125

In addition, we divide the second equation by the first one and
this yields

atanana = B (7.16)

This equation determines, analogous to what we discovered

in the previous section, which energy values are allowed since
« and f are both functions of the energy E. Unfortunately, it’s
impossible to solve this equation analytically for E.1? However,
one thing we can do is solve the equation numerically. Another
possibility is to plot the left and right-hand side separately. The
points of intersection are then the allowed solutions.

To understand this, we define ¢ = aw and ny = af such that
Eq. 7.16 reads

= Gtang

as we can check

n= Etané
> 4 =aB, = aa
aB = ax tanaa

B= «atanaa + Eq. 7.16 V

We can then plot the allowed values for ¢ and 7:

7

aN

mek tan€

sls
aly
Bw
My

2 Mathematicians call this type of
equation a transcendental equation.

126 NO-NONSENSE QUANTUM MECHANICS

In addition, we have to recall how we defined a and f in the

first place:
_ f2mE
=e
B = \/2m(Vo — E)/h?.
3 This condition has to be fulfilled We can therefore conclude}
since Vo is the fixed value that 2 >! 2mVo
determines how tall our potential x p= en (7.17)
walls are. h
We can translate this condition into a condition for our newly
“4 We start with the final condition defined variables 4 and ¢:14
and then show why it is true. 2
2 2! 2ma Vo
an
; > 1 =aB,f = aw
1 2ma°VY
(ap)? + (aa)? + HMO
2
i 2m Vo

This condition for 7 and ¢ defines circles on which all allowed
values lie. The points where our function (y = ¢ tan¢) and these
circles intersect, correspond to allowed energy values.

7

nls

3rt SH 2m
z 2 z

The most important feature here is that tan x is a periodic func-
tion and therefore there are multiple solutions. And again, only

QUANTUM MECHANICS IN A BOX

a discrete set of values for E are allowed. The bottom line there-
fore is: energy is also quantized inside a finite box.

There are dozens of different variations of the box problem. For
example, we could investigate how the solution looks like if the
box is not symmetric around x = 0 and the potential inside the
box is non-zero V = Vo. However, such changes do not lead

to new physical systems. We can always shift our coordinate
system and the absolute energy scale such that the system is
symmetric and has potential zero inside the box.

Alternatively, we can investigate different shapes of the box or
what happens when the box itself moves. A famous example is
a box that is infinitesimally thin and infinitely deep (the "delta
potential"). Such problems are especially popular in university
exams. However, since we do not learn anything qualitatively
new in these problems, we do not discuss them here. The most
important aspects (tunneling and quantization) are already
covered in the two simple examples we have discussed in the
previous two sections.

The quantum system we discuss in the next section is, in some
sense, the masterclass when it comes to quantum systems with
bound states. However, the basic lessons are the same that we
already discussed in the previous two sections, only the formu-
las are more complicated. For this reason, we will not discuss
every detail but only talk about the most important aspects.

7.3 The Hydrogen Atom

Before we start discussing the hydrogen atom, there are a few
things we should talk about. All examples in the previous sec-
tions were one-dimensional. However, the hydrogen atom is

a three-dimensional system and therefore we need to under-

127

128 NO-NONSENSE QUANTUM MECHANICS

** Angular momentum plays no role
in 1 dimension, since there are no
rotations in 1 dimension.

© In fact, L? is exactly the squared
angular momentum operator that
we already discussed in Section 3.9.
The spherical harmonics func-
tions that we talk about below are
eigenfunctions of this operator.

17 In Section 6.1, we used that for
systems, in which the potential
does not depend on the time t, we
can separate the time-dependence
and the position-dependence of the
wave function: ¥(x,t) = p(x)T(t).
Now, we do the same thing again,
but this time we separate the
angular and radial dependence of
the wave function.

stand what is different if we are dealing with more than one
dimension.

First of all, in three dimensions one additional quantity often
plays a crucial role: angular momentum.*> From the discussion
in Section 3.4, we know that angular momentum is conserved
whenever our system is spherically symmetric. In practice,

this means that the potential of the given system is symmetric
under rotations. Then it makes sense to switch from Cartesian
coordinates (x, y,z) to spherical coordinates (9, 6,7).

This switch of coordinates is useful since spherical symmetry
means that we only need to consider the variable r for each
system individually. This follows since a spherically symmetric
potential does not depend on g and 6: V = V(r). Therefore,
we first rewrite the stationary Schrédinger equation (Eq. 6.5) in
terms of spherical coordinates:

_W roy

1?

2m r or2 Ya sae Sy + V(r)p = Ep (7.18)

where?®

> pf 1a,.,a, 1 8
ach (sra3e 8955 + sre ape

We then separate the variables, which is the trick that we al-
ready used in Section 6.1 to derive the stationary Schrédinger
equation.’” Specifically, we make the ansatz (x) = R(r)Ym(0, @),
where Y¢_(6,@) only depends on the angles and R(r) only

the radial distance. Putting this ansatz into the stationary
Schrédinger equation yields two equations; one for Yon(0, 9)
and one for R(r). The resulting equations are quite complicated,
solving them requires quite some mathematical machinery and
offers little physical insights. So let’s only talk about the most
important facts.

The crucial point is that the angular equation (the equation for
Yem(9, ~) ) is the same for all systems with spherical symmetry

QUANTUM MECHANICS IN A BOX 129

since the potential does not depend on the angles. So we have
to solve it only once. The solutions to the angular part of the
Schrédinger equation are known as spherical harmonics. These
are special functions which are defined by their property that,
well, they are solutions of the angular part of the Schrédinger
equation.

The radial equation depends on the specifics of the system that
we consider and therefore, there is no general solution.

The most important example of a system with a spherically
symmetric potential is the hydrogen atom. The relevant poten-
tial is the Coulomb potential V(r) = — 77, ;. This potential

is spherically symmetric since it contains no dependence on

the angles @ and g. Therefore, one part of the solution are the
spherical harmonics already mentioned above.

In the solution of the radial Schrédinger equation, a new type
of special function appears which is known as generalized
Laguerre polynomials.‘® An important result is then that the

possible energy levels are quantized (Ey = —}5me (sex) ae
completely analogous to what we already discovered for the box
examples above.

8 You can find the details of how
these functions and the spherical
harmonics are derived in other
quantum mechanics textbooks. I’m
sure if you see the calculation you
will be able to follow the steps.
However, it is also clear that it
would take a lot of time to come
up with these solutions on your
own. Historically, these weren't
discovered in an hour either. So
don’t worry, students are usually
not expected to come up with
solutions for such complicated sys-
tems. If you do actual research, it
is possible that you have to find so-
lutions of the Schrédinger equation
for comparably complicated sys-
tems. However, there is no general
method to come up with solutions.
Usually the best idea is to ask a
trustworthy colleague from the
math department. This is why we
don’t discuss all the details here.

8

Scattering off a Box

In the previous sections, we only discussed bound states. Such
states describe particles which are trapped inside some poten-
tial.

The second type of state that exists in quantum mechanics are
scattering states’. These states describe particles that move, for
example, towards some potential barrier.

Depending on their energy and the height of the potential bar-
rier, the particles either get reflected, or pass through or above
the barrier. As always in quantum mechanics each such process
is possible with a certain probability.

So the situation we are now interested in looks like this:?

L Lt at
RV
wy
' —a a 7

t As discussed in Section 6.3, bound
states are characterized by E <
V(co) and E < V(—ov), while
scattering states are characterized
by E > V(co) or E > V(—0).

? We consider a particle that moves
from the left towards the potential
barrier. Of course, it is also possible
to consider a particle that comes
from the right.

132 NO-NONSENSE QUANTUM MECHANICS

3 We will talk about this in more
detail in a moment.

Then, after the interaction with the potential barrier, the situa-
tions has changed:

As in the previous section, we have to solve the Schrédinger
equation piece-wise because the potential is defined piece-wise.
In the Regions I and III, we have no potential and therefore the
usual free particle solutions:

W(x) = eh 4 Ae x < -a
Wr11(x) = B elkx x>a, (8.1)

with k = /2mE/h*. Take note that there is no coefficient in

‘kx in Region I and no function of the form e~** in

front of e
Region III since we consider a particle that moves from the

left towards the potential barrier3. In other words, we do not
consider the most general system but a very specific physical

situation.

The probability that our particle passes through the barrier or
gets reflected are directly related to the coefficients A and B.

P(reflection) = |A|?

P(transmission) = |B|?.

Therefore, our only task is to calculate these coefficients for dif-
ferent potential barriers and different energies of the incoming
particle. The energy of the particle (relative to the height of the
potential barrier) is important since if it is high enough, the par-
ticle can pass above the barrier. If the energy is lower than the
potential barrier, the particle has to tunnel through the barrier.
So the solution in the Region II depends on whether the energy

is higher or lower than the potential barrier. If it is higher we
also get an oscillating solution

W1,(x) = Ce** + D ew ™ -a<x<a, (8.2)

but with a modified frequency x = \/2m(E — V)/f’.
If the energy is lower than the potential barrier (E < V), we have

something negative in the square root here: ,/2m(E—V)/h’.

The square root of something negative is imaginary. In such a
situation we factor out a —1 from the square root, which then
becomes*

K = 1/2m(E—V)/h? = \/(-1)2m(V — E)/t*
= \/(—1)\/2m(V — E)/h? = iy/2m(V — E)/t? =ik. (8.3)

The solution in Region II then reads

Wy (x) _ Ceik* +D eo ikx
> Kk =ik, Eq. 83

- >) @=-1
=Ce*+De™. (8.4)

_ Cellik)x +D ei (ik)x

So we get an exponential decay of the wave function, which
means physically that the particle tunnels through the barrier.

Before we discuss the most important examples, a few com-
ments that hopefully answer the most pressing questions you
probably have at this point:

> One thing I was confused about as a student is why e*
describes a wave that moves from left to right. This inter-
pretation only makes sense if we remember that we con-
sider solutions (x) of the stationary Schrédinger equation.
These solutions do not move at all! The full solutions are
Y(x,t) = T(t)p(x) = p(x)exp (-#) (Eq. 6.6). So for a
solution of the form (x) = e’* (ignoring fh for a moment),
we have ¥(x,t) = e'*—'£t, Now, let’s focus on one specific
point in our incoming wave. We choose the point which is at

SCATTERING OFF A BOX 133

4 We will discuss all this more
explicitly in the following sections.

+€

134 NO-NONSENSE QUANTUM MECHANICS

5 Formulated differently: a wave
packet is a superposition of many
plane waves.

t = Oat the location —7. The value of the wave function at
this point is ¥(x = —7,t = 0) = e(—im) = —1. Now, we
want to understand how the wave function moves. As time
passes, t becomes larger. This, in turn, means that the point
that we picked is now at a larger x since there is a minus sign
between the x and ¢ part in the exponent. As x gets larger, we
move on the x-axis from the left to the right. This shows that
the wave really moves from the left to the right.

Another question that usually comes up at this point is why
there is no coefficient in front of the incoming wave. This is a
result of our physical choice that the particle moves towards
the potential from the left. In words, this means that 100%

of the particles come from here. However, take note that the
total probability is still not larger than 100%. The coefficients
are only probability amplitudes. Only the absolute square of
them is related to probability. Especially, take note that we
calculate the probability to find the particle in region I by tak-
ing the absolute square of the corresponding wave function.
In general, the result will not be 1. Physically, this means that
the particle will move beyond the potential barrier with a
nonzero probability.

In the images above, we have wave packets that move to-
wards and away from the potential barrier. However, as al-
ready explained at the beginning of this part, calculations
with wave packets are, in general, too difficult. Therefore in
the following, we talk about plane waves instead (Eq. 8.1).
This is a valid approach since wave packets consist of plane
waves.

8.1 The Step Potential

The first concrete potential we now take a look at is a box that
spreads out infinitely to the right:

SCATTERING OFF A BOX 135

NI

AZ7 ,

Mathematically, we have

0 «<0

V(x ) = ,

uU x>0

where U > 0 is a constant. Take note that V(x) is not really a
box potential but rather a step potential. As discussed in the
introduction, we consider a particle that moves towards the
potential from the left.

Once more our task is to solve the stationary Schrédinger equa-
tion (Eq. 6.5)° 6 We use the shorthand notation

_ #2 y’ = d,p and p” = azy.

Since the potential is defined piece-wise, we have to solve it
piece-wise. The crucial idea which allows us to connect the
solutions in the different regions is again that our wave function

and its first derivative are smooth everywhere’. 7 Recall that the physical reason for
this requirement is that otherwise

. . the momentum or kinetic energy
As already mentioned above there are two different cases we would be infinite.

can discuss. Either the incoming particle has an energy large
enough to overcome the barrier (E > U), or the energy is too
small (E < U). In the second case, classically the particle would
definitely get reflected, but in quantum mechanics the parti-

cle can also tunnel through the barrier. So there is a non-zero
probability to find it in Region II.

We discuss both cases in the following two sections.

136 NO-NONSENSE QUANTUM MECHANICS

8 The equations above are a sys-
tem of two equations for the two
unknowns A and B. We do not
discuss how we solve such a system
of equations since it has nothing

to do with quantum mechanics. If
you’re unsure how to solve such a
system you can use, for example,
http://wolframalpha.com.

81.14 E<U

As already discussed in the introduction, we define two new
constants to simplify the notation

k = \/2mE/#
& = \/2m(U — E)/#’.

The Schrédinger equation in the two regions then reads

y’+eyp=0 x<0

yp” -Rp=0 x>0.
The corresponding solutions are the usual free particle solu-
tion in Region I: p = Jeikx 4+. Ae—ikx and the tunnel solution
y = Be—** in Region II. Take note that, in principle, we could
also have in Region II a term of the form e**. However, this
term is not allowed since otherwise the wave function becomes
infinitely large for x — oo.

Next, we demand that and y’ are continuous at x = 0 and this
yields
1+A=B
ik1 — ikA = —%B.
We can solve these equations for A and B:®
_ k-ik _ 2k
+I + iR

Now, if someone gives you explicit values for the potential

barrier height U and the energy of the particle E, you could im-
mediately calculate the probabilities to find the particle behind
or in front of the barrier explicitly.

An important observation is that for U — oo we have |B| — 0

since X = /2m(U — E)/h? > o. Physically this means that for
an infinitely high potential barrier, no tunneling is possible.

In the following section, we discuss the same system again for a
particle with an energy larger than the potential barrier.

81.2 E>U

For this situation we define

k= \/2mE/#

Kk = \/2m(E—U)/#?
and the Schrédinger equation then reads

yp’ +hep=0 x<0
yp’ +rp=0 x>0

Again, we have in Region I (x < 0) the solution » = e* +
Re~‘**, But this time we have in Region II (x > 0) the oscillat-
ing solution p = Te’***.9 Take note that, in principle, we could
also have an e~?** term in Region II. However, this would cor-
respond to a particle that moves towards the potential barrier
from the right. In the physical situation that we investigate here,
there is only one particle that moves towards the barrier from
the left side.

Next, we again use the fact that y and ~’ must be smooth at
x = 0. This yields the equations

1+R=T
ik —ikR = ixT.

Solving them for R and T yields

se
k+x’ k+K

In the previous section, we had a particle with an energy too
small to overcome the barrier classically (E < U). However,
in quantum mechanics there is a non-zero probability that the
particle tunnels through the barrier. Now, we have a particle
with sufficient energy to overcome the potential barrier (E > U).
Classically, the particle would therefore simply move beyond
the barrier. However, in quantum mechanics there is a non-zero
probability that the particle gets reflected even though it has
enough energy.

SCATTERING OFF A BOX 137

9 Take note that here T is a constant
and not the time-dependent part
of the full Schrédinger equation.
The letter "T" is used because this
constant encodes information
about the transmission probability.
Similarly, the letter "R" is used here
because it is directly related to the
reflection probability.

138 NO-NONSENSE QUANTUM MECHANICS

8.2 The Box Potential

The next system we have a look at is very similar to the previ-
ous one. The only difference is that the potential barrier does
not extend infinitely to the right:

tL I Ir
N= L. —]|

U

So mathematically, we have

0 «<0
V(x) =U O<x<a
QO x>a.

While it is also possible to discuss the two cases E < U and
E > U, here we restrict ourselves to the former case since for the
latter case we wouldn’t learn anything new.

Again, we define

k= \2mE/W
& = iy/2m(U — E)/h?.
The Schrédinger equation in the three regions then reads

yp’ +hyp=0 x<0
yp" -@Pp=0 0<x<a
py" +RPp=0 x>a.

SCATTERING OFF A BOX 139

The solutions are of the following form which is somewhat
familiar by now:

p = elk + Rew tke x<0
wp = Ae™* + Be™ O<x<a
yp = Te'* x>a.

Using the smoothness of p and w’ at x = 0 and x = a gives us
the equations

1+R=A+B
ik(1— R) =x(A-—B)
Ae™ + Be-** — Telka
x(AeX* — Be~**) = ikTe'**.

We solve these and obtain?® 1° Again, here we do not discuss
how we solve such equations

x —ik ; since this is purely a mathematical
1+ —R = Telkae—xa problem and does not help us to

K+ ik understand quantum mechanics any
14 « + ik R = Teikapxa better.

x — ik ,

After a long and tedious calculation we find

2 — x2

2kk

-1
T =e tka (cosh Ka —i sinh ra) .
The most important fact is that T is, in general, non-zero. This

once more demonstrates the phenomenon of quantum tunnel-
ing explicitly.

Again, it’s of course possible to study arbitrarily complicated
variations of the problems we discussed in the previous two
sections.

140 NO-NONSENSE QUANTUM MECHANICS

However, the basic method is always the same. And most im-
portantly, quantum mechanics is not really the right theory to
study interesting scattering processes. In interesting scattering

processes, multiple particles collide and new particles are cre-
ated through the scattering. It is extremely difficult to study
such processes in quantum mechanics and the right theory to
deal with this kind of problems is quantum field theory.

Now, we move on to another incredibly famous and important
quantum system: the quantum harmonic oscillator.

9

Harmonic Quantum Mechan-

ics

Sidney Coleman once remarked that “the career of a young the-
oretical physicist consists of treating the harmonic oscillator in ever-
increasing levels of abstraction.”

So it certainly makes sense to study the quantum harmonic
oscillator in some detail. But first, what is a harmonic oscillator?

In fact, all systems with a potential of the form V = cx”, where c
is some constant. The plotted potential of the harmonic oscilla-
tor looks like this

142 NO-NONSENSE QUANTUM MECHANICS

*For the basic idea behind the
Taylor expansion see Appendix A.

An example of a system with such a potential is an object at-
tached to a spring.

Now you might wonder, why harmonic oscillators are so impor-
tant?

It turns out that in a first approximation, lots of potentials are
extremely similar to the harmonic potential. In particular, this
means that the first term of the Taylor expansion’ of many
potentials is exactly the harmonic potential:

harmonic
= potential

For example, the Taylor expansion of a much more complicated

function like cos x is
2

x
=1-—+4+....
cos x at

So for small x, the potential can be approximated by 1 — x?. A
concrete physical example is a pendulum which is described by
the potential V = 1 — cos~x:


HARMONIC QUANTUM MECHANICS 143

Thus, by studying the harmonic potential, we can learn a lot
about lots of other systems (at least about their behavior for
small excitation/low energies).

The potential of the harmonic oscillator is usually written as
V(x) = Ske, (9.1)

where k is the spring constant which characterizes the strength
of the spring. Alternatively, we write the potential often as

V(x) = snes? , (9.2)

where w = Vk/m denotes the classical oscillation frequency Vv
and m the mass at the end of the spring.

The stationary Schrédinger equation (Eq. 6.5) therefore reads

#2 ey ay
om xz + VP = Ep x
> Eq.92

2 0% 122
—h ame t ied x“p = Ey. (9.3)

This equation is quite complicated, but it’s possible to solve it er
by using clever mathematical tricks. However, our goal is to

understand quantum mechanics and not to solve complicated

equations. Only for completeness, let me mention that the solu-

tions to Eq. 9.3 look like this Figure 9.1: Wave functions for the
harmonic potential. Take note how

lvay2 mw — muy 2 similar these are to the solutions of
Yn(x) = (5)" An (y ex) em, the finite box system.
where H, denotes the so-called Hermite polynomials
27 a” 2
H,(u) = (—1)"e /27—_e-*'/?
n(u) = (—1)"e" 2 F
The first few Hermite polynomials are:

Ho(u) =1, Hy(u) =2u, H2(u) =4u?—2, H3(u) = 8u? —12u.

The functions ¥;,(x) are the energy eigenstates since they are
solutions to the stationary Schrédinger equation. The corre-
sponding energy eigenvalues are

1
By = hw (n+ 5).

144 NO-NONSENSE QUANTUM MECHANICS

2 Take note that a* is the Hermitian
adjoint of a, where t = *T,i.e.,
conjugation plus transposition.

And once more, these functions describe the probability am-
plitude densities to find the particle in certain spatial regions.
So in principle, this is all we want to know. We know which
energies are allowed and we can calculate where we will most
probably find the particle if it has energy E, (e.g., energy E;).

There are two important lessons here:

> Quantum mechanics gets complicated quickly. Anything be-
yond simple boxes is almost impossible to solve analytically.

t> We need a smart idea to get any deeper understanding of the
quantum harmonic oscillator.

Luckily, there is an incredibly smart method that makes the
whole problem much more transparent. This method is the
topic of the next section.

9.1 The Magical Method

As promised, here is a smart idea: We define the following two
operators and then use them instead of % and p?

a= [ex +i (9.4)
~ V 2h amuh? 9-4

a= = xX -— i—_—__—_ Pp. .
Th man? (9.5)

We will understand the physical meaning of these operators in
a moment.

We can also invert these equations:

+ mw wo:
a+a'=2 on™ this is Eq. 9.4 + Eq. 9.5

x = 4/——(a+a") (9.6)

HARMONIC QUANTUM MECHANICS 145

and

ton 1 _.
a—a' = 2i———p this is Eq. 9.4 - Eq. 9.5
2mwh

p=—i\/ rane (a—a’). (9.7)

In addition, by using the canonical commutation relation

[x, p] = ih we can calculate the commutator of a and at:3 3 It will become clear in a moment
why this is useful.

*) = aa*—ata

mu mw . 1
2h 2mwh 2° 2mwh
a ‘pte iP aac Ke
2h 2h wh

[a,a
> Eq. 9.4 and Eq. 9.5

— aR XP + age — ar
— 1 exp) = itp x) = —1 hep) = — hin
»)
=1, (9.8)

We can use these equations to rewrite the Schrodinger equation
for the harmonic oscillator (Eq. 9.3) in terms of a and at

; ; ; > Eq.9.6 and Eq. 9.7
= me (—a*at + ata + aa* — od) ¥ 4 Me (aa+ata+aat +a0°a*) ¥
= me (ata + aa‘) ¥.

We can then use the commutator relation in Eq. 9.8 to rewrite

146 NO-NONSENSE QUANTUM MECHANICS

4 At least, when the system is in an
energy eigenstate.

5 Acting with a on our state |E})
yields a new state. What we do now
is to check if the operators a and

a* change the energy. All this will
make a lot more sense in a moment.

this as follows

EY = ne ( *a+aa*) ¥
> —atatata=0

= "(ata + aa* —ata+ata)¥
2
hw iy + +
= “> (2a a+ [a,a'|)¥

h > (aa'] =1,Eq.98
1 (2a%a + 1) y
2
, D)
= hw (sta 3) Y.

What we have on the right-hand side is the quantum energy
operator. As already mentioned we usually call this operator the
Hamiltonian and denote it by H:

H=hw («*e + 3) ; (9.9)

Acting with this operator on a state that describes our system
tells us the energy of the system+:

H\E,) = Ey |E;) . (9.10)

Now, we want to understand these new operators a and a‘.
The most important thing for us is what a and a*t do when they
act on our system: a|E))=? To get a feeling for this, let’s calcu-
late the energy of such a new state>. Before we can do this, we
need one more thing: the commutator [H,a] as we will see in a

second. Using Eq. 9.8 and Eq. 9.9, we find

[H,a] = Ha — aH

HARMONIC QUANTUM MECHANICS 147

Eq. 9.9

= hw («tan + f —aa*a — d)

= hw (ata - aa* ) a
= hula’, ala
= —hwla,a*)a

= -—hwa.

Completely analogously, we can calculate

[H,a*] = hwa’ .

~

AB -— BA = [A,B]

[a,a"] = —[at,]

AD wv wv wv

[a,a*] = 1, Eq. 9.8
(9.11)

(9.12)

With this information at hand, we are finally ready to calculate

the energy of our new state a|E;):

A (a|E,)) = (Ha— aA +af) |E;) —aH +aH =0
Aa — aH = [Bq]
= aH |E,) + (A,a] |E,)
Eq. 9.10
= aE, |E,) + [Aa] |E1)
Eq. 9.11
= (E: hw) (a|E:) ). (9.13) fF
Analogously for a* we find F
a
yt _ +
Ha" |E,) = (E1 +hw)a" |E}) . 9-14) cay | dil
What do we learn here? E4thw | dat |w>
a
By looking at Eq. 9.13 we see that a|E)) can be interpreted as a P
new state with energy Ey — hw! a In?
Let’s make this more concrete. We define E-dhw aalny>
Ea) = (5) | Ya
e, lo?

148 NO-NONSENSE QUANTUM MECHANICS

with

AlEy) **2 A(a|E;))
2 Eq. 9.13
= (E, — fw) |Eo) . (9.16)

Analogously, by looking at Eq. 9.14 we see that a* |E,) can be
interpreted as a new state with energy Ej + hu,.

Specifically, we have
|E2) =a" |E;)

with :

FL \Ey) 12" (Ey + fw) |E2) .
This is why a and a* are known as ladder operators. They allow
us to move between the energy eigenstates. Using a* we can
jump to the next higher eigenstate. Using a we can jump to the
next lower eigenstate.

The non-trivial part of the Hamiltonian operator (Eq. 9.9) is
N = a'a. (9.17)

With this definition, we can rewrite the Hamiltonian in the
form:

H=hw(N+5) . (9.18)

So the operator N tells us in which energy eigenstate we cur-
rently are:

N|n)=n|n), (9.19)

where we use 1 to label the n-th energy eigenstate with energy
E,. It is conventional to use the notation |1) ,|2),...,|”) for
these states. The operators a and a‘ let us move between them
in discrete jumps.

One important thing we need to take care of is the following:
States in quantum mechanics always need to be normalized.
Otherwise, our probabilistic interpretation makes no sense since
probabilities of more than 100% do not make sense. However,
when we act with an operator on some state, we can not expect

HARMONIC QUANTUM MECHANICS

that the new state we generate this way is automatically nor-
malized, too. Instead, in general, we get something of the form

a‘ |n) =C|n+1), (9.20)

where |n) and |n + 1) are normalized states. In other words,
when we act with a* or a ona ket |n), we do not simply get

|n + 1) but possibly an additional constant factor C. So to deter-
mine completely what a and a* do, we need to determine these
constant factors. We can do this by using that |n) and |n +1)
are normalized. We first calculate®

(a* |n))* = (C|n +1))*
> In) = (a), @t)t =
(nla = (n+1\Ct. (9.21)

and can then calculate

(n| aat |n) = (n+ 1\CtC|n +1) using Eq. 9.21 and Eq. 9.20
> Cis a number, not an operator
= CC (n+1|n +1)
> (nt+1[n+1)=1
=c'tc. (9.22)

Alternatively, we can evaluate this expression using the com-
mutation relation in Eq. 9.8

(n| aa* |n) = (n| (aa —ata +a*a) |n) using —a'a+ata =0
2
= (n| ([a,a*] + ata) |n)
Eq. 9.8
= (n| (1 +a *a) |n)
> Eq.9.17
<oi(venin
= (n| (N In) +1 |n) )
> Eq.9.19

= (n| (a |n) +1|n) )

= (n|(n +1) |n)

6 Recall that (¥| = [¥)".

~ + 1is a number, not an operator

= (n +1) (n\n)
> (nin) =1
=n+1. (9.23)

149

150 NO-NONSENSE QUANTUM MECHANICS

Putting Eq. 9.22 and Eq. 9.23 together yields
(n| aa* |n) = (n| aa" |n)

> Eg. 9.22 and Eq. 9.23
ctc=n+1

C=vn+l1. (9.24)

We can therefore conclude

a’ |n) =C|n+1) this is Eq. 9.20
2 Eq. 9.24

=vVn+1|n+1). (9.25)
Following the same steps we can derive
a|n) = Va|n—1). (0.26)

This result is important because it tells us that the ladder ends.
For n = 0 we get

a|0) = VO|Oo—1) =0. (9.27)

This means that if we act with the lowering operator a on the
state with label 0, we don’t get a new state but simply 0. So
this is where the ladder ends. In physical terms this means that
there is a state with minimum energy. Acting with

A =hw (N + ) (Eq. 9.18) on this state yields

ho (w+ 3) 10)
= hw («'e + 5) |0)

= hw (0+ 3) 10)

hw
= = 10) -

Eq. 9.18
H|0) *2*

9 N= ata, Eq. 9.17

> 4|0) =0, Eq. 9.27

This means that the ground state energy of the quantum har-
monic oscillator is Eg = iw /2.

Let’s summarize what we have learned here:

HARMONIC QUANTUM MECHANICS 151

> There is a state with the lowest possible energy Ey = ". This

is the ground state energy of the Harmonic oscillator. Inter-
estingly it is non-zero, so there is always some fluctuation.”

All other energy eigenstates can be generated by acting with

+

the raising operator a" on this state with the lowest energy

+

multiple times. Each time we use a", we generate a new state

with an energy that is Aw higher than the previous one.

The energy spectrum is therefore again discrete. The distance
between the energy states is hw.

7 This leads to a curious result in
quantum field theory. As already
mentioned above, in some sense, a
quantum field is a set of infinitely
many harmonic oscillators. Now,
we just learned that the ground
state energy of a single harmonic
oscillator is non-zero, but Ey = fie
The ground state energy of a system
consisting of two harmonic oscilla-
tors is therefore hw, and the ground
state energy of a system consisting
of infinitely many harmonic oscilla-
tors is infinite. In other words, the
ground state energy of a quantum
field is infinite. However, we can
only measure energy differences
anyway and since every field has
an infinite ground state energy, we
usually simply ignore this infinite
result.

10

Quantum Systems with Spin

In all examples we discussed so far, we assumed that the par-
ticles are structureless. This means that we assumed that it is
sufficient to describe them using the variables: position, energy,
and momentum.

However, as we already discussed in Section 3.10, certain parti-
cles have some kind of internal structure known as spin.’ This
property is not always relevant and only makes a difference for
specific systems. So often we can ignore that our particles have
spin (at least in a first approximation).

But there are, of course, also systems where a non-zero spin
makes all the difference.

To understand this a bit better, imagine the following situation:

You throw a ping-pong ball to a friend who stands in front

of you. The ball is perfectly round and perfectly white. You
then ask your friend: "was the ball spinning as it was traveling
towards you?" Since the ball is perfectly round and perfectly
white, there is no way he can answer this question. In addition,
the trajectory of the ball does not depend on whether it spins

* Actually all known elementary
particles have a non-zero spin,
except for the Higgs boson.

154 NO-NONSENSE QUANTUM MECHANICS

?Just think about how big the
difference is between the trajectories
of a spinning football and one that
does not spin.

3 The electron has an intrinsic
magnetic dipole moment M

due to its spin, which is given

by M = —egsS/2m, where

8s = 2(1+a/27+4+---) denotes the
gyromagnetic ratio and « ~ 0.0073
is the so-called fine-structure con-
stant. So if there is an external
magnetic field B the electron also
has a potential energy U = —M-B
which we need to include in the
Schrédinger equation.

4We have multiple spin operators.
Each measures the spinning around
a different axis.

5

® We discussed eigenvalues in
Section 3.8.

or not - at least as long as we neglect air resistance. We can
calculate the trajectory using Newton's second law F = ma
plus Newton’s law for gravity F = —mgh and there is nothing
that changes if the ball spins. However, the internal spinning
becomes incredibly important if we change the setup a bit. For
example, if the ball collides with another ball. Another example
is when the ball is so large that its interactions with air make a
significant difference?.

In the examples above, we neglected that elementary particles
have spin. We already mentioned a system where spin is im-
portant in Section 3.10: the Stern-Gerlach experiment. Here, the
analogue to our ping-pong ball is an electron (or analogously a
silver atom). The analogue to the air surrounding our spinning
ping-pong ball is a magnetic field. Due to the presence of this
magnetic field, it makes a huge difference how exactly our elec-
tron spins. When an electron spins, it behaves like a tiny magnet
since it carries electric charge. Completely analogous to how a
magnet gets deflected in a magnetic field, our spinning electron
gets deflected3.

Lets recall quickly what we discussed already in Section 3.10:
the spin operators for an electron read*

Oi, (10.1)

where g; are the Pauli matrices>. One thing we can see immedi-
ately is that no matter how we measure the spin of an electron,
the result is always h/2 or —h/2, which we usually call "spin
up” and "spin down". This follows since the eigenvalues of each
of the three spin operator matrices are exactly h/2 or —h/2.6 In
physical terms, this means that no matter whether we measure
the spin along the z-axis, the x-axis, or along the y-axis, the re-
sult is always either 4/2 or —h/2. There are only two possible
outcomes since the spin operators are given by (2 x 2) matrices.

We now consider a concrete example of how a spin-measurement
works in the quantum formalism. We will not only discover one
crucial feature of quantum mechanics, but also get a deeper un-
derstanding of how the quantum formalism works in practice.

QUANTUM SYSTEMS WITH SPIN 155

10.1 Spin Measurements

The eigenstates of the Sz operator’ 7 We discussed the spin operators
in Section 3.10. The operators
é h hf1 0 ( ) themselves are defined in Eq. 3.58.
= 93, - — 10.2
P27 2 \0 -1
are

na).* (4) and na), (2). (10.3)

We can check this explicitly:

S |n/2), = , ( ") (:) using Eq. 10.3 and Eq. 10.2

> matrix product

A > Eg. 103

and

Ss. |—h/2), = , ( ") (") using Eq. 10.3 and Eq. 10.2

matrix product
_ —h [0
— 2 \1

—h
= 2 |-h/2), v

> Eg. 103

As always in quantum mechanics, a general state is not a spin-
eigenstate, but a superposition of the form |X) = a|h/2),+
b|—h/2),. The coefficients a and b depend on how exactly we
prepare our system.

For example, if we measure the spin along the z-axis and filter
out all particles with spin —f/2, the coefficient b is zero and a
is 1. In words, this means that after the filtering the probability
to measure the value i/2 for the spin along the z axis is 100%
since we've filtered out all particles with spin —h/2 and no
other value is possible.

156 NO-NONSENSE QUANTUM MECHANICS

Without any measurement and filtering the coefficients are

a=b= Wa which correspond to the probabilities |a|?_ = |b|? =
5 = 50% for each of the two possibilities.

Now things get really interesting if we make a measurement
along the z-axis and afterwards a measurement of the spin
along a different axis. For concreteness let’s say we measure
in this second step the spin along the x-axis. If we filter out

all particles with "spin down" regarding the z-axis, there will
be particles with spin down along the x-axis. And something
cool happens when we measure the spin along the z-axis again
after we measured the spin along the x-axis and did a similar
filtering procedure here. Even though we filtered out all parti-
cles with spin down along the z-axis in the first step, after the
filtering regarding the spin in the x-direction, we suddenly get
particles again with spin down in the z-direction.

QUANTUM SYSTEMS WITH SPIN 157

So we perform the following steps:

> We start with a spin measurement along the z-axis and filter
out all particles with spin down (—fA/2). We describe the
resulting state by the following ket

|X) after z-axis filtering = |n/2), . (10.4)

This is a state that purely consists of spin up since we filtered
out all particles with spin down. Thus, when we measure
the spin along the z-axis after this filtering we get a very
unsurprising result: the probability to measure spin —f/2 is
zero and 100% for spin +h/ 2:8 5 This is how we extract the prob-
ability amplitudes for specific out-
_ comes in the quantum framework:
z (h/2|X) after z-axis filtering ~~ 1 we multiply the ket that describes
our state from the left-hand side by

the bra that denotes the outcome.
We discussed this in Section 3.2.

\—h/2|X) after z-axis filtering =0.

> We then measure the spin along the x-axis. Since we didn’t
care about the spin in the x-direction in the first step, we
get the probabilities 1/2 = 50% for a measurement of spin
up in the x direction and a probability of 1/2 = 50% fora
measurement of spin down?. 9 We will calculate this in a moment.

> Next, we filter out all particles with spin down in the x-
direction. This means that the particle beam is then in the
state

IX) after x-axis filtering — |n/2), «

> Finally, we measure the spin in the z-direction again. Here,
we get the surprising result that the probability of measuring
spin down is no longer zero, but 1/2 = 50% instead!

So the bottom line is that the measurement of the spin in the
x-direction "produces" spin down states in the z-direction even
though we did filter all such states out in the first step. In other
words, the measurement of spin in the x-direction erases all in-
formation we previously collected about spin in the z-direction.

158 NO-NONSENSE QUANTUM MECHANICS

7° We talked already about this in
Section 3.4 and Section 3.10

™ The subscripts always denote the
axis of the eigenstate.

This is, in fact, completely analogous to how a measurement of
the momentum changes what we measure for the location’®.

We now calculate the probabilities explicitly that we already
listed in the summary above.

But before we start a few general remarks and reminders:

To find the probability to get the result —h/2 for a spin mea-
surement along the z-axis of a system described by a general ket
|X) =a|h/2), +b|—h/2),, we have to calculate’

z(—-h/2|X) = a,(-h/2|h/2), +b,(—-h/2|—h/2),=b, (10.5)
—~> —_—T

where we used that the states |/2) and |—h/2) are orthogonal
and normalized. The probability of measuring —//2 for the
spin along the z-axis is then P,__y/2 = |b|*. If we want to
measure the spin along another axis, say the x-axis, we first
need to expand our state in terms of the eigenstates of S,. This
operator reads in explicit matrix form (Eq 3.58)

{0 h/2
= (yo °).

The corresponding normalized eigenvectors are

In/2), =p ()) and |-W/2), =, (1). (10.7)

So if we want to calculate the probability to measure —f/2 for
the spin in the x-direction, we first need to rewrite |f/2), and
|—h/2), in terms of |h/2), and |—h/2),:

(10.6)

1
\n/2), = 5 (|h/2)s + |—h/2),)
since we ( == ( (= ()+¥ ‘al :)) (Eq. 10.3 and Eq. 10.7)
|-n/2), = 5 (Ih/2)- |-n/2),)
since (') = =(= ()) ss ( 1 )) (Eq. 10.3 and Eq. 10.7)
1 J2\V/2 J2\-1

QUANTUM SYSTEMS WITH SPIN 159

Our general state reads in this new basis’?

|X) =a|h/2), +b|—-h/2),

1 1
a (|h/2)x + |-R/2)y ) +b; (h/2), = |-R/2), ).
The probability amplitude to measure —f/2 for the spin along
the x-axis is therefore}

a (\t/2), +|-h/2), )

+b ([h/2), —|-W/2), ))

a b
= a _ 71 . (10.8)

-(h/2|X) = .(-h/2| (+5;

After these general remarks, we are finally ready to calculate the
probabilities for the example we discussed at the beginning of
this section.

We start by filtering out all particles with spin down in the z-
direction. The resulting ket is

|X) after z-axis filtering = |n/2), : (10.9)

Using our formula from above, we see immediately that the
probability to measure —h/2 for the spin along the x-axis is*4

1 0
Pyo-n/2 = IF — al =1/2.

We then filter out all particles with spin —f/2 in the x-direction.
The resulting ket reads

|X) after x-axis filtering = \n/2), : (10.10)

The crucial question is now: what's the probability to measure
—h/2 for the spin in the z-direction?

To calculate this, we first need to write |h/2), in terms of the
z-basis states |h/2). and |—h/2),:

What we do here is a basis change
from the basis which is given by the
eigenvectors of S, to the basis that
is given by the eigenvectors of S,.
We discussed such a basis change
already in Section 3.3.

3 The probability is

a b»
Py aj = 5 - WA

“4 Here we use Eq. 10.8 with a = 1
and b= 0.

160 NO-NONSENSE QUANTUM MECHANICS

|X)

* Think: two vectors that either
point in the same or in opposing
directions. Adding them yields
something large in the first case and
zero in the second (if the vectors
have the same length).

*© In Section 7.3 we ignored such
effects completely. However, they
can be treated as additional correc-
tions and we will talk about how
we can include such corrections in
Chapter 12.1.

after x-axis filtering —

Ih/2), = ([h/2), + |-/2),)
. 1/1 1 1 0
= ()- a0) 0)

The probability to measure —f/2 is therefore

six

(Eq. 10.3 and Eq. 10.7)

P,=-n/2 = |,(—h/2|X)|? = 1/2 £0.

So, as promised, a measurement of the spin in the x-direction
erases all information we previously gathered for the spin in
another direction. As a reminder: We filtered out all particles
with spin down in the z-direction in the first step. Nevertheless,
in the final step, we get a non-zero probability to measure spin
down in the z-direction. This is a result of our measurement

of the spin in the x-direction since without it the probability to
measure spin down in the z-direction would be zero.

Another important aspect of quantum mechanics that we
haven’t talked about so far are systems in which more than
one particle with spin is present. In such systems, there are
various ways how the individual spins of the particles can add
up to the total angular momentum of the system*. In the next
section we discuss how we can calculate the probabilities to find
the system with different values of the total angular momen-
tum. This is important, for example, for the hydrogen atom.
The proton and the electron both have spin 1/2, and there are
various possibilities how they can add up. Depending on their
relative alignment the energy of the electron is a bit higher or
lower. So a detailed understanding of how spins add up allows
us to calculate the energy spectrum of the hydrogen atom (and
lots of other systems) much more precisely.1®

QUANTUM SYSTEMS WITH SPIN

10.2 Spin Addition

For concreteness, let’s consider two particles with spin 1/2. We
already know that for such spin 1/2 particles there are always
only two possible spin alignments: spin up |t) or spin down
||). We are now first interested in the total spin of the system in
the z-direction. The possible arrangements of the two spins are
as follows:

Tt, Th Lt Lt -

Here the first arrow represents the first particle (say, the elec-
tron) and the second arrow represents the second particle (say,
the proton).

What values will we measure if the spins align like this?

The spins in the z-direction simply add up:*7 7 Reminder: $, |m) = hm |m) .

Seta = (si + s) Pate = (fy) Yr+ 1 (spo)
= (hy pi) $2 + pr (mapa) = h (my + mz) pir.

The possible values for the overall spin in the z-direction are

therefore
tt: m=1
tl: m=0
Lt: m=0
tl: m=-1

The physical interpretation of this observation is that the two
spin 1/2 particles can form together a system with a total spin
of 1 or a total spin of 0. For the spin 1 case, we can measure for
the z-components the values —1, 0 or 1. We say the state is ina
triplet state and denote it by

1) =tt
No) = —Neaut
— V2" V2

1-1) =.

161

162 NO-NONSENSE QUANTUM MECHANICS

% The discussion from above works
completely analogously if we
consider, for example, the addition
of orbital angular momentum and
the spin of a particle.

On the left-hand side, we have kets that describe the total sys-
tem. The first number is the total spin of the system and the
second number is the z-component. On the right-hand side we
can see how the system is constructed in terms of the spins of
the individual particles. The factor 5 is a normalization con-
stant that makes sure that the overall probability is exactly 1.

In words, this means that if the complete system consisting

of the two particles is in the |10) state, there is a 50% chance

to find the spins aligned like this: t{ (first particle spin up,
second one spin down), and a 50% chance to find them like this:
Lt (first particle spin down, second one spin up). The other
possibility is that the complete system has a total spin of zero.
In this case, we say the system is in a singlet state. In terms of
the individual spins this state reads

1 1

Be

So the only difference to the |10) state is a minus sign, which

|00) = tt.

however is crucial if we determine the energy levels, for exam-
ple, in the hydrogen atom.

We will not discuss how these factors can be calculated in detail.
These numbers —., —- etc. are known as Clebsch-Gordan
coefficients. They tell us how a system looks like in terms of
the individual angular momentums that it consists of.t® There
are clever and general methods to calculate Clebsch-Gordan
coefficients. However, for almost any system you can imagine
someone has already calculated them and therefore, you can
simply look them up in a table.

11

Further Systems

There is, of course, an infinite number of quantum systems we
did not discuss here. Most of them do not teach us anything
new and contain the same lessons hidden behind more compli-
cated mathematics. However, some of the additional systems
are so famous that you should know about them nevertheless.
In addition, some examples are extremely useful to understand
more advanced concepts in a simplified setup. So before we
move on to the next part where we discuss clever methods to
deal with more complicated systems, in this section we will talk
about other important quantum systems that we do not discuss
in detail.

But first, a short comment on the general pattern:

The main task is always to solve the Schédinger equation for
different potentials. For each different system (= different poten-
tial) our task is therefore to solve a different differential equa-
tion. This task is often far from trivial and nothing students can
do in an hour or so. In fact, mathematicians are much better at
solving differential equations and most of the time we physicists
simply use their solutions. You can see that the solutions of the
Schrédinger equation for a system are far from trivial if they

164 NO-NONSENSE QUANTUM MECHANICS

* The boxes etc. we discussed are
merely toy models and nothing we
can really observe in nature.

? Reminder: for spherically sym-
metric potentials we can split the
variables r and 6, p and then get
two equations: one which only de-
pends on 6, ¢@ and another one that
only depends on r. The solutions of
the former one are special functions
called the spherical harmonics. This
is true for all spherically symmetric
systems.

are named after some person or have at least a special name.
Examples we already encountered are the spherical harmonics,
the Hermite polynoms, and the Laguerre polynoms. So as soon
as we have written down the Schédinger equation for some sys-
tem, we should always check if it corresponds to a well-known
differential equation. Then we can check how the mathemati-
cians solved the problem or simply use their solutions. How-
ever, for almost no realistic system such exact solutions exist’.
The main idea is then to use the solutions of a similar system
that can be solved analytically as a starting point and treat the
differences between the two systems as perturbations. This is
what we will discuss in the next chapter.

Now, as promised, a few comments on other famous quantum
systems and the related buzzwords you should have heard
about:

[> Three Dimensional Boxes: While we only discussed one-
dimensional boxes, there is nothing really new in two or
three dimensions - only a bit more complicated mathematics.
A popular example is a particle confined in a three dimen-
sional spherical ball. This means that V = 0 forr < a and
V = © otherwise.

As we discussed in Section 7.3, the only thing we have to
do is to solve the radial Schédinger equation since the po-
tential is spherically symmetric”. This equation, however,

is extremely complicated to solve and the general solutions
are another kind of special function called spherical Bessel
functions. If we then want to determine the energy spec-
trum of this system we can use that the wave function has to
vanish at r = a.3 Therefore we get a condition of the form
¥(a,0,¢) ~ 0. Then we use that the general solutions look
like ¥ « jn(kr)Y;"(8, @), where jn (kr) are the spherical Bessel
functions and Y;"(6, @) the spherical harmonics. Our condi-

tion ¥ (a, 6, 9) ~ 0 then tells us immediately that j,(kr) has

to vanish at r = a: jn (ka) ~ 0. Then, all we have to do is to
look up where the zeroes of the spherical Bessel functions
are and use that k = \/2mE/h’. For example, for n = 1 one
zero is at x ~ 4.49. This tells us that one energy level is at
E = hi? /(2ma?) - 4.49? since

ji(ka)=0 and j,(4.49) =0

= ka+449
\| ar + 4.49
' ig 2
E+. .4.49?.
> 2ma2 9

All other allowed energy values correspond to other zeroes of
the spherical Bessel functions. The additional indices m and |
in the wave function denote the total angular momentum and
the z component of the angular momentum? of the particle
described by ¥ « jn(kr)Y/"(0,~). So in summary, we get a
quantized energy spectrum again as a result of our boundary
condition at r = a, analogous to the one dimensional case.

The Quantum Pendulum: In the limit where we only con-
sider small displacements the pendulum is very similar to
the harmonic oscillator. However, even at low energies, there
is something a quantum pendulum can do that a harmonic
oscillator cannot. A pendulum can perform a rotation around
its anchor point. Classically a lot of energy is necessary for
such a rotation. However, in quantum mechanics the pendu-
lum can tunnel through this potential barrier. An important
aspect is that after such a full rotation the pendulum is not

FURTHER SYSTEMS 165

3 This is completely analogous to
what we did for the one dimen-
sional box. The potential is infinite
for r > a. Therefore, the wave
function is zero in this region. The
non-zero wave function inside the
box has to connect smoothly to the
zero-solution on the outside.

4 See Section 3.9 and Section 7.3.

166 NO-NONSENSE QUANTUM MECHANICS

5 Quantum Chromodynamics (QCD)
is the correct quantum field theory
that describes strong interactions,
e.g., how quarks interact with each
other.

® Perturbation theory is the topic of
the next few sections.

7 Mathematically, a series with
these properties is known

as an asymptotic series. To

learn more about this try

http: //jakobschwichtenberg. com/

divergence- perturbation-series-qft/.

8 A quantum field with spin zero,
in some sense, is an infinite set of
coupled harmonic oscillators.

9 For example, one of the most
famous toy models in quantum field
theory - called Sine-Gordon model

- describes a bunch of coupled
pendulums.

*° This system is incredibly impor-
tant since it is analogous to the
situation which we have for an elec-
tron in a crystal. The crystal nuclei
are much bigger than the electrons
and form a lattice. Therefore, they
provide a periodic static back-
ground potential for the electrons
in the crystal. The wave functions
in this context are known as Bloch
waves.

necessarily in the same state where it started. Instead, it can
pick up a phase. This phase can become physically impor-
tant, and this makes the pendulum an ideal toy model to
understand, for example, the famous quantum phase 6 that
characterizes the ground state of Quantum Chromodynam-
ics>. In addition, the pendulum is a nice toy model to under-
stand why the perturbation series® in quantum field theory
yields infinity if we add all terms together, but yields sensible
results if we only take the first few terms.” While the har-
monic oscillator is a nice toy model to understand quantum
fields with zero spin®, the pendulum is a perfect toy model to
understand quantum fields with non-zero spin?. The formula
for the potential energy of a pendulum is V « (1 — cos¢) and
the corresponding stationary Schrédinger equation (Eq. 6.5)
therefore reads

W y(¢9) _
— am age + VOY = EV)

no?
2m “ — mgl(1—cos$)p($) = Ey(¢). (11.1)

When we consider the pendulum system, the relevant vari-
able is the angle ¢ which only takes on values from 0 to 271.
However, it is also possible to consider the same Schrédinger
equation for a general x which takes on any value from —oo
to oo. In this case the Schrédinger equation describes a par-
ticle in a periodic potential’®. The Schrédinger equation for
the pendulum is extremely difficult to solve because of the
cos() term. In mathematics there is a completely analogous
differential equation which is known as Mathieu’s differ-
ential equation. As always, the fact that this equation has a
special name already indicates that it is far from trivial. The
special functions that solve this equation are known as Math-
ieu functions. Therefore, although the system looks quite
simple it is non-trivial to solve in quantum mechanics.

The driven Harmonic Oscillator: This system is just a spring
with a motor attached to it. It is useful to understand the in-

terplay between quantum theories and gravity. Since the cor-
rect theory of Quantum Gravity is not known yet, we have to

use clever tricks to get some insights how quantum theories
and gravity could fit together. The driven harmonic oscilla-
tor is a nice analogue to a quantum theory with an external
source, like the gravitational field, which is still treated clas-
sically. Using this toy model it is possible to understand, for
example, how in the quantum field theory vacuum, particles
can be produced if a gravitational field is present. Famous
examples of this effect are the Hawking radiation and the
Unruh effect.

FURTHER SYSTEMS

167

12

When the Going Gets Tough,
the Tough Lower Their Stan-

dards

The title of this chapter is actually a quote from a brilliant book
by Sanjoy Mahajan’. And he continues: "Approximate first, and
worry later". This is exactly what this chapter is about.

The main idea is that often it is absolutely essential that we

get rid of our desire to know everything exactly. As already
indicated at the end of the last part, often it is simply impossible
to find an exact solution; especially for any kind of realistic
system that we can actually observe in nature. To be able to

say anything at all about such systems we need to lower our
standards. The best we can do is find approximately correct
answers.

This is not really problematic since in practice we are never
able to measure anything exactly anyway. So as long as the
error we introduce through our approximations is smaller than
the experimental errors, everything is fine. In addition, the

*Sanjoy Mahajan. The art of insight
in science and engineering : mastering
complexity. The MIT Press, Cam-
bridge, Massachusetts, 2014. ISBN
978-0262526548

170 NO-NONSENSE QUANTUM MECHANICS

2 There are, in fact, whole books on
this topic. So not only on perturba-
tion theory but also whole books
on perturbation theory in quantum
mechanics!

3 We use the Taylor expansion:
cos(x) # 1— x + x —.... See
Section A.

4 Consider, for example ¢ = 0.1.
Then we have ¢? = 0.01,

¢* = 0.0001, ° = 0.000001.
This observation tells us that we
do not make a huge mistake if we
ignore higher order terms.

magnitude of the approximation errors usually depends on how
much time we are willing to spent. So with more effort we can -
if we want - calculate the results with higher accuracy.

There is a huge toolbox that we can use to calculate approxi-
mately correct answers*. We will once more focus on the basic
ideas behind approximation methods and only comment on
more advanced methods.

12.1 Perturbation Theory

While above I indicated that approximation methods are es-
pecially useful for realistic systems, we will once more stick to
simpler toy models. In more realistic systems, the core ideas are
too hidden behind complicated formulas.

What we try to do now is to calculate corrections to previous
results that arise when our systems become a bit more realistic.
For example, we want to calculate the energy levels for an infi-
nite box when the potential inside the box is not everywhere the
same. Another example could be if the potential of our system
only looks approximately like the potential of a harmonic os-
cillator. This is, for example, the case for a pendulum. As long
as the pendulum swings a little the harmonic oscillator poten-
tial is a great approximation. However, upon closer inspection,
the pendulum potential and the harmonic oscillator potential
do not agree exactly. We can see this mathematically by Taylor
expanding the pendulum potential>

-cospx1-(1-£ 4%.) _#
Val—cos¢?x1 ( 7 t+ a J = moto

(12.1)
For small displacements of the pendulum ¢ higher order terms
are smaller than low order terms.* So if we don’t care about
details V « ¥ is a good approximation. This is exactly the
potential of a harmonic oscillator. However, if we want to calcu-
late, say, the energy levels more exactly we should, at least, take

4
the term « f into account, too. So the resulting Schrédinger

WHEN THE GOING GETS TOUGH, THE TOUGH LOWER THEIR STANDARDS

equation reads

hn 3?
-= oe — mgl(1—cos$)p(¢) = Ep(¢)

> Eq. 12.1

hi a2 2. 4
— oP — ml (F - t) o(p) © Ep()
> definitions

(Ho + Vi) p(p)  Ep(9), (12.2)

where we have defined the unperturbed Hamiltonian

2 2 2
EPH) _ gi

2m dag?

¥(9)

and the perturbation

¢*
VY, = mgl 99).
The system described by the Schrédinger equation in Eq. 12.2 is
known as the anharmonic oscillator. Ho is exactly the Hamil-
tonian of the harmonic oscillator and if we ignore V; for a mo-
ment, we already know the exact solutions to this problem.

Therefore, our task is to use this knowledge to calculate the
energy levels and wave functions of the anharmonic oscillator,
i.e. when we additionally take the new term V, into account.

Formulated differently, we now want to do the following:

Given the energy levels Eo) that correspond to the unperturbed

Hamiltonian Ho, what are the eigenvalues if we take a perturba-
tion like V; into account?

There is a general method to calculate the corrections to the un-
perturbed eigenvalues and this is the topic of the next section.

12.1.1 General Perturbation Formulas

In general, the situation we are now interested in looks like this

H=Ho+AV, (12.3)

171

172 NO-NONSENSE QUANTUM MECHANICS

5 This will make more sense in a
moment. The basic idea is that A
helps us to remember how large
the error is we are making with our
approximations.

6 This is simply the stationary
Schrédinger equation (Eq. 6.5).

7 This looks somewhat familiar if we
recall what we usually do when we
calculate a Taylor series.

° For simplicity, we only consider
the terms proportional to A explic-
itly.

where H is the Hamiltonian for the full system, Hp the Hamil-
tonian of a system that we have already solved and V is the
difference between the two. Here, A is a parameter that we in-
troduce to keep track of the order of perturbation theory.> The
main idea is that everything we do here only makes sense if V is
in some sense small relative to Ho. In particular, this means that
our system is very similar to the system described by Hp and
there is only a small difference between H and Hp. In practice,
this means that A is some small parameter that indicates that V
is smaller than Ho.

Our goal is to calculate the energy levels E, of this system
which correspond to the eigenvalues of H:6

H |n) = En |n)
> Eg. 123
(Ho + AV) |n) = En |n) . (12.4)

where |/) are the corresponding eigenstates. This whole proce-
dure only makes sense if we already know the solutions to Ho:

Ho |1t)y = En” |11)q - (12.5)

Our basic task is to calculate corrections to |1) (0) and EO).
Since we use the parameter A to label the magnitude of the dif-
ference between Hp and V, we also make the following ansatz
for the states”

|n) = |n)g tA|n), +A? |n)o +... (12.6)
and for the energies
En = FO) + AB 4 a2E@ 400, (12.7)

We call |n), and E\) the first order corrections, |n)> and gE?)
the second order corrections and so on. Next, we simply put
these ansatze into our Schrédinger equation (Eq. 12.4)°

WHEN THE GOING GETS TOUGH, THE TOUGH LOWER THEIR STANDARDS 173

(Hp + AV)|n) = En |n)

> Eq. 12.6
(Ho +AV)(|2)o +A |n), +...) = En(\n)o +A (2), +...)
> Eq. 12.7
0 1
(Ho FAV) (|n)y Ala), +...) = (EO + AEM +...) (|n)g An), +...)
(0) (1) (0) °
Ho |") + AV |n)9 +AHo |n)y +... = En’ |t)o +AEn’ |n)g +AEn’ |n), +...
Now, we can see why the parameter A is useful. Since by as-
sumption A is smaller than one we can use it to rank the various
terms by their relative importance. The terms without A are
the most important ones. The second most important terms are
those that get multiplied by A, then the terms proportional to A?
and so on?. So first of all, we collect all terms without A: 9For A < 1 we have
0 1<A<M<...
Ho |) = EX” |n)q - (12.8)
This is exactly Eq. 12.5 from above. t© We could equally collect those
terms with A? in front of them etc.
; ; 10 and this would yield formulas for
Then we collect all terms with A in front of them: the higher order corrections. If you
(1) (0) want to do this, take note that there
AV |n)y +AHo |2), =AEn’ |N)g + AE,’ |n), are additional terms proportional
> x to A? that only appear implicitly in
Vin Haln). — FO) n FO) n),. 12. the equations above since we didn’t
| )o + Ho | M ” | )o + En | M (12.9) include the A? |), and A2E?) terms
(1) explicitly.

What we now want is an equation for E,,’ since these are the
dominant corrections to the energy levels E©. A clever idea’! is We will see in a moment why this

to multiply Eq. 12.9 by 9(n|: is a clever idea.

o(| V |n)9 + o(n| Ho |n), = o(n| EX” [n) + o(n| EO |n),

o(n| V |) + pin Ee Ta), = o(n| EL? |n)o + gi EO Ta),

> Eq. 128
(1) ’
o(t| V |n)o = o(n| En’ |1)o
D)
D)

EY) is a number, not an operator
o(t| V |) = En” o(|n) 0
o(2|n) 9 =1
o(tt| V [t)y = En.
So what we are left with is exactly what we want: an equation
that tells us how we can calculate EM, It’s simply the expec-

174 NO-NONSENSE QUANTUM MECHANICS

* Or alternatively how the wave
functions change.

% The calculation that follows is a
bit more involved. So if you’re only
interested in the basic ideas, you
can skip it and jump directly to the
example.

™4 We discussed basis changes in
Section 3.3.

tation value of the perturbation potential V with respect to the
unperturbed state |1) 9:

(12.10)

Following analogous steps it is possible to derive formulas
for BE, EP), ... up to any order we want. For example, the
resulting formula for the second order corrections reads

| o(m| V |n)o |?
FO) _ pO)

EY =

(12.11)

mAéAn n — =m «

It is clear that the formulas for higher order corrections are in-
creasingly complicated. So we always only calculate as many
corrections as we need to compare our calculations to experi-
mental results. Often the first and second order corrections are
enough.

Now, before we have a look at a simple example, there is one
more thing we need to discuss.

What we did so far is calculate corrections to the energy levels
EO), Following similar steps we can also calculate how the
kets |) change in the presence of the perturbations”, i.e., the
corrections |1),, |1)», etc.

To calculate the first order correction to the unperturbed kets,
we start again with Eq. 12.9" and our first step is to rewrite it
as follows

V |) + Ho |n), = EY? |n)y + ES |n),

(V — El) |n)) = —(Ho — EM) |n), - (12.12)

Everything on the left side is known, so this is a differential
equation for |n), that we have to solve. The crucial idea is that
the unperturbed kets |n),) are a complete basis. This means

that we can write every possible state in terms of these kets.
Therefore, we can also write the perturbed states in terms of the
unperturbed states"

WHEN THE GOING GETS TOUGH, THE TOUGH LOWER THEIR STANDARDS 175

\n), = Yo cum |m)o - (12.13)
m
So now, our task is to calculate the coefficients cym.
We put this ansatz into Eq. 12.12
(V — EN”) |n)y) = —(Ho — En”) |),
> Eq. 12.13
= —(Hy — EL) cam |m) g
m
; 2
=~" camHo |) + Y camE® |m)o
m m
> Eq. 12.5

m

To isolate the coefficient Cym we multiply this equation by 9(I|
and then use that these basis states are orthogonal’:

o(l| (V — EY?) |n)9 = — 9 (l| Vecnm(EW) — B®) |r)
m

5 (1 |m) 9 = 51m where 5}, denotes
the Kronecker symbol which is 1 for
1 = m and zero otherwise.

>) Cum, ES ) £0) are numbers

= = Ycam(EQ — B®) g(t|m) o
m

») o(!|m) o = 51m

= ¥en (ES) _ EY orm
m

= oy (E) — £0).
And we can conclude

o(l| (V= En?) |r) _

(EO ~ £0) Cul- (12.14)

We can put this result back into Eq. 12.13 and this yields

(12.15)

This is the formula that we can use to calculate how the first
order perturbations to our unperturbed kets |), look like.‘

Next, let’s have a look at a simple example.

*6 Take note that we used in

our derivation the stationary
Schrédinger equation. This means
that our equation here is only
valid for systems where the poten-
tial does not depend on the time.
Moreover, the system makes no
sense when two unperturbed en-
ergy states have the same energy:
Eo) = Eo) for some m # n. In
this case our formula yields infinity.
For such systems there are other
methods and we will talk about
them in Section 12.2.

176 NO-NONSENSE QUANTUM MECHANICS

7 Here we ignore the time-
dependent part, i.e., we only focus
on the solution of the stationary
Schrédinger equation.

8 To get to the second line we use
that we can always switch to an
explicit basis such as the position
basis. The resulting coefficients in
this basis are the wave functions
n(x). This was shown explicitly
in Eq. 3.28.

12.1.2. The Perturbed Infinite Box

Let’s imagine there is a perturbation across half of the infinite
box that we discussed in Section 7.1.

V(x)

Vo

The unperturbed energy eigenstates are (Eq. 7.5)'7

(12.16)

Yn(x) © = psn (Fx)

and the corresponding unperturbed energy levels are (Eq. 7.6)

nh
E, = 722m (12.17)

Using the general formula (Eq. 12.10) we can immediately calcu-
late the first order corrections to these energy levels'®

WHEN THE GOING GETS TOUGH, THE TOUGH LOWER THEIR STANDARDS 177

En = o(n| V [no
1 > Eq. 3.28
= [ ax(u(2))*Vpn(z)

L/2 L
=f ax(u(2))Vopn(x) + [ dx(palx))*V p(x)

>) V(x) =0forx€ 5-4

~ [ Ax (n(x) )* Vopn(x)©

= TP asin? (Ex)

_ 2Vo (L _ sin(Ln7/L)
~ EL \4 4n7/L

Yo

7

> Eg. 12.16

») [ sin? (xB) = ‘ - sin Ab)

> sin(nz) =0

This result does not depend on n and therefore each energy
level is simply shifted by the constant amount Yo - at least in
the first order approximation. This result gives us some confi-
dence in our formula since this is what we would have naively
expected.

12.2 What Other Tools Do We Have?

A complete discussion of all existing quantum approximation
methods is enough content for at least one complete book. So
like in the previous chapters, let’s discuss only the main ideas
and buzzwords. If you are interested in further details, you can
find them in the textbooks recommended in Part 16.

> The formulas we derived in Section 12.1.1 are only valid if
the Hamiltonian is time-independent since we used in the
derivations the stationary Schrédinger equation. There are, of
course, also methods to deal with perturbations for systems

178 NO-NONSENSE QUANTUM MECHANICS

with a time-dependent Hamiltonian. These tools are known
as time-dependent perturbation theory. We need these tools,
for example, to calculate the rate at which an excited atom re-
turns to its ground state. Formulated differently, to calculate
how often a quantum jump happens. Other important appli-
cations of time-dependent perturbation theory are scattering
processes. The most famous example is a photon that scatters
off an electron or atom. In the latter case, it’s possible that the
photon gets absorbed and then emitted again. It is possible
to calculate the absorption and emission rates and these are
especially important in the context of lasers. One main result
is Fermi’s golden rule

27 .
Ting = | (fIVIi) Pe,

which expresses the probability I';_,- that the initial state i
becomes the final state f. V is the time-dependent perturba-
tion of the Hamiltonian and p the density of final states.

> Itis also possible that an electron scatters off an atom and no
absorption happens. In this case the main goal is to calculate
the probability that the electron gets deflected by a certain
angle. The corresponding probability amplitude is usually
called scattering amplitude. The main approximation meth-
ods in this context are known as partial wave analysis and
the Born approximation. One main idea is that we model the
atom or whatever we are scattering at by a spherical poten-
tial:

vin={ yt r<a
0 r>a.

The next idea is then that our incoming particle is given
by a plane wave and after the scattering we have outgoing
spherical waves.

WHEN THE GOING GETS TOUGH, THE TOUGH LOWER THEIR STANDARDS 179

This motivates the ansatz
eikr
YHA + f(0)—

where e!* is our incoming plane wave and “ the outgo-
ing spherical wave. The goal is then to calculate f(@) which
is the amplitude to find the scattered particle at an angle 6.
One main result of the partial wave analysis is that our scat-
tered wave is given by special functions known as spherical
Hankel functions times the usual spherical harmonics. We
expand the general result in terms of these functions and the
coefficients C; in this expansion are known as partial wave
amplitudes. The amplitude that we want to calculate f (0) is
directly proportional to these amplitudes:

foe)
L(- iy] att 1 CP,(cos8)

where P;(cos@) are special functions known as Legendre

nie

f(9) =

polynomials’9. The main idea that we use to calculate these
C; is once more that inside the spherical potential we have

a different wave function than outside of it and that the two
kinds of solutions must match up. The Born approximation is
a lot more complicated and quickly leads us into the terrain
of quantum field theory.

Another instance when our formulas from Section 12.1.1
fail is if two or more states of the unperturbed system corre-

*9 The spherical harmonics are de-
fined in terms of these polynomials.

180 NO-NONSENSE QUANTUM MECHANICS

(1)
20 _ y(m|(V-En Mo
1). = Lngn (£0 £0) |111)q -
ar p(2) _ lo(m|V|1) 9/2
Ex = Lmgén EO 0)

22 We shortly talked about the
hydrogen atom in Section 7.3.

3 You can find a full discussion and
derivation of the Dirac equation in
my book

Jakob Schwichtenberg. Physics
from Symmetry. Springer, Cham,
Switzerland, 2018. ISBN 978-
3319666303

spond to the same energy level. In such systems, we say that
the energy levels are degenerate. We can see that in such sys-
tems our formulas fail to produce sensible results by looking
at Eq. 12.157° or Eq. 12.1177. If two energies £0 ) and £ are
equal, we get naively, infinity as a result. The methods that
let us make sense of this result and calculate sensible correc-
tions for such systems are known as degenerate perturbation
theory.

One of the most important applications of degenerate pertur-
bation theory are corrections to the spectrum of the hydrogen
atom.”? For the naive Hamiltonian we talked about in Sec-
tion 7.3 there are various states with the same energy. (An
exception is the ground state which is non-degenerate.)

How can there be different states with the same energy?
Well, these various states with equal energy are character-
ized by different angular momentum quantum numbers. In
physical terms, this means that they correspond to different
ways how the spin of the electron aligns and adds up with its
orbital angular momentum.

Upon closer inspection, we notice that different angular mo-
mentum quantum numbers also lead to slightly different
potential energies. The spin-orbit interaction is described
by a new term in the Lagrangian which we can treat as a
perturbation to our naive Hamiltonian. The naive Hamil-
tonian only includes the Coulomb potential. If we take the
spin-orbit interaction into account, the states with previously
the same energy have now different energies and we say the
degeneracy has been lifted. Other similarly important correc-
tions come about since we didn’t use the correct relativistic
energy-momentum relation. The correct relativistic equa-
tion to describe electrons is the Dirac equation and not the
Schrédinger equation.?3

The Dirac equation takes correctly spin and the relativistic
energy-momentum relation into account. We can expand the
Dirac equation on a non-relativistic limit and what we end

WHEN THE GOING GETS TOUGH, THE TOUGH LOWER THEIR STANDARDS 181

up with is the Schrédinger equation plus higher order cor-
rection terms plus a spin term. The spin term describes the
spin-orbit interaction we talked about above. The two other
equally important correction terms are known as Darwin
term and kinetic energy correction.

Together, these corrections are known as fine-structure of

the hydrogen atom. Of course, it is also possible to go be-
yond that and consider, for example, corrections due to the
interaction of the magnetic moment of the electron with the
magnetic moment of the proton. The resulting corrections are
known as hyperfine-structure.

Another handy approximation tool is the so-called WKB-
method*4. The crucial idea is to make use of the smallness of
the Planck constant h. To say something is small, of course,
only makes sense relative to something else and hi is tiny
from our macroscopic perspective. So the WKB-method is a
semi-classical approximation method”.

This means that we treat the system almost as if it were a
classical system and then include quantum effects only as
corrections. The corrections are given in a power series in h,
and the whole procedure only makes sense for highly excited
states, i.e., large n states?®.

24 WKB stands for Wentzel-Kramers-
Brillouin who popularized the
method.

5 On a first glance, something very
confusing is that one of the most
important applications of the semi-
classical approximation is in the
context of tunneling phenomena.
For example, we use the semi-
classical approximation in quantum
field theory to investigate instanton
configurations, which are tunneling
processes. However, this is possible
through a clever trick known as
Wick rotation which flips our
potential. The behavior in the
classically forbidden regions can
then be investigated by the semi-
classical approximation since
through the potential flip these
regions become classically allowed.

6 Recall that n is the quantum
number we use to label energies E,,.

182 NO-NONSENSE QUANTUM MECHANICS

Part III
What Your Professor is Not
Telling You About Quantum Mechanics

"As with all true and deep physical effects, there are many ways of arriving
at the results.”

Roman Jackiw

PS: You can discuss the content of Part III with other readers, find exercises to check your
understanding and give feedback at ww.nononsensebooks . com/qm/part3.

So far we've only talked about one possible way to describe
what is going on in the quantum world. And most textbooks
talk exclusively about this approach. The method we used so far
is usually called the wave function formulation.

However, this is not the only possible formulation of quantum
mechanics and in this final part of the book, we will talk about
alternative formulations. The situation is analogous to how we
can describe classical mechanics either using Newton’s formal-

ism, the Lagrangian formalism or the Hamiltonian formalism?7. »7 There is a one-to-one corre-
spondence between the various

formulations of classical mechanics
Maybe you wonder: why should I care? I already learned one and the different formulations of

framework that works. So why should I learn anything else? quantum mechanics. There is even
a formulation of classical mechan-

ics that is analogous to the wave

There are two excellent reasons: function formulation of quantum
mechanics! We will talk about this
in detail in a moment.

> Firstly, it is much easier to describe certain systems in one
formulation than in the others. This is analogous to how
in classical mechanics the generalized coordinates of the
Lagrangian formulation often make a problem much simpler
than in the Newtonian formulation.

> Secondly, knowing the various formulations and how they
are connected is extremely useful when you want to think
about what quantum mechanics really means. In too many
discussions people argue about aspects of the wave func-
tion and act as if wave functions were something real. If
you know that we can describe what is going on in quan-
tum systems completely without wave functions, you will
understand that wave functions are merely a convenient
mathematical tool.

Before we start, we should pause for a minute and think about
what we want to achieve.

First of all, take note that in the following sections, we only
talk about different mathematical formulations of quantum
mechanics and not about different interpretations?®. These dif- *8 The various interpretations of

ferent formulations all agree in terms of what they predict for Gwe are the topic of
apter 15.

186 NO-NONSENSE QUANTUM MECHANICS

experiments. Only the calculations which we use to get these
predictions are different. So none of them is the correct one.

The crucial idea that will allow us to describe quantum systems
in quite different ways is that there are various mathematical
arenas that we can use as the stage where our description of
physics takes place. We will discuss various mathematical are-
nas that are useful in physics in the next chapter. Afterward, we
will see how different the rules of quantum mechanics in the
various arenas are.

13

Mathematical Arenas

The simplest arena we can use to describe nature is the three-
dimensional physical space we live in’. In physical space, we
describe the location and the momentum of each object using an
individual vector. These vectors all live in the same arena that
we call physical space.”

For simplicity, let’s consider an object which moves in just one
dimension. Our mathematical arena is then simply a line (IR):

+" 9 __> SO

Now, if we want to describe two objects which move in one
dimension the first method that comes to our mind is to use two
vectors:

* To be precise: by physical space
I mean the usual Euclidean three-
dimensional space R? or R if for

some reason our objects can only
move in one-dimension.

? All this will make a lot more sense
as soon as we talk about alternative
arenas.

188 NO-NONSENSE QUANTUM MECHANICS

3 We also need only two vectors if
there are three or even more objects
in the system.

In addition to two vectors that keep track of the locations, we
need two further vectors that keep track of the momenta.

This is what we do, for example, in the Newtonian formulation
of classical mechanics. Such a description in physical space is
handy since we can immediately understand everything that

is going on in the system. Each vector is simply an arrow that
points from one location to another. However, in practice, this
approach is often laborious - especially when we are dealing
with lots of objects.

So how else could we describe our system consisting of the two
objects that move along a line?

What we need, mathematically, is a tool that allows us to keep
track of the locations and momenta of the two objects. In phys-
ical space, we need four vectors to accomplish this: two for the
locations and two for the momenta.

Using the following idea, we can describe the whole system
with just two vectors?.

> Firstly, we act as if there were a separate arena for each ob-
ject:

re
——— s
ns

ne
a eaean
2

> Then we glue these separate spaces together:

ttt =

xR R

>

VY

MATHEMATICAL ARENAS 189

So in particular, for the example from above this means that
instead of just one line, we now use two. We say our first ob-
ject moves along one line and the second object along another
line. At each possible location of the first object, we need to
take into account the possibility that the second object could
be anywhere. Hence we need a complete copy of our line R
that we use to keep track of the location of the second object at
each location of the R that we use to keep track the location of
the first object. Gluing a copy of R to each point of R yields a

rectanglet. 4 The mathematical name for this
kind of construction is product

. . . space. We will talk about another
So why is this a clever idea? example of a product space in a

moment.
Well, instead of two vectors 7, = (f(x)),72 = (g(x)) we can now
describe our whole system consisting of the two objects with
just one vector 7 = (f(x),g(x)). The important point is that this
vector lives in a higher-dimensional space. So instead of pointing
to a point on our line, this new vector 7 points to a point on our
rectangle.

In physical space, we need N vectors to keep track of the loca-
tions of N objects. Using the idea of gluing the spaces together
we always only need one vector which, however, lives in an RN-
dimensional space. If the objects are allowed to move freely in
three dimensions, our vector 7 lives in IR?‘ since we are gluing
N times R° together.

The resulting arena is known as configuration space. The basic
idea is that instead of keeping track of the N individual objects
on our system, we treat the system as a whole. We can imag-
ine the whole system as just one point that moves through this
higher-dimensional space called configuration space. Each point
in our configuration space corresponds to one specific config-
uration the system can be in. As time passes, the configuration
of the system usually changes. Using configuration space, we
can describe the time evolution of our system by a trajectory in
configurations space.

190 NO-NONSENSE QUANTUM MECHANICS

(

3n dimensidnal
configuration
space_@

Let’s have a look at two concrete examples.

The configuration space of a harmonic oscillator is simply a

5 We discussed the quantum har- lined
monic oscillator in Section 9.

Configuration 1 Configuration 2

——— > (i \

For a second harmonic oscillator our configuration space is also
a line, which however we rotate by 90° for reasons that will
become clear in a moment:

— Fa

If we now consider the system that consists of the two harmonic
oscillators we need to attach to each point of the configuration

space of the first harmonic oscillator the configuration space of
the second one. So what we end up with is a rectangle:

Configuration 1 Configuration 2

Configuration

Configuration 2 <— Space

Configuration 1

Our second example is a pendulum. The configuration space
of a pendulum is a circle since it can rotate around its anchor
point:

Configuration 2

oo

N

Configuration 1

We can then construct the configuration space for the system
that consists of two pendulums by attaching to each point of
the configuration space of the first pendulum the configuration
space of the second one.

The result of this procedure is a torus.

MATHEMATICAL ARENAS

191

192 NO-NONSENSE QUANTUM MECHANICS

Configuration 1 Configuration 2

Configuration 2 a
Configuration
Configuration 1 Space

An important observation is that our configuration space only
keeps track of the locations of the various objects. However,

to describe the state of a system, we need additionally to keep
track of their momenta. So in addition to our vector 7 that keeps
track of the locations, we need a vector f that keeps track of the
momenta.

This motivates the construction of the next mathematical arena
which works completely analogous to what we did above to
construct the configuration space. However, this time we also
act as if the momenta live in a different space and then glue the
momentum spaces to our location spaces. As a result, we can
describe the complete state of our system with just one vector.

The resulting mathematical arena is known as phase space.
Each point in this phase space corresponds uniquely to one

MATHEMATICAL ARENAS 193

specific location of each object and one specific momentum

of each object. So everything that is going on in the system is
described by just one vector (or equally the point the vector 43
points to) that moves through phase space.

aoa

The price we have to pay for this is that the vector we use to P

describe the system lives in a 2 x 3N-dimensional space for N Figure 13.1: Phase space of a har-
monic oscillator. The different
ellipses correspond to different ini-
tial conditions, i.e., different initial
velocities and locations of the object
at the end of the spring. At the posi-
tions where the object is the farthest
away from its rest position, the mo-
mentum is zero since at this point,
all energy is saved in the spring in
the form of potential energy. The
momentum has its maximum value
when the object passes through

the rest position since the potential
energy is zero here.

objects that move in three-dimensions.

6n-dimensional
phase space

o>

4 |

Phase space is notoriously difficult to visualize since even for

just two objects moving in one-dimension phase space is al- 7
ready four-dimensional. However, for just one object in one- Figure 13.2: Phase space of a pen-
dimension, it is possible. You can see two examples in Fig- dulum. We can see that for small

excitations the system is extremely
similar to the harmonic oscillator.
However, for large initial momenta,
the pendulum can rotate once
around its revelation.

ure 13.1 and Figure 13.2.

So far, we went from our three-dimensional physical space IR?
via the 3N-dimensional configuration space to the 2 x 3N-
dimensional phase space. The final mathematical arena we will
discuss next is another development in the same direction. But
why do we need another space? Using the corresponding phase
space, we can already describe our whole system with just one
vector. How could we ever do better than that?

We can’t - at least if we were only dealing with situations like
the ones described above. However, there is one crucial aspect
of every physical system we haven't taken into account yet: un-
certainty. In the examples above we assumed that the locations

194 NO-NONSENSE QUANTUM MECHANICS

® We discussed this already in
Section 2.3.

7 This is what we already discussed
in Chapter 3. However, take note
that it is also possible to incorporate
uncertainty in our descriptions in
physical, configuration and phase
space. We will talk about this in
detail in the following sections.

8 For different systems we have
different Hilbert spaces, similar to
how we have different configuration
spaces or different phase spaces for
different systems

9 Formulated differently, there are
infinitely many real numbers be-
tween any given two real numbers.

and momenta of every object in the system are perfectly known.
In the real world, there is always uncertainty since the precision
of a real measurement device is always limited. In addition, as
soon as we try to describe the world of elementary particles,
there is the quantum uncertainty we seemingly can’t get rid of°.
This feature of nature motivates the construction of a fourth
mathematical arena.

Let’s recall what uncertainty means. For a single object, it
means that we are not completely sure about its momentum
and its location. Imagine a beam of particles. We prepare each
particle as similar as possible and send them into our experi-
ment separately. However, when we then measure the locations
and momenta of different particles we do not always get the
same numbers. Instead, our measurement results are always
somewhat spread out. This motivates exactly the kind of struc-
ture we used all the time in the previous chapter. Instead of

a vector which points to one specific location, we now use a
superposition of possible locations (or momenta)’

[¥) =a|x1) +b |x2) +c |x3) +d |x4) , (13.1)

where, for simplicity, we imagine that the particles in our sys-
tem are confined to a lattice structure, i.e., we can only find it
at some discrete set of points x1, X2,%3,%4. The crucial point is
that these objects |‘¥) (our kets) do not live in physical space or
any other space we talked about so far. Instead, they live in a
mathematical arena that we usually call Hilbert space. And in
fact, every calculation in this book did happen in some Hilbert

space®.

The main difference to our previous mathematical arenas is
that we have one basis vector for each possible location. So since
only four locations are possible, we have four basis vectors:

|x1) ,|x2),|%3) ,|x4). However, in general, if we describe an
object that moves freely in, say, one dimension we have one
basis vector |x) for each point on the line x € R. Yes, there

are infinitely many of them. No matter how much you zoom
in, there are always infinitely many points between any two
points on the line R.9 So in general, we have infinitely many

basis vectors. Therefore, we can conclude that our mathematical
arena is infinite-dimensional.

This sounds extremely frightening at first, but luckily we are al-
ready somewhat familiar with this kind of structure. We already
know how we can squeeze out physical predictions from our
infinite-dimensional vectors |) since this is exactly what we
discussed in all previous chapters.

Recall that often we use specific coefficients to describe a given
vector @ = (3,1,5)". Analogously, we often use explicit co-
efficients ¥(x) to describe a given vector |¥) living in Hilbert
space’®. The only difference is that now, we have an expansion
with respect to infinitely many basis vectors |x) and we get one
coefficient for each point x € IR3. Therefore, we have infinitely
many coefficients ‘Y(x) which we call the wave functions. In
this sense, people usually say that wave functions live in Hilbert
space.

Hilbert spaces are quite similar to the other spaces we discussed
previously**. The two big differences are that Hilbert spaces

are complex and can be infinite-dimensional'?. By complex

we mean that we allow complex linear combinations of the
basis vectors, i.e. we allow the coefficients ¥(x) or a,b,c,d to be
complex.*3

So before we move on and discuss how we can describe quan-
tum systems using the various mathematical arenas discussed
in this section, let’s summarize what we have learned so far.

> One possibility to describe nature is to keep track of every-
thing using vectors living in physical space.

> A bit more convenient is a description in configuration space,
where one point is enough to keep track of the locations of
all objects in our system.

> Even better is a description in phase space, where each point
corresponds to one specific state of the system, including all
locations and all momenta.

> A fourth possibility is a description in Hilbert space, where

MATHEMATICAL ARENAS 195

10 We discussed this in detail in
Section 3.3.

™ Hilbert spaces are also vector
spaces, which means that the basic
tule to add elements works exactly
like for ordinary vectors.

” The Hilbert space for specific
systems can be finite dimensional.
For example, in our example above
where only four specific locations
were possible, the Hilbert space is
finite-dimensional.

3 We will not discuss the mathe-
matical details of Hilbert spaces
any further here. But you can find
proper discussions in the textbooks
discussed in Part 16.

196 NO-NONSENSE QUANTUM MECHANICS

%4 In mathematical terms, we say
that phase space is a symplectic
manifold since the natural product
of phase space functions is the
Poisson bracket, which we usually
call a symplectic structure.

*5 While the other three are taught
in any standard physics curricu-
lum, this fourth formulation is

not well-known. For a particu-
larly nice introduction, see the
"Notes on Koopman von Neumann
Mechanics, and a Step Beyond"

by Nobel laureate Frank Wilczek
http://frankwilczek.com/2015/
koopmanVonNeumann02. pdf.

also each point corresponds to one specific state. However,
one advantage is that a Hilbert space is a (complex) vector
space. This means that the objects which live in Hilbert space
behave exactly like the familiar arrow-type vectors. In con-
trast, a phase space is, in general, not a vector space’.

These are really just different mathematical tools that allow us
to describe the same systems in different ways. It is up to you
which one you like best.

However, the crucial point is the following:

We can describe any given system

- classical or quantum -

using any of these mathematical arenas.

This is how the various formulations of quantum mechanics
come about and, in fact, also why there are different formula-
tions of classical mechanics.

So for classical mechanics we have the following more or less
well-known formulations:

> Classical mechanics in physical space is what we call the
Newtonian formulation.

> Classical mechanics in configuration space is what we call the
Lagrangian formulation.

> Classical mechanics in phase space is what we call the
Hamiltonian formulation.

> Classical mechanics in Hilbert space is what we call the
Koopman-von-Neumann formulation*?.

For quantum mechanics, we have completely analogously:

> Quantum mechanics in physical space is what we call the
pilot wave formulation or de Broglie-Bohm formulation.

> Quantum mechanics in configuration space is what we call
the path integral formulation or Feynman formulation.

> Quantum mechanics in phase space is what we call, well, the
phase space formulation or Wigner-Moyal formulation.

> Quantum mechanics in Hilbert space is what we call the
wave function formulation or Schrédinger formulation’®.

Unfortunately, a full discussion requires at least 100+ pages for
each formulation. So the best I can do here is to sketch some of
the main ideas and tell you where you can learn more if you are
interested. Be warned that I will oversimplify a lot of things in
the following sections. My only goal is to give you a rough idea
of the main concepts used in the various formulations.

MATHEMATICAL ARENAS _ 197

*6 There is a subtlety since the for-
mulation using bras and kets is
often referred to as Dirac formula-
tion. We have already seen above
that wave functions only correspond
to one specific basis choice. We will
talk a bit about another possible
formulation in Hilbert space in
Section 14.4.

14

The World Beyond Wave Func-
tions

Let’s start with the formulation of quantum mechanics in the
simplest arena that we have: physical space.

14.1 The Pilot Wave Formulation

I don’t know about your preferences, but I think a description
of physics in physical space is potentially extremely useful since
we can immediately understand what is going on. While the
more abstract configuration, phase, and Hilbert spaces have

lots of advantages when it comes to calculations, physical space
always wins when it comes to intuition.

However, the formulation of quantum mechanics in physical
space is - somewhat surprisingly - not very well known and
appears in almost no textbook or lecture.

One reason is certainly a historic one. The pilot wave formula-
tion was mainly promoted by the physicists David Bohm and is,

200 NO-NONSENSE QUANTUM MECHANICS

* Adam Becker. What is real? :
the unfinished quest for the meaning
of quantum physics. Basic Books,
New York, NY, 2018. ISBN 978-
0465096053

in fact, often called Bohmian mechanics. Unfortunately, "before
Bohm could defend his revolutionary ideas about quantum physics, he
was swept up in the anti-Communist hysteria of the McCarthy era.
Bohm ended up blacklisted and trapped in Brazil, in exile from the rest
of the physics world."*

When a colleague presented Bohm’s alternative formulation at
a conference the "room erupted in vitriol". And Robert Oppen-
heimer, then one of the most famous and influential physicists,
suggested to the room: "if we cannot disprove Bohm, then we must
agree to ignore him"!, Well, and this is exactly what happened.

So historically Bohm’s formulation was dismissed because he
was sympathetic towards communism. But why is it still not
widely known and taught? His reformulation shouldn't be
controversial any longer. It’s just a different mathematical way
to calculate the same things as in the standard wave function
formulation.

I’m not a historian, but my best guess is that Bohm’s ideas were
dismissed during the crucial years when many important quan-
tum mechanics textbooks were written. Since his ideas were
dismissed by all leading figures at the time they were not in-
cluded in any textbook. As a result, the following generations
did not learn about his reformulation. When the next genera-
tion wrote their textbooks, Bohm’s pilot wave formulation again
did not get included because the authors either didn’t know
about it or still thought that there was something wrong with

it since so many famous physicists dismissed it. Well, and this
story continues to this day. Nowadays, most physicists are sim-
ply satisfied with the wave function formulation since it allows
them to calculate anything they wish to calculate. Why should
they care about another formulation that does not offer any new
experimental predictions? This point of view is expressed, for
example, by Nobel laureate Steven Weinberg:

In any case, the basic reason for not paying attention to the Bohm
approach is not some sort of ideological rigidity, but much simpler -
it is just that we are all too busy with our own work to spend time on

THE WORLD BEYOND WAVE FUNCTIONS 201

something that doesn’t seem likely to help us make progress with our
real problems.”

So here’s the thing. I’m not a hardcore fan of the pilot wave
formulation. I don’t use it for calculations. I don’t think it

is in any way superior to the other formulations. But it isn’t
worse either. So while it makes sense to teach students the wave
function formulation, I think, you should at least tell them that
such an alternative formulation exists and then let them decide
themselves. To me, these different formulations are entirely
detached from any ideological arguments about what quantum
mechanics really means*. They are simply different mathematical
tools to calculate the same predictions for what is going on in
the quantum world.

After this long prologue, let’s finally talk about what the pilot
wave formulation is all about.

> The starting point is the following ansatz for a general wave

function:5
¥(1,t) = \/p(r, £) lS 4)/2,

where p = ¥'¥* is the usual probability density® and S(r, t)
the phase of the wave function.

(14.1)

> We put this ansatz into the Schrédinger equation

#2
inas¥ = (“5 + v) y
2m

and then treat the real part and the imaginary part as sepa-
rate equations. This yields

de VS\ _
as. (Vs)?
95 | ( +V+Q=0, (14.3)

ot 2m

*http://inference- review. com/
article/on-bohmian-mechanics

3 There are some die-hard fans of
Bohmian mechanics. If you google
for "Bohmian mechanics" you'll find
them.

4 This is the stuff people get pas-
sionate about.

YAY Rye

[Y G1) 1 = “Awptitude”

6(%,1) = "Phase"

5 We can understand the motivation
for this ansatz by observing that
wave functions live in a complex
Hilbert space, but now we want

a description in our real physcial
space. We can write any complex
number c € C asc = re”, where r
is the absolute value of the complex
number and @ its phase. This is
known as the polar form of the
complex numbers and possible
thanks to Euler’s formula

z = e* = cos(x) + isin(x)
= Re(z) + ilm(z).

So instead of the two complex
variables c and c* we can use the
two real valued variables r and 6 to
encode the same information.

® See Section 3.3

202 NO-NONSENSE QUANTUM MECHANICS

where
2 2 2
g--# [2>(=*) - (%)
8m p p
he VE V¥\]?
=a (Be )+ PCr)

is known as the quantum potential. Equation 14.2 is the
usual continuity equation that tells us that probabilities are
conserved. The second equation (Eq. 14.3) is more interesting

since it is completely analogous to the classical Hamilton-
Jacobi equation.

> The key idea is that we do the same thing as in classical
mechanics but additionally take the quantum potential into
account. As a result of the new potential we get a new force
Fo = —VQ that acts on our particles. We can then calculate
the trajectories of particles using Newton’s usual second law
ma = F = —V(V + Q), where V is the normal potential of
the system and Q the quantum potential. So what we end up
with are trajectories in our physical space, which is exactly
what we wanted to accomplish.

> The new potential Q is responsible for the strange quan-
tum effects and guides our particles as they move along
their trajectories. Our solutions to Newton’s second law
F = ma = mf(t) depend crucially on the initial condition
r(to). However, we never know r(to) for any particle with ab-
solute accuracy. The quantum potential is extremely sensitive
to small changes in the initial conditions. Therefore, the best
we can do is average over ensembles of particles. This way
we again end up with probabilistic predictions just as in the
wave function formulation. The motivation for the name pilot
wave formulation comes from the observation that we have a
wave-like potential Q that guides our particles as they move
through space. This is in contrast to the wave function for-
mulation where the wave function is a somewhat mysterious
object that encodes all information about the system.

THE WORLD BEYOND WAVE FUNCTIONS 203

It is instructive to see how the famous double slit result comes
about in the pilot wave formulation. One crucial observation is
that we never know exactly where our particle enters a slit. Have
a look at the trajectories for the double slit experiment in the
following figure:

The crucial point is how different the trajectories are for par-
ticles that enter the slits right next to each other. This demon-
strates how sensitive the quantum potential Q is to the initial
conditions. Secondly, the interference pattern comes about be-
cause the wave-like quantum potential goes through both slits
and then guides the particles in such a way that they end up in
the characteristic pattern.

The research group of John Bush recently did a series of illumi-
nating experiments that demonstrated how this can happen.”
They studied the behavior of oil droplets that bounce along the
surface of a liquid. The droplet sloshes the liquid as it bounces
along its surface. In return, the path of the droplet is affected by
the ripples in the liquid that are created this way. So the liquid
is the analogue to the quantum potential and the droplet to the
quantum particle. Using this setup, they can reproduce several
of the most astonishing quantum results, including the result of

7John Bush is a professor of applied
mathematics at the Massachusetts
Institute of Technology (http:
//math.mit.edu/~bush/).

204. NO-NONSENSE QUANTUM MECHANICS

8 To learn more about these experi-
ments I recommend having a look
at the article titled "Fluid Tests Hint
at Concrete Quantum Reality" by
Natalie Wolchover in Quanta Maga-
zine which is freely available online.
In addition, I like the Youtube video
"Is This What Quantum Mechan-
ics Looks Like?” by Veritasium
https: //www. youtube. com/watch?
v=WIyTZDHuarq.

9 David Bohm. Quantum theory.
Dover Publications, New York, 1989.
ISBN 978-0486659695

© Peter Holland. The quantum the-
ory of motion : an account of the de
Broglie-Bohm causal interpretation
of quantum mechanics. Cambridge
University Press, Cambridge Eng-
land New York, NY, 1995. ISBN
978-0521485432

™ The following thought experiment
is due to Anthony Zee and appears
in his brilliant book

A Zee. Quantum field theory in
a nutshell. Princeton University
Press, Princeton, N.J, 2010. ISBN
9780691140346

* Take note that this is not the
same as |1(B)|? + |~2(B)|?. The
important difference is the inter-
ference term i; (B)i2(B) which
is responsible for the interference
pattern.

the double slit experiment®.
So what’s the message to take home here?

Firstly, since all we did was to rewrite the Schrédinger equa-
tion, our results are the same as in the standard wave function
formulation. And secondly, it’s possible - as promised - to de-
scribe what is going on in quantum systems using ordinary
trajectories in physical space.

Two good starting points to learn more about the pilot wave
formulation are

> Quantum Theory by David Bohm?

> The Quantum Theory of Motion by Peter R. Holland’®

We now move on to the next alternative formulation of quan-
tum mechanics which is a lot less controversial. This time our
goal is to reformulate quantum mechanics in configuration
space.

14.2 Path Integrals

We start with a thought experiment that illustrates the general
idea’.

Our starting point is once more the double slit experiment. In
the standard wave function formulation, we have a probability
amplitude ~,(B) that our particle travels from A through slit 1
and then ends up at the location B on our screen. Analogously,
we have an amplitude #2(B) that it travels through slit 2 and we
then detect it at the location B. The total probability is then the
sum of the amplitudes squared’?

Pap = |Waal| = |y1(B) + Y2(B)/*. (14.4)

THE WORLD BEYOND WAVE FUNCTIONS 205

A ‘|
Now, here’s a clever series of thoughts which starts with the

question: What happens if we drill another slit into our wall?

Well, in this case we simply have

Pap = |Paal = |¥1(B) + p2(B) + Y3(B)/*. (14.5)

The next clever question is: What happens if we add another
wall with holes in it behind the first one?

Again we need to include all possibilities how the particle can
get from A to B. For example, we now have an amplitude for
the path from slit 1 in the first wall to the slit 1’ in the second
wall, another amplitude for the path from slit 1 in the first wall
to slit 2’ in the second wall and so on.

The crazy thing is what all this implies when we take this game

206 NO-NONSENSE QUANTUM MECHANICS

3 We discussed the quantum frame-
work in Chapter 3.

4 We use the shorthand notation
|(q)) = |q) and, for simplicity
assume that the Hamiltonian is
time-independent, which is the case
for a free particle. Otherwise, we
have to write the integral all the
time: U(t) =e" feat He), Also, we
neglect the factor ft to unclutter the
notation.

to the extreme: We add more and more walls and drill more
and more holes into them. At some point there will be no walls
left since we drilled so many holes into them. However, our
discussion from above suggests how we have to calculate the
probability that the particle starts at A and ends up at B: we
have to add the amplitudes for all possible paths to get from
A to B. This is true even though there are no longer any walls
since we drilled so many holes into them. The final lesson is
therefore that in empty space without any physical walls, we
have to consider the probabilities of the particle taking all pos-
sible paths from one point to another instead of just one path.
This is the basic idea behind the path integral formulation of
quantum mechanics.

x
A

We will translate exactly this idea into a mathematical form and
then see how the name path integral comes about.

What we are interested in is the probability that a particle that
starts at a point A ends up after some time T at another point B.
Using the standard quantum framework, we can immediately
write down the corresponding probability amplitude’

(BI¥(A,T)) . (14.6)
Using the time evolution operator (Eq. 3.48) we can write this
as'4

(B/¥(A,T)) = (B|U(T)|A)
> Eq. 3.48
= (Ble HT A) .

THE WORLD BEYOND WAVE FUNCTIONS

The thought experiment from above suggests how we can cal-
culate this: We slice the spatial region between A and B and the
time-interval [0, T] into many many pieces. Then, to calculate
the probability that the particle moves from A to B, we have to
sum over the amplitudes for all possible paths between A and
B.

For example, let’s consider one specific path where the particle
travels from A via some intermediate point q to B.

}

The corresponding probability amplitude is
(Blew) gy) (gale "Ay ,

where ft; is the time the particle needs to travel from A to the
intermediate point qj.

However, according to our thought experiment, it is not enough
to consider one specific path. Instead, we must add the ampli-
tudes for all possible paths. This means that we need to take
into account the probability amplitudes that after t; seconds the
particle is at any possible locations q.

207

208 NO-NONSENSE QUANTUM MECHANICS

And mathematically this means that

(Ble (7-4) ay) (qlee A) . (14.7)
1

In general, there are not just a discrete set of possible locations
after t; seconds but instead a continuum. Therefore, we have to
replace the sum with an integral

Bq. 14.7 + [dq (Ble!) qn) (qule™ A). (248)

So far we only took into account the probability amplitudes that
the particle is at some specific point in time f, at all possible
locations. However, to consider all possible paths we have to do
the same thing for all points in time between 0 and T. For this
purpose, we slice the interval [0,T] into N equally sized pieces:
6 = T/N. The time evolution operator between two points in
time is then U(5) = e~*#9/" and we have to sum after each time
evolution step over all possible locations:

THE WORLD BEYOND WAVE FUNCTIONS 209

5 38 (N-4)35 0 T C

Mathematically, we have completely analogous to Eq. 14.8 for
the amplitude 4_,3 that we want to calculate

PAsB = fan -»dgn—1 (B|e"? |qn—1) (guile |qn-2) +
(je? |A) . (14.9)
Our task is therefore to calculate the products of the form
(aisle |qj) = Kaje1qj)

which is usually called the propagator. We expand the expo-

nential function in a series since 6 is tiny? *5 Once more we use the Taylor
expansion e* = D*.9 2+ (Ap-
. 1 2 <2 pendix A).
Kayaay = (opal (1 iS 5H + ) Ig
2
= (47411 9j) — 1 (4j41| qj) + ---- (14.10)

The further evaluation of the propagator is quite complicated
and needs many tricks that look extremely fishy at first glance.
So don’t worry if some steps are not perfectly clear since, as it

happens often, you simply need to get used to them.’ If you’re *6 The following quote by John von
Neumann seems quite fitting here:
"Young man, in mathematics you

jump directly to the final result in Eq. 14.16. don’t understand things. You just
get used to them."

not in the mood for a long calculation, it also makes sense to

With this said, let’s continue. The first term in the sum is a delta
distribution since our eigenstates are orthogonal

AD; inf... —a,
(qj+119j) = 9(4j41 — 4) = / aon %) (14.11)

210 NO-NONSENSE QUANTUM MECHANICS

7 This can be motivated as follows:
recall that we construct a wave
packet as a linear combination of
plane waves. The delta distribution
is, in a sense, an extreme wave
packet which is infinitely thin but
at the same time infinitely high.

To construct such a wave packet
using plane waves we have to use
every plane wave that exists. This is
basically what we wrote down here.
For more on this, see Appendix C.

8 This is analogous to how we
switched from an abstract |) to the
explicit position basis in Section 3.3.

K,

4j+14j

_ / AP; ipjlaies -4j)
27

= [= AP; aipjlaies ~4j)

In the last step we rewrote the delta distribution in terms of its
explicit integral representation’”. Next, we evaluate the second
term in Eq. 14.10. The crucial idea is to recall the explicit form

of H « p*/2m + V(x). To get rid of the operator pf, we need to

switch to the momentum basis™®

2.
i al) = i el (ae PO)

== 18 (qual (2 +v@) [Pm rian
£2 Pi

=1

=- =-i6 | F ap) @ + Vana) (qj411 Pj) (Pil 9)

=— =-i6 | F api (5. +V(qj »)) efi (4i41—4))
(14.12)

where we again used the orthogonality of the basis states and
the explicit integral representation of the delta distribution. So
in summary, our propagator (Eq. 14.10) reads

= (95411 9j) — 1 (4j4a| Alay) +
> Eq. 14.11
— 16 (qj41| H |qj) +...

> Eq. 14.12

_ is [ Ft api @ + V(qj »)) elPi (441-4) +,

AP; (a... —a, _( P
— [ 2Pi gipjais—a) i5 Pj V
= [$e i 2 no (4j-+1)

AD; in (gis, —a; ;
=f ceeiPiGin 1) exp (—i5H(pj,qj+1)) -

(14.13)

THE WORLD BEYOND WAVE FUNCTIONS 211

With this at hand, we are finally ready to go back to Eq. 14.9
and evaluate the amplitude ~,_,,. In total, we get N times such
a propagator Kg... 4;-

N-1

PaoB = / I] 49; Kaj 41.9;
J=

> Eq. 14.13

- [Taf 1 exp (#E (» j=? —a954))

(14.14)

Now, in the limit N — oo our interval 6 becomes infinitesimal.
Therefore, in this limit the term (jam a)
q.79 So the term in the exponent reads pq — H. If we then ex-

ecute the integration over dp and recall that the Lagrangian L

becomes the velocity

is exactly the Legendre transform of the Hamiltonian, we can
rewrite the amplitude as

PasB =

(sas) ° [Tas exp (ws y (L(qj) )) (14.15)

It is conventional to write the amplitude then in the following
more compact form?°

(14.16)

pan = [Patten

where S[q(t)] is the action that we always use in the Lagrangian
formalism and Dq(t) the so-called path integral measure.

In words, this equation tells us that in quantum mechanics

we can calculate the probability amplitude that a particle goes
from A to B by summing over all possible paths between A

and B and weight each path by the corresponding action. This is in
stark contrast to what we do in classical mechanics. In classical
mechanics, we also calculate the path an object takes between
two fixed points A and B by considering all paths and using the
action. But in classical mechanics, there is only one correct path:
the path with minimal action?"

"9 This is the definition of the
derivative as the difference quotient.

20 We have included the so-far
neglected ft again in this final
formula.

1 This is the whole point of the
Lagrangian formalism. For each
path between two points, we can
calculate the corresponding action.
Since nature is lazy, she always
takes the path with minimal action.
The paths with minimal action
correspond to solutions of the
Euler-Lagrange equations, which
are therefore our equations of
motion. (In some cases the action
is not minimal and a more correct
statement would be to talk about
paths with stationary action.)

212 NO-NONSENSE QUANTUM MECHANICS

22 Once more we can understand
this using Euler’s formula

z=e?

= cos() +isin(?)
= Re(z) + ilm(z)

Now, in quantum mechanics we act as if the particle takes all
possible paths and the classical path with minimal action is
therefore only one path out of many.

Take note that the path integral formulation not only works
for the probabilities of a particle which travels between two
points. Instead, we can use the same method to calculate the
probability that a system in a given configuration evolves into
another configuration at a later point in time. In this case, we
are talking about paths in configuration space.

The explicit evaluation of the path integral (Eq. 14.16) for con-
crete systems is notoriously difficult. For almost any system
clever approximation schemes are needed to get any informa-
tion out of it. For this reason, we will not talk about any details
here.

Instead, we will discuss an extremely helpful visual way to
understand the path integral which was popularized mainly
by Richard Feynman. The main idea is that the action is just a
number for any given path. Some paths require a lot of action
(ie., S[q(t)] is large for these paths between A and B) while
others require only a little action. The action appears as the
argument of the complex exponential function: e’% la(t)],

In general, since the action S[q(t)] is an ordinary number this is
a complex number with absolute value 1. In the complex plane,
these numbers lie on the unit circle??.

THE WORLD BEYOND WAVE FUNCTIONS 213

The contribution of each path to the total path integral is there-
fore simply a unit complex number. The total path integral is a
sum over infinitely many unit complex numbers.

Therefore, it is useful to imagine that there is a little stopwatch

attached to the particle as it travels a given path. At the begin-

ning of each path the dial points directly to the right? which On a real clock it would point to
in our complex plane corresponds to z = 1 = e’. Now, as the the 3.
particle travels the clocks move. At the end of each particular

path, the dial points to one specific number on the clock.

For example, for one path the situation may look like this:

Xn (1)
, ‘
as

While for another path we have

214 NO-NONSENSE QUANTUM MECHANICS

e "2

an
x
XA O °
©
«Ep
XA

To calculate the path integral, we have to add the little arrows
for each path like we would add vectors. The total value of the
path integral is then the resulting arrow.

The black arrow here is what we get if we connect the starting
point of the first gray arrow with the final point of the third
gray arrow.

Since the resulting arrows do not necessarily all point in the
same direction, the resulting arrow can be quite small. Here, we

THE WORLD BEYOND WAVE FUNCTIONS 215

have three paths but to get the final result we have to include

all possible paths, not just three. The final result depends on the
starting locations A and B. For some final point B’ most of the
arrows cancel each other. The resulting arrow is tiny. In physical
terms this means that the probability to find the particle at this
location is tiny. For another final point B” lots of arrow point in
the same direction and the resulting arrow is large. This means
that it is quite probable that we find the particle at this location
at the end of our time interval.

If you want to learn more about the pictorial way to understand
path integrals I highly recommend the book

> QED: The Strange Theory of Light and Matter by Richard P.
Feynman”4.

To learn more about the path integral formulation with real
math, a good starting point is

> Quantum Mechanics and Path Integrals by Richard P. Feyn-
man and A. R. Hibbs”>.

Before we move on there is one more cool thing that we can do
with path integrals

14.2.1 The Origin of the Classical Path

First, let’s shortly recall what we do in the Lagrangian formula-
tion of classical mechanics.

In classical mechanics the correct path an object travels is the
path with minimal action. A special property of a minimum is
that if we investigate its neighborhood, we notice that it only
goes up from there and never down. Otherwise, it wouldn’t be
a minimum. This is the basic idea of variational calculus.

4 Richard Feynman. QED: the
strange theory of light and matter.
Princeton University Press, Prince-
ton, NJ, 2014. ISBN 978-0691164090

75 Richard Feynman. Quantum
mechanics and path integrals. Dover
Publications, Mineola, N.Y, 2010.
ISBN 978-0486477220

216 NO-NONSENSE QUANTUM MECHANICS

26 This is the standard method to
find the minimum of a function.
The basic idea is that the rate of
change at a minimum is zero.

27 A functional is a function of a
function. So while an ordinary
function eats a number x and spits
out a number f(x), a functional
F[f(x)] eats a function and spits
out a number. An example of a
functional is our action S[q(#)]
which assigns a number to each

path q(t).

To understand this a bit better let’s calculate the minimum Xin
of some function f(x) = 3x? + x. We can do this by looking at
one specific x = a and then investigate its neighborhood. This
means that we consider the value of f at a+ €, where € denotes
an infinitesimal (positive or negative) variation:

f(at+e) =3(ate)?+ (ate) =3(a*+2ae +67) +ate.

Now the crucial idea is that if a is a minimum, the first order
variation in € must vanish. Otherwise, we could choose a neg-
ative €, and this would mean that f(a + e€) is smaller than f(a).
In other words, this requirement makes sure that we only go
upwards if we move away from a. Thus, we collect all terms
linear in € and demand that they vanish:

3-2ae+e +0 > 6a+1=0.

From which we can conclude
1 —1
a=—.
So we have successfully calculated the minimum of our func-
tion. This is the same result that we get if use the standard
method, i.e., take the derivative f(x) = 3x*+x > f'(x) =6x+1

and then demand this to be zero?®.

While for functions this is just another method to do the same
thing, the variational method is extremely powerful because it
also works for functionals?7.

With this in mind, we return to our quantum path integral

(Eq. 14.16). As we will see in a moment, the classical path also
plays a special role here, although initially, it seems as if it were
just one path out of many.

What we have learned above is that the probability of a given
final position depends crucially on the relative positions of the
final arrows. If the arrows point mostly in the same direction,
we get a long final arrow. We say that in such a situation we
have constructive interference. If the final arrows point wildly
in different directions, they mostly average out, and we end up

THE WORLD BEYOND WAVE FUNCTIONS

with a short total arrow. This is known as destructive interfer-
ence.

So why is the classical path (= the path with minimal action) so
important?

It turns out that alone it is not that important since every path
contributes exactly one arrow. So in some sense, the classical
path is in our quantum context just one path out of many. How-
ever, we can understand why the classical path is so important
in classical mechanics by exploring the contributions of neigh-
boring paths. For concreteness, let’s consider two neighboring
paths q(t) and q’(t) where the second path is a variation of the
first one q’(t) = q(t) + y(t), where y(t) denotes a small varia-
tion.

The first path contributes e’5[7(4)]/" while the second path con-
tributes e!5'I7'()]/h and we can expand the action of the second
path around the first one

Sli] = Sla-+n) =Slal+ [arn 514 + O07).

If q(t) is the path with minimal action q,;(t) the first order vari-
ation, as discussed above, vanishes:

217

218 NO-NONSENSE QUANTUM MECHANICS

5S[q]

S{a']=Slaa+m = Staal + faenS 7h) +00")

4q-4el

65[q\ _ -
2 5q(t) = 0 for q = 4c1

= $[qci] + O(n").

The physical implication for our path integral is that paths

in the neighborhood of the path with minimal action q,;(t)
yield arrows that point in approximately the same direction
since S{q’] ~ S[q,)]. In other words, paths around the classical
path interfere constructively. This is why the classical path is
important. In contrast, for an arbitrary path far away from the
classical path the resulting arrows of neighboring paths vary
wildly, and we get destructive interference.

q WN paths interfere Aci (+)

constructively fo

—__ paths interfere
destructively

”

In the next section, we discuss yet another way to calculate
probabilities in quantum mechanics, this time using the corre-
sponding phase space.

THE WORLD BEYOND WAVE FUNCTIONS 219

14.3. Phase Space Quantum Mechanics

For a long time people thought that a formulation of quantum

mechanics in phase space was simply impossible. After all, one

of the main lessons of quantum mechanics is that we can’t mea-

sure the location and the momentum of a particle at the same

time with arbitrary precision. In a phase space formulation, we

use the position and momentum variables at the same time and

this seems highly incompatible with quantum mechanics”®. 28 We discussed the general idea
behind phase space in Chapter 13.

However, these prejudices are somewhat unfounded since it is

quite easily possible to incorporate uncertainty in a phase space

formulation. A point in phase space corresponds to one spe-

cific state of the system. Formulated differently: such a point

corresponds to exactly known locations and momenta for all ob-

jects in the system. As time passes by this point moves through

phase space since, in general, the locations and momenta of the

various objects change. Therefore, a trajectory describes the time

evolution of the system in phase space.

De

We never know the positions and momenta exactly. There is
always some uncertainty. For our phase space, this means that
the state of our system does not correspond directly to one
point but to a region in phase space. This region consists of all
states of the system that are in agreement with what we know
about the system.

Maybe the following idea helps: Imagine that if we have definite
knowledge about the state of the system we have just one point.
If we are not exactly sure this big point splits up into many

220 NO-NONSENSE QUANTUM MECHANICS

79 We will discuss this using an
explicit example in a moment.

Figure 14.1: In general, for a contin-
uous set of possible initial states, we
get a region in phase space.

3° We will discuss what is different

in quantum mechanics in a moment.

But first, we recall how classical
mechanics works in phase space.

points which are a bit transparent. The level of transparency in-
dicates how confident we are to find the system in this state.
More transparency corresponds to a smaller probability to

find the system in the corresponding state. The crucial point

is then that if we add up all the points we get a completely non-
transparent point which is identical to the definite knowledge
point. In physical terms, this means, of course, that probability
is conserved. In the definite knowledge case, we have just one
point since we are 100% certain that the system is in this state.
If we are not sure, the 100% get distributed among all possible
states.79

In practice our limited accuracy means that we don’t know the
exact point our object is at but only that it has to be in a certain
spatial region. The same is true for the momentum which has
to be within some range. Now, if we take uncertainty into ac-
count, our time evolution is no longer just a trajectory in phase
space but a collection of trajectories. Imagine you put a pen-
cil down on each possible initial state of the system. Then, as
time passes by each of these pencils traces out the path in phase
space that describes the time evolution if the system was in the
corresponding initial state. Taken together all of these pencils
trace out what we call a flow in phase space.

So far, this is nothing that is specifically related to quantum
mechanics>°. Everything we just discussed works exactly like

THE WORLD BEYOND WAVE FUNCTIONS 221

this in classical mechanics. The flow of a given distribution of
initial states in classical mechanics is described by the famous
Liouville equation

op op. , op.
ot ¥ (50 4 Op, mi)

=—{p,H}, (14.17)

where p(t, pi, qi) denotes the probability density, { , } the
Poisson bracket3? and H the Hamiltonian function.

In words, this equation is completely analogous to what we
already know from quantum mechanics: the Hamiltonian func-
tion H generates the time-evolution. The Poisson bracket is the
natural product how operators act in phase space. If we inte-
grate this probability density over some phase space volume

pi & (pm, pm], qi € [qit'", q’""*|, we get the probability to

measure the locations and momenta of the objects in our system
in the ranges p; € [p”™™, p™*], qi € [q'", q™*).

To understand this a bit better, let’s imagine a one-dimensional
system with two objects and that for some unspecified reason
only very particular positions and momentum values are possi-
ble. This means that only a few initial states are viable and not
an infinite continuous set.

Further, let’s say we are pretty certain our system is in the

state A where q7 = 2m, p, = 3kg-m/sand q2 = 3m,

po = 4kg - m/s. However, we can’t exclude the state B where
9 = 3m,pi = 4kg-m/sand q2 = 4m, pp = 5kg-m/s

or state C where qj = 1m, p1 = 2kg-m/sand q, = 2m,

p2 = 3kg- m/s. Our (now discrete) initial probability density is
then33

p(t =0,A) = 0.7
p(t =0,B) =0.2
p(t =0,C) =0.1
(14.18)

In words, this means that we are 70% certain to find the system

31 The Poisson bracket is de-
fined as follows: {F,G} =

rN (# aG _ OF 2c )
M=1\ 0qn OPn Pn On

3 The equivalence of the first
and second line follows if we use
Hamilton’s equations:
._ 0H
q= ap
oH

33 To unclutter the notation we
dropped the units.

222 NO-NONSENSE QUANTUM MECHANICS

3 Take note that the state C is not in
our region and therefore does not
appear in the sum here.

in state 1 and, for example, 20% certain to find it in state 2.

Now, to get the probability at = 0 to measure our objects in
the regions (41,92) € {2...3,3...4} and with momenta in the
range (p1,p2) € {3...4,4...5}, we have to "integrate" over the
corresponding volume. Since we are dealing with a discrete set
of possible states, our "integration" is simply a sum3+

P( (41-42) € {2...3,3...4}, (pip) € {3...4,4...5})

35 You can find a more complete
discussion of the Liouville equation
in

Jakob Schwichtenberg. No-
Nonsense Classical Mechanics : a
student-friendly introduction. No-
Nonsense Books, Karlsruhe, Ger-
many, 2019. ISBN 9781096195382

2
91=3,92=4,p1=4,p2=5
p(t = 0, p1, 41, P2, 42)
91 =2,92=3,p1=3,p2=4
2
= p(t =0,A) + p(t = 0,B)
2

=0.7+0.2=0.9.

In general, our probability density changes over time, and we
can repeat the same procedure for any point in time. The tool
that allows us to calculate how any initial probability density
evolves in time is Liouville’s equation (Eq. 14.17).

Again: everything we discussed in this section works exactly
like this for classical mechanics. If we want to understand how
we can also describe quantum mechanics in phase space, we
first need to answer the question:

Where does Liouville’s equation come from?35

It follows directly from three other equations:

1. Hamilton’s equations:

THE WORLD BEYOND WAVE FUNCTIONS 223

These equations determine the path of each initial state. So
in other words, given any state of a system, we can calculate
how it evolves in time using Hamilton’s equation.

2. The continuity equation for the probability density

dp _ 94) , a(op)

at oq op
Using the product rule in this continuity equation and then
Hamilton’s equations yields exactly Liouville’s equation.

The continuity equation tells us that for each initial state we al-
ways only get one path through phase space. So in our discrete
example from above, if we start with three possible states, at
some future point in time, there will again only be three states
possible. This follows since each given initial state evolves ac-
cording to Hamilton’s equations. So for each initial state, we get
exactly one future state.

In particular, this means that our probability density at some
future point in time t = 10 s looks like this

0.5, py = 4,41 = 22, po = 3,q2 = 23
0.1 py =2,q, = 21, po = 5,q2 = 22

but never like this

0.5, py = 4,41 = 22, po = 3,q2 = 23
0.2, pi =3,4q1 = 23, po = 4,42 = 24
0.2, py = 1,4) = 22, p2 = 1,q2 = 21
0.1 py = 2,4, = 21, po =5,q2 = 22

p(t = 10, p1,91, P2492) =

(14.19)

This is a crucial assumption. It makes sense in classical me-
chanics since the evolution of each initial configuration is 100%
fixed by Hamilton’s equations. There may be some uncertainty
about which exact initial state is the correct one, but for each
possibility, the path through phase space is entirely fixed.3

This assumption is often formulated in slogan form: "the phase
space flow is incompressible". To understand this imagine that

3° However, there are also systems
in classical mechanics where this
is not true. A famous example

is "Norton’s dome" or systems
with dissipative forces. For these
systems, the Liouville equation is
wrong since such systems cannot
be described using Hamilton’s
mechanics.

224 NO-NONSENSE QUANTUM MECHANICS

37 Think about a bucket of water. We
can dump the bucket on the floor.
This certainly changes the shape
of the water, i.e., the exact form of
p(t, pi, qi). However, the density of
the water stays the same no matter
if it is in the bucket or on the floor.
Again, the reason is, of course,
that each molecule takes up a fixed
amount of space and no molecules
get lost if we dump the bucket on
the floor.

in our discrete example each point in phase space takes up
some finite volume. The set of all possible initial configurations
then corresponds to some fixed volume in phase space. Now, as
time passes these points move through phase space. However,
at some later point in time, if we do the counting, we will again
find the same number of points which therefore corresponds to
the same phase space volume.

All this talk about volumes in phase space is important in the
continuous case where we no longer have a fixed number of
points that we can easily follow. So in other words, the crucial
assumption that goes into the derivation of Liouville’s equation
is that the phase space volume that our system takes up in the
phase space description always stays the same. However, take
note that our phase space density can spread out a lot.

Just imagine how our three discrete points from above can get
separated a lot as time passes. But still, since these three points
always stay three points, the total volume they take up is the
same. Since a fluid that always takes up the same volume is
called incompressible, we borrow this language and usually say
that our phase space flow is incompressible37.

Now, we are finally ready to get back to quantum mechanics.
Maybe, you can probably already guess how it is different from
classical mechanics in phase space.

To describe quantum mechanics in phase space, we need to

get rid of the assumption that our phase space flow is like an
incompressible fluid. This is the crucial difference between
quantum mechanics and classical mechanics. And as a result,
we have to replace, for example, our Liouville equation with a
new equation. But before we talk about these details, let’s think
about what it means that our phase space flow is no longer
incompressible.

To understand this, let’s return to our simple example from
above. At t = 0 we know that the system is in one of just three
possible states. Each such state corresponds to one specific point

THE WORLD BEYOND WAVE FUNCTIONS

in phase space. If we assume each point takes up some finite
unit volume, the total phase space volume our system takes up
in phase space is exactly three times this unit volume.

In classical mechanics, we are able to trace out the phase space
flow by putting down a pencil on each point and then draw

the trajectories in phase space for each point as a line. At any
later point in time we always end up again with exactly three
points and the total phase space volume our description of

the system takes up in phase space is constant. The three new
points correspond to three new states and the probabilities can
now be very different. But for each initial state, we end up with
exactly one final state. In quantum mechanics if you try to do
the same thing with just three pencils, you will fail. The number
of possible final states is not necessarily the number of initial
states. Or formulated differently, the phase space volume is no
longer constant.

Take note that this does not mean that probability is no longer
conserved. This becomes clear by looking at the explicit proba-
bility densities for our example above. Initially, there are three
possible states (Eq. 14.18). After some time the probability den-
sity possibly looks like the one in Eq. 14.19. While there are
now four possible states, the total probability is still 100%. So if
we integrate the probability density over all possible states, we
always end up with 100%.

225

226 NO-NONSENSE QUANTUM MECHANICS

38 I’m not a huge fan of these no-
tions since they carry a lot of
baggage. There are too many "low
signal/high noise" discussions
about them. However, still, it’s often
useful to know the words others
like to use.

39J. E. Moyal. Quantum mechanics
as a statistical theory. Proc. Cam-
bridge Phil. Soc., 45:99-124, 1949.
DOI: 10.1017/S0305004100000487

Another way how people like to talk about this is in terms of
deterministic vs. non-deterministic time evolution3®. In classical
mechanics, we have exactly one final state for each initial state.
This is a deterministic evolution. In contrast, in quantum me-
chanics there can be several possible final states for each initial
state. We call this non-deterministic time evolution.

To bring this point home here’s a quote from one of the most
important papers on the phase space formulation of quantum
mechanics39

“Classical statistical mechanics is a ‘crypto-deterministic’ theory,
where each element of the probability distribution of the dynamical
variables specifying a given system evolves with time according to
deterministic laws of motion; the whole uncertainty is contained in the
form of the initial distributions. A theory based on such concepts could
not give a satisfactory account of such non-deterministic effects as ra-
dioactive decay or spontaneous emission (cf. Whittaker (2)). Classical
statistical mechanics is, however, only a special case in the general the-
ory of dynamical statistical (stochastic) processes. In the general case,
there is the possibility of ‘diffusion’ of the probability ‘fluid’, so that
the transformation with time of the probability distribution need not be
deterministic in the classical sense.”

A crucial observation is that quantum mechanics isn’t neces-
sarily more uncertain than classical mechanics. You can think
about the total uncertainty as something like the total distance
of the points in phase space.

Say we start with a fairly well-known configuration of the sys-
tem, which means that all the corresponding points are fairly
close to each other in phase space. Now, as time passes these
points can get farther and farther away from each other. And
this is in fact what happens in classical mechanics. The whole
process is known as filamentation of the phase space fluid.

THE WORLD BEYOND WAVE FUNCTIONS 227

This observation could already be a hint that classical mechanics

is not the end of the story. To quote Roger Penrose*® 4 Roger Penrose. The emperor's
new mind : concerning computers,

” . . . . minds and the laws of physics. Oxford
For a somewhat analogous situation, think of a small drop of ink University Press, Oxford, 2016.

placed in a large container of water. Whereas the actual volume of ISBN 9780198784920
material in the ink remains unchanged, it eventually becomes thinly

spread over the entire contents of the container. [...] What this spread-

ing tells us is that, no matter how accurately we know the initial state

of a system (within some reasonable limits), the uncertainties will tend

to grow in time and our initial information may become almost use-

less. Classical mechanics is, in this sense, essentially unpredictable.

[...] This spreading effect in phase space has another remarkable impli-

cation. It tells us, in effect, that classical mechanics cannot actually be

true of our world!”

The reason that classical mechanics works fairly well neverthe-
less is that we usually only consider a small number of large
objects where our uncertainties remain manageable.

Now, let’s talk about how all this works in practice. I don’t
want to dive into the mathematical details here, but the main
concepts are the following.

The most important difference between classical mechanics in

228 NO-NONSENSE QUANTUM MECHANICS

# Reminder: Liouville’s equa-
tion reads % = —{p,H}, where

{ , } denotes the Poisson bracket:

_<oN (aE 3G _ aF aG
{F,G} = DN, (#3 Opn oan

# This is the definition of the
Wigner quasiprobability distri-
bution.

).

phase space and quantum mechanics in phase space is that
the classical Liouville equation (Eq. 14.17) gets modified as
follows4* 3W

op = ~{{W, A}. (14.20)
Here W is the Wigner quasiprobability distribution and {{,}}
denotes the Moyal bracket. So in other words, our probability
distribution p gets replaced with the Wigner quasiprobability
distribution and the Poisson bracket with the Moyal bracket.
Let’s talk about these new objects one after another.

t> A major new aspect of the Wigner quasiprobability distri-
bution is that it can take on negative values (in extremely
localized regions). This feature is also why it’s not a prob-
ability distribution in the usual sense and thus called a
quasiprobability distribution.
However, the expectation value of some observable A can be
calculated using the Wigner function as you would probably
expect it

(A) = [Ale p)W(x paxdp. (14.21)

In general, we can calculate the Wigner function by using the
corresponding wave function ¥ (x)4?

1 se .
W(x, p) = Th I. W(x + y)¥(x—y)e2Pe/"dy. (14.22)

t> The Moyal bracket in the equation above is defined by
2 h <> =>
{{W, H}} = —,Wsin (5055; - 53:)) H. (14.23)

This is not too illuminating, but if we Taylor expand it in
powers of fi, we get

{{W, H}} = {W,H}+O(?), (14.24)

where ©(h”) denotes all higher order corrections. So the
Poisson bracket { , } is the correct approximation for the
Moyal bracket for systems where we can ignore corrections
proportional to i, i.e., quantum corrections. This explains
why the Liouville equation works for classical systems.

THE WORLD BEYOND WAVE FUNCTIONS 229

For more details try

> Quantum Mechanics In Phase Space by Zachos, Fairlie and

Curtright*3 43 Cosmas Zachos. Quantum mechan-
ics in phase space. World Scientific,
New Jersey London, 2005. ISBN
9812383840

Before we summarize what we have learned in the preceding
sections, there is one final alternative formulation of quantum
mechanics we have to talk about. However, this formulation
isn’t something completely new since it is just another formu-
lation in Hilbert space. In some sense, it is only a change of
perspective.

14.4 Heisenberg Formulation

In Section 3.6 we discovered that we can describe the time evo-
lution of our states using the Schrédinger equation (Eq. 3.45)

ihd, | (x, t)) = H|¥ (x,t) .

An important point we didn’t talk about so far is that in the
wave function formulation we used so far, our operators do
not change as time passes. However, this is not necessarily the
case. In fact, we can switch our perspective and reformulate
everything such that only the operators change and the states
stay the same. In Section 3.6 we also introduced the so-called
time evolution operator (Eq. 3.48):

[¥ (x, t)) = U(E) |¥(zx,0)) (14.25)

Using this formula and the relationship between bras and kets+4 —’ Reminder
tells us immediately that [¥(x,t))* = (¥(x, 2)

(¥(x,#)| = (¥(x,0)|U(H)*. (14.26)

So far, this operator U(t) was just a convenient way to describe
the time-evolution of states in quantum mechanics. But now
comes a crucial idea.

230 NO-NONSENSE QUANTUM MECHANICS

4 There is a third picture in which
the operators and the states change.
The motivation behind this picture
is similar to what we did in Sec-
tion 12.1.1 to write the Hamiltonian
in two parts H = Hp + H and then
split the time-evolution operator

U(t) = eh oat He)
= ef oat! (Holt) +Hi(t))
= ef oat Holt!) oi So ae H(t")
= UU.

We then say that the operators
evolve according to Up and the
states according to Uy. This third
perspective is known as the interac-
tion picture. It is especially useful
in quantum field theory. The idea

is that Ho describes the free system
and H, all interactions that go on.
By using the interaction picture, we
can reuse all results for the opera-
tors (= the fields) that we derived in
the free theory also in the presence
of interactions. The only thing that
is new is encoded in Hy, and this
part only modifies our states.

Let’s say we want to calculate the expectation value (Eq. 3.19) of
some operator O for a system in the state |¥(x, t)):

(¥ (x, t)|O/F(x,#)) = (¥(x,0)| UT (LOU) ['¥(x,0)), (14.27)

where we used Eq. 14.25 and Eq. 14.26.

So far, we have always assumed that our states change over
time. In particular, this means that our operator U(t) acts on
the ket |‘¥(x,0)). However, without changing any result, we can
equally say that U acts on the operator O instead and the kets
remain unchanged. The time evolution of an operator is then
given by

O(t) = ut(t)OU(E). (14.28)

Using this, we get the same result for the expectation value:
(¥(x)|O(#) [¥(x)) = (¥(x)| UT (HOU(E) [¥(x)) ¥

This change of perspective is known as the Heisenberg picture.
In this picture, the operators change while the states remain
unchanged. The standard picture we used so far where the
states change and the operators remain unchanged is known as
the Schrédinger picture‘.

In the Heisenberg picture, the Schrodinger equation (which
describes the time evolution of states) gets replaced with the
so-called Heisenberg equation

The derivation is completely analogous to the steps in Eq. 4.4
where we derived how quantum mechanics is related to classi-
cal mechanics.

Now it’s finally time to summarize what we have learned in the
preceding sections.

THE WORLD BEYOND WAVE FUNCTIONS 231

14.5 Which Formulation Is The Best?

The most important lesson is that no formulation is the correct
one. All formulations agree in what they predict for experi-
ments. Moreover, in the preceding sections we have explicitly
discussed the connections between them. This gives us some
confidence in their equivalence.

Nevertheless, each formulation has unique strengths and weak-
nesses. This is something we should talk about.

> The wave function formulation has the major advantage that
everyone knows and uses it. So if you need any help or want
to look up a solution your best chance of finding it is if you
use wave functions. In addition, many quantum systems are
described most easily using wave functions.

> The pilot wave formulation is great because it describes
quantum systems with ordinary trajectories in physical space.
However, the extreme instability of the quantum potential
makes it computationally extremely challenging. Moreover,
there are problems to generalize it to quantum field theory.

> The path integral formulation is extremely useful to inves-
tigate formal and global aspects of quantum mechanics (and

also quantum field theory)4*. Since we include all paths - 46 Famous examples are gauge fix-
ing, Faddeev-Popov ghosts, solitons,
instantons and the Fujikawa method
to the final location - we grasp global aspects of the system to treat anomalies.

which possibly get lost in other treatments. A huge disadvan-

even those that move extremely far away and then return

tage is that the path integral is usually extremely difficult to
solve. In addition, there are still problems to make the inte-
gral measure Dq that appears in the path integral (Eq. 14.16)
mathematically rigorous.

> The phase space formulation makes quantum mechanics
appear as similar to Hamiltonian mechanics as possible and
avoids the operator formalism plus the abstract Hilbert space
concept completely. This lets us understand the differences
between classical mechanics and quantum mechanics much

232 NO-NONSENSE QUANTUM MECHANICS

more clearly. A significant disadvantage is that this formula-
tion is quite unknown and it’s tough to find useful resources.

In the previous sections, we haven’t talked about possible inter-
pretations of quantum mechanics at all since it is critical to keep
the topics "formulations" and "interpretations" separate. But in
the following chapter, we will finally talk about what quantum
mechanics really means (or better what people think it could
mean).

15

What Does It All Mean?

"He who confuses reality with his knowledge of reality generates
needless artificial mysteries.”
Edwin Thompson Jaynes

Before we start, a short disclaimer: I dislike all the fights about
what quantum mechanics means. However, at the same time,
I’m not a fan of the "shut up and calculate" approach either.

I think that a proper interpretation of quantum mechanics is
essential if we want to get a deeper understanding of nature.
Moreover, take note that most of what follows is highly subjec-
tive and most other physicists have very different views.

With that out of the way, let’s dive in.

The most important thing first: quantum mechanics needs no
interpretation. The various formulations of quantum mechanics
work perfectly without any additional interpretational input.
We need no idea about what it all means to describe quantum
systems accurately. The equations and algorithms to calculate
predictions do not need an interpretation to work perfectly.

For this reason, quantum mechanics is often taught completely

234 NO-NONSENSE QUANTUM MECHANICS

* Christopher A. Fuchs and Asher
Peres. Quantum theory needs
no ‘interpretation’. Physics Today,
53(3):70-71, March 2000. DOI:
10.1063 / 1.883004

?In fact, most "problems" in modern
physics are puzzles. Famous exam-
ples are the strong CP "problem",
the cosmological constant "problem"
or the hierarchy "problem". The
crux is always that some parameter
has a value which appears strange
and is not what we would naively
expect. However, we can simply put
in the "strange" experimental values
and use our framework without any
problems. Of course, it makes sense
to wonder about the origin of the
strange values, but it is important
to keep real problems separate from
puzzles.

3 Something that exemplifies nicely
how confusing the whole situation
is, is that there isn’t even any
consensus on what exactly the
Copenhagen interpretation is. In
fact, while many physicists would
answer that it’s their preferred
interpretation their point of view is
often much closer to the "shut up
and calculate" approach.

without any discussion about possible interpretations. The
whole approach has even its own name: "shut up and calculate".
Students are discouraged to "waste" time thinking about what is
really going on and should instead focus on learning how to do
the calculations.

At the other end of the spectrum are seemingly endless nat-
ural language texts on proposed solutions to "problems" and
“paradoxes” in quantum mechanics. Often it even remains neb-
ulous what the claimed problem is, let alone what the author
is proposing. The most important point is always to keep in
mind that all these "problems" people like to argue about are
not problems but puzzles. We are dealing with a problem when
we calculate a prediction that disagrees with what we observe
in experiments. And "if quantum theory had been in [such] a
crisis, experimenters would have informed us long ago!" In
contrast, a puzzle is an aspect of our framework that seems
strange or mysterious?.

So we have "shut up and calculate" on the one end and endless
discussions about arcane aspects of the quantum framework on
the other end of the spectrum. In-between these two extremes
there are lots of intelligent discussions and ideas. Many of the
best physicists have joined the debate about what quantum me-
chanics is trying to tell us. Since quantum mechanics is almost a
century old, there are thousands of papers on possible interpre-
tations. So there is no way that we can discuss even a fraction
of all the ideas that are out there. For this reason, I will stick to
some general comments and list some references where you can
learn more.

The most famous interpretation of quantum mechanics is the
so-called Copenhagen interpretation>. The goal is to make
sense of the wave function formulation of quantum mechanics.
Our main focus in this formulation are the measurements we
perform on the system described by the corresponding wave
function. We have seen that the quantum framework only al-
lows us to make probabilistic predictions.

WHAT DOES IT ALL MEAN? 235

For example, we can only predict that, for an ensemble of
equally prepared systems, we will measure for 80% of them
"spin up", and for 20% of them "spin down". The Copenhagen
interpretation states that through the measurement process one
of the various possibilities gets picked out. Before we measured
the spin, the system simply does not have a well-assigned spin.
So, in general, any given quantum system does not have definite
properties before being measured. The measurement process
affects the system in such a way that afterwards the probability
of one of the possibilities is 100%. The most famous thought
experiment discussed in this context is Schrédinger’s cat experi-
ment. We put a cat in a box together with a flask of poison and
a radioactive source. In the radioactive source, each atom will
decay with some probability. When this happens for one atom,
it emits a photon which then gets detected by a Geiger counter.
This causes a hammer to fall on the flask of poison.

The whole point is that, before we look into the box, we don’t
know whether the cat is alive or dead. In the Copenhagen in-
terpretation before we open the box, our cat is simultaneously
alive and dead since the state reads schematically

|cat) = a|cat dead) + b |cat alive) . (15.1)

However, there are lots of discussions about when the mea-
surement really happens. For example, one can argue that the
Geiger counter inside the box already performs the necessary
measurement and leads to the collapse of the wave function to
|cat) = |cat dead). So from this point of view, the collapse does
not happen when we open the box but already before that.

236 NO-NONSENSE QUANTUM MECHANICS

4It is worth noting that very re-
cently Nobel laureate Steven Wein-
berg stated in a New York Review
of Books essay titled "The Trouble
with Quantum Mechanics" that the
Copenhagen interpretation "is now
widely felt to be unacceptable."

5 For a very nice discussion along
similar lines including comments on
how all this came about historically
see

Carlo Rovelli. Space is blue and
birds fly through it. 2018. pot:
10.1098/rsta.2017.0312

Another currently popular interpretation is the so-called many-
worlds interpretation. Again, the goal is to make sense of the
wave function formalism. The basic idea is that the various pos-
sibilities encoded in the wave function are all real and realized
but not in the same world. For the cat example, this means that
as soon as the observer opens the box, the whole system splits
into two. In one we have the observer plus the cat alive and in
the other one the observer plus a dead cat. At the same time it
is impossible that the two newly created "worlds" interact with
each other. According to this interpretation, the wave function
never collapses. Instead, we have an incredibly large (maybe
infinite) number of alternative "worlds" which all correspond to
alternative histories and futures.

The Copenhagen interpretation is popular since it was the view
held by most of the founding fathers of quantum mechanics.‘.
The many-worlds interpretation is fun to think about. However,
an incredibly large number of parallel worlds seems like a huge
stretch to me. At least as long as there is no experimental hint
that at least one such parallel world exists.

Probably my biggest problem with these interpretations is that
they do not take the existence of alternative formulations of
quantum mechanics into account. They focus solely on the wave
function formulation. While wave functions are certainly an
extremely convenient tool, there is no need to believe that they
are something that exists outside of our description. Instead,
there are several hints that wave functions are not real physical
entities like, say, the electromagnetic field:>

> Probabilities (which we can measure) are only indirectly
related to any given wave function: P = |p|*. This means that
we can always multiply our wave function by any complex
number of unit length: » > e'? without changing anything
that we can measure

P=|p? =p > pre PelPy = p*y.

Any prediction will be the same no matter if we use ip or
ely, However, the wave function itself changes dramati-

WHAT DOES IT ALL MEAN? 237

cally through such a gauge transformation. This is known as
gauge invariance.

t> Wave functions are not objects in physical space but live in
abstract Hilbert spaces. So they are not physical entities in
the same sense as real waves that we observe in everyday life.

> Thirdly, there is the measurement problem’ that arises when —_ © Once more we would be better
we act as if the wave function is a real physical entity. Prior off by calling it the measurement

to our measurement of the location of the particle, the cor- puczle

responding wave function usually spreads out over a large

region of space. However, as soon as we measure the loca-

tion, the wave function is suddenly concentrated to a single

point. This is, of course, a non-problem if the wave function

is merely a mathematical tool.

The point to take away is nicely summarized by the following
story Felix Bloch told about a conversation he had with Werner
Heisenberg:

"We were on a walk and somehow began to talk about space. I had just
read Weyl’s book Space, Time and Matter, and under its influence was
proud to declare that space was simply the field of linear operations.
“Nonsense,” said Heisenberg, “space is blue and birds fly through it.”
This may sound naive, but I knew him well enough by that time to
fully understand the rebuke. What he meant was that it was dangerous
for a physicist to describe Nature in terms of idealised abstractions too

far removed from the evidence of actual observation."7 7 Felix Bloch. Heisenberg and the
early days of quantum mechanics.

Physics Today, December 1976
In other words, the main problem is that often physicists have a * % ”

tendency to identify theoretical constructs (like the wave func-
tion) of highly successful models with reality itself. Edwin
Jaynes coined the name mind projection fallacy for this phe-
nomenon:

"This oldest of all devices for dealing with one’s ignorance, is the first
form of what we have called the "Mind Projection Fallacy”. One as-
serts that the creations of his own imagination are real properties of
Nature, and thus in effect projects his own thoughts out onto Nature.
It is still rampant today, not only in fundamentalist religion, but in

238 NO-NONSENSE QUANTUM MECHANICS

SE. T. Jaynes. Probability Theory

as Logic, pages 1-16. Springer
Netherlands, Dordrecht, 1990. ISBN
978-94-009-0683-9

9Paul Schilpp. Albert Einstein,
philosopher-scientist. Open Court, La
Salle, Ill, 1970. ISBN 979-0875482865

70L. E. Ballentine. The statistical in-
terpretation of quantum mechanics.
Rev. Mod. Phys., 42:358-381, 1970.
DOI: 10.1103/RevModPhys.42.358

™ See, for example, Section 2.3 and
Section 2.4 in

James Sethna. Statistical mechanics:
entropy, order parameters, and com-
plexity. Oxford University Press,
Oxford New York, 2006. ISBN
9780198566779

every field where probability theory is used. [...] [I]n the Copenhagen
interpretation of quantum theory, whatever is left undetermined in

a pure state w is held to be unknown not only to us, but also to Na-
ture herself. That is, one claims that w represents a physically real
“propensity” to cause events in a statistical sense (a certain proportion
of times on the average over many repetitions of an experiment) but
denies the existence of physical causes for the individual events below
the level of p.”®

With that said, what further alternatives are there?

> The statistical interpretation. The whole idea is that the
rules of quantum mechanics only apply to ensembles of sim-
ilarly prepared systems and don’t make statements about
individual systems. To quote Albert Einstein: "The attempt to
conceive the quantum-theoretical description as the complete
description of the individual systems leads to unnatural the-
oretical interpretations, which become immediately unnec-
essary if one accepts the interpretation that the description
refers to ensembles of systems and not to individual sys-
tems."? To learn more about this interpretation, have a look
at "The statistical interpretation of quantum mechanics” by
Leslie Ballentine *°.

> The stochastic interpretation. The main assumption is that
the quantum rules follow since all our particles perform ran-
dom walks. This is motivated by the observation that the
Schrédinger equation is exactly the diffusion equation that
describes random walking particles, but with an imaginary
diffusion constant™’. A famous example of random walking
particles are pollen grains in water. Their seemingly ran-
dom behavior is a result of the permanent collisions of the
pollen grains with individual water molecules. Since the
water molecules are too small to be seen with an ordinary
microscope, the pollen grains seem to move randomly.

The key idea is that something similar explains the quantum
behavior of elementary particles. Similarly to what happens

in the water and pollen grain example, the strange behav-

ior of quantum systems could then be explained once we
have better "microscopes" which can reveal the cause for
their apparent random motion. One proposal is that vacuum
fluctuations and the constant interaction of all particles with
them are causing the random walks. To learn more about this
approach, have a look at the "Review of stochastic mechanics"
by Edward Nelson.*”

These interpretations have the advantage that they are not
specifically related to one particular formulation of quantum
mechanics. There are dozens of other proposed interpretations.
And as already mentioned above there is no way that we can
discuss them all. But if you want to learn more about alternative
interpretations, there are lots of textbooks to choose from. Here
are some good ones:

> Conceptual Foundations of Quantum Mechanics by Bernard
D’Espagnat 73.

> The Interpretation of Quantum Mechanics by Roland
Omnes“4.

> Elegance and Enigma - The Quantum Interviews by Maxim-
ilian Schlosshauer’>.

> Foundations of Quantum Mechanics: An Exploration of the

Physical Meaning of Quantum Theory by Travis Norsen’®

Two final comments before we move on.

If you feel the urge to join the discussion about what quantum
mechanics means, please do it. We need more smart people
with an adequate physical and mathematical background that
think deeply about such fundamental issues’.

In addition, if you want to start thinking about interpretations
seriously, you should know which often-heard statements about

WHAT DOES IT ALL MEAN? 239

Edward Nelson. Review of
stochastic mechanics. Journal of
Physics: Conference Series, 361(1):
012011, 2012. URL http://stacks.
iop.org/1742-6596/361/i=1/a=
612011

3 Bernard d’Espagnat. Conceptual
foundations of quantum mechanics.
Advanced Book Program, Perseus
Books, Reading, Mass, 1999. ISBN
978-0738201047

Roland Omnes. The interpretation
of quantum mechanics. Princeton
University Press, Princeton, N.J,
1994. ISBN 978-0691036694

*5 Maximilian Schlosshauer. Elegance
and enigma : the quantum interviews.
Springer, New York, 2011. ISBN
978-3642208799

6 Travis Norsen. Foundations of
quantum mechanics : an exploration

of the physical meaning of quantum
theory. Springer, Cham, Switzerland,
2017. ISBN 978-3319658667

"7 Often (young) researchers are
actively discouraged to spend

time on such problems since many
consider it a waste of time. For a
nice essay on this topic, see "Shut
up and let me think. Or why you
should work on the foundations of
quantum mechanics as much as you
please" by Pablo Echenique-Robba;
https://arxiv.org/abs/1308.5619

240 NO-NONSENSE QUANTUM MECHANICS

quantum mechanics are true and which are not. There are too
many myths that are routinely told to students. A good starting
point is

*8 Hrvoje Nikolic. Quantum me- > Quantum mechanics: Myths and facts by Hrvoje Nikolic’®.
chanics: Myths and facts. Found.

Phys., 37:1563-1611, 2007. DOI:

10.1007/S10701-007-9176-y

16

Get an Understanding of Quan-
tum Mechanics You Can Be
Proud Of

As I already warned you in the preface, the content of this book
is far from comprehensive. There are hundreds of different
aspects of quantum mechanics that I didn’t even say a word
about. Quantum mechanics is almost a century old now. Thou-
sands of people have worked on it. And unsurprisingly, no
single book can capture it all.

However, there are lots of excellent books that cover various
special aspects extremely well. There’s no need for you to read
hundreds of books on quantum mechanics - just the best. Since
for every good book there are at least 20 bad ones which are not
worth your time, below I recommend some of my favorites. So,

start by picking the ones that interest you most, and dig in’. ‘If you need further or more spe-
cialized reading recommendations,
. . . . you should visit:
Two highly recommended books which are written in the same www. physicstravelguide.com
physics-first spirit as the book you are currently reading are This is an expository physics wiki

where anyone can help to collect
the best resources on any physics
topic + publish student-friendly
explanations.

242 NO-NONSENSE QUANTUM MECHANICS

? Richard Feynman. The Feynman
lectures on physics. Basic Books,
a member of the Perseus Books
Group, New York, 2011. ISBN

978-0465025015

3 David Griffiths. Introduction to
quantum mechanics. Pearson Prentice
Hall, Upper Saddle River, NJ, 2005.
ISBN 9780131118928

4V. M. Galitski. Exploring quantum
mechanics : a collection of 700+ solved
problems for students, lecturers, and
researchers. Oxford University Press,
Oxford, 2013. ISBN 9780199232727

5 Yoav Peleg. Quantum mechanics
: based on Schaum's outline of theory
and problems of quantum mechanics.
McGraw-Hill, New York, 2006.
ISBN 9780071455336

® Bernd Thaller. Visual quantum
mechanics : selected topics with
computer-generated animations of
quantum-mechanical phenomena.
Springer /TELOS, New York, 2000.

ISBN 9780387989297

7Siegmund Brandt. The picture book
of quantum mechanics. Springer, New
York, NY, 2012. ISBN 9781461439509

8 Asher Peres. Quantum theory
: concepts and methods. Kluwer
Academic, Dordrecht Boston, 1993.

ISBN 978-0-7923-2549-9

9 Leslie Ballentine. Quantum mechan-
ics : a modern development. World
Scientific, Singapore River Edge, NJ,
2000. ISBN 9789810241056

> Lectures on Physics Volume 3 by Richard Feynman?.

> Quantum Mechanics by David J. Griffiths3.

To get more experience with the quantum framework the fol-
lowing two problem books are extremely useful. They contain
not only hundreds of problems but also the corresponding solu-
tions.

> Exploring Quantum Mechanics: A Collection of 700+
Solved Problems for Students, Lecturers, and Researchers
by Victor Galitski, Boris Karnakov, Vladimir Kogan, Victor
Galitski Jr‘.

> Schaum’s Outline of Quantum Mechanics by Yoav Peleg,
Reuven Pnini, Elyahu Zaarur, Eugene Hecht>. The book is
freely available online; google it!

To get a better visual understanding of how wave functions
behave in various systems the following two books are great:

> Visual Quantum Mechanics by Bernd Thaller®.

> The Picture Book of Quantum Mechanics by Siegmund
Brandt and Hans Dieter Dahmen/.

If you’re interested in formal and advanced aspects of quantum
mechanics the best starting points are

> Quantum Theory: Concepts and Methods by Asher Peres®.

> Quantum Mechanics: A Modern Development by Leslie E.
Ballentine?.

To understand quantum mechanics in more rigorous terms

GET AN UNDERSTANDING OF QUANTUM MECHANICS YOU CAN BE PROUD OF 243

and learn more about related mathematical topics, you should
consult the following three books

> Quantum Theory for Mathematicians by Brian Hall*®. A
free version is available online.

> Quantum Theory, Groups and Representations by Peter
Woit"?. You can download a free version from Peter Woit’s
website (www.math. columbia. edu/~woit).

> An Introduction to the Mathematical Structure of Quantum
Mechanics by Franco Strocchi’.

In addition, to get a feeling for why mathematical rigor can
be extremely useful in quantum mechanics I recommend the
following paper

[> Mathematical surprises and Dirac’s formalism in quantum
mechanics by Francois Gieres’.

Finally, there are lots of other good books you should consult
whenever you are stuck and confused about something. In

such a situation the only way forward is usually to read what
different authors have to say about it. Luckily there are dozens
of textbooks that cover the standard topics. The following books
are all somewhat popular and ideally suited to find a second or
third explanation:

> Modern Quantum Mechanics by Jun John Sakurai“.

> The Principles of Quantum Mechanics by Paul Dirac’.

© Brian Hall. Quantum theory for
mathematicians. Springer, New York,
2013. ISBN 9781489993625

™ Peter Woit. Quantum theory, groups
and representations : an introduction.
Springer, Cham, Switzerland, 2017.
ISBN 9783319646107

*F Strocchi. An introduction to the
mathematical structure of quantum me-
chanics : a short course for mathemati-
cians. World Scientific, Hackensack,
NJ, 2008. ISBN 9789812835222

3 F Gieres. Dirac’s formalism and
mathematical surprises in quantum
mechanics. Rept. Prog. Phys., 63:
1893, 2000. DOI: 10.1088/0034-
4885 /63/12/201

“4 J.J. Sakurai. Modern quantum
mechanics. Pearson India Education
Services, Noida, India, 2014. ISBN
9789332519008

%*P. A.M. Dirac. The principles

of quantum mechanics. Clarendon
Press, Oxford England, 1981. ISBN
9780198520115

244 NO-NONSENSE QUANTUM MECHANICS

16 Albert Messiah. Quantum mechan-
ics. North-Holland, Amsterdam,
1965. ISBN 9780471597667

*7 Ravi Shankar. Principles of Quan-
tum Mechanics. Springer Verlag,
City, 2014. ISBN 9781461576754

8 Claude Tannoudji. Quantum
mechanics. Wiley, New York, 1977.
ISBN 9780471164333

9 Robert Klauber. Student friendly
quantum field theory : basic princi-
ples and quantum electrodynamics.
Sandtrove Press, Fairfield, Iowa,
2014. ISBN 9780984513956

2° Jakob Schwichtenberg. Physics
from Symmetry. Springer, Cham,
Switzerland, 2018. ISBN 978-
3319666303

> Quantum Mechanics by Albert Messiah’®.
> Principles of Quantum Mechanics by Ramamurti Shankar’.

> Quantum Mechanics by Claude Cohen-Tannoudji, Bernard
Diu und Franck Laloé*®.

The logical next step in the hierarchy of theories after quantum
mechanics is quantum field theory. Quantum field theory is
what we end up with if we combine the lessons of quantum
mechanics with those of Einstein’s theory of special relativity.

The absolute best book to get started is

> Student Friendly Quantum Field Theory by Robert D.
Klauber’?.

In addition, at this stage, you might also enjoy my other book

> Physics from Symmetry”®. In this book I argue that the
equations used in quantum field theory and all other funda-
mental theories of modern physics can be understood most
easily from a symmetry perspective.

One Last Thing

It’s impossible to overstate how important reviews are for an
author. Most book sales, at least for books without a marketing
budget, come from people who find books through the recom-
mendations on Amazon. Your review helps Amazon figure out
what types of people would like my book and makes sure it’s
shown in the recommended products.

I’d never ask anyone to rate my book higher than they think it
deserves, but if you like my book, please take the time to write
a short review and rate it on Amazon. This is the biggest thing
you can do to support me as a writer.

Each review has an impact on how many people will read my
book and, of course, I’m always happy to learn about what
people think about my writing.

PS: If you write a review, I would appreciate a short email with
a link to it or a screenshot to Jakobschwich@gmail.com. This
helps me to take note of new reviews. And, of course, feel free
to add any comments or feedback that you don’t want to share
publicly.

Part IV
Appendices

A

Taylor Expansion

The Taylor expansion is one of the most useful mathematical
tools and we need it in physics all the time to simplify compli-
cated systems and equations.

We can understand the basic idea as follows:

Imagine you sit in your car and ask yourself what your exact
location I(t) will be in 10 minutes: I(t9 + 10 minutes) =?

> A first guess is that your location will be exactly your current
location
I(t9 +10 minutes) ~ I(tg).

1 Here 0; is a shorthand notation
Given how large the universe is and thus how many possible for 2 and d;I(t) yields the velocity
(rate of change). After taking
the derivative, we evaluate the

> If you want to do a bit better than that, you can also include rely function I(t) = oyl(t) at to:
your current velocity I(to) = ael(t)|,.* The total distance (to) = al(#)|,,.
you will travel in 10 minutes if you continue to move at your

locations there are, this is certainly not too bad.

current velocity is this velocity times 10 minutes: I(t) x
10 minutes . Therefore, your second estimate is your current
location plus the velocity you are traveling times 10 minutes

I(to +10 minutes) © I(to) +1(to) x 10 minutes.  (A.1)

250 NO-NONSENSE QUANTUM MECHANICS

? The factor 4 and that we need to
square the 10 minutes follows since,
to get from an acceleration to a
location, we have to integrate twice:

[at { atz(0) =
[ ax(to)t =
5e(to)?

where x(f9) is the value of the
acceleration at t = to (= a constant).

3 Here the superscript n denotes
the n-th derivative. For example
f = f and fO is df.

> If you want to get an even better estimate you need to take
into account that your velocity can possibly change. The rate
of change of the velocity (to) = 9?1(t)| fy 18 What we call
acceleration. So in this third step you additionally take your
current acceleration into account?

I(t9 +10 minutes) ~ I(tg) + 1(to) x 10 minutes

+ sl(to) x (10 minutes)?.

> Our estimate will still not yield the perfect final location
since, additionally, we need to take into account that our
acceleration could change during the 10 minutes. We could
therefore additionally take the current rate of change of our
acceleration into account.

This game never ends and the only limiting factor is how pre-
cisely we want to estimate our future location. For many real-
world purposes, our first order approximation (Eq. A.1) would
already be perfectly sufficient.

The procedure described above is exactly the motivation behind
the Taylor expansion. In general, we want to estimate the value
of some function f(x) at some value of x by using our knowl-
edge of the function’s value at some fixed point a. The Taylor
series then reads?

oo ¢(n) (gq _)\n
jee) = § tote)

— fO)(x=a)? . fM(a)(x—-a)! | fA) (a)(x-a)?

— 0! + 1! + 2!

f (a)(x — a)
3!

where f(a) is the value of the function at the point a we are ex-

+ to. (A.2)

panding around. Moreover, x — a is analogous to the 10 minute
timespan we considered above. If we want to know the location
at x = 5:10 pm by using our knowledge at a = 5:00 pm, we
get x — a = 5:10 pm — 5:00 pm = 10 minutes. Therefore, this
equation is completely analogous to our estimate of the future
location we considered previously.

TAYLOR EXPANSION 251

To understand the Taylor expansion a bit better, it is helpful to
look at concrete examples. ex

We start with one of the simplest but most important examples:
the exponential function. Putting f(x) = e* into Eq. A.2 yields

= SOM"

{
na0 nN

The crucial puzzle pieces that we need are therefore (e*)’ = e*

and e? = 1. Putting this into the general formula (Eq. A.2)

yields

Se e%(x-O)" Sx”

v=) ce ) =) (A.3)
n=0 . n=0 “*

This result can be used as a definition of e*.

Next, let’s assume that the function we want to approximate
is sin(x) and we want to expand it around x = 0. Putting
f(x) = sin(x) into Eq. A.2 yields

©, sin(")(0)(x — 0)"

n=0

The crucial information we therefore need is (sin(x))’ = cos(x),
(cos(x))’ = —sin(x), cos(0) = 1 and sin(0) = 0. Because
sin(0) = 0, every term with even n vanishes, which we can use
if we split the sum. Observe that

oo oo foe]

Yi n= )o(2n+1)+ )o (2n)

n=0 n=0 n=0

1424+34+44+5+6...=1434+5+... +424+4+6+...
(A.4)
Therefore, splitting the sum into even and odd terms yields
0 gin (2n+1) (0) (x _ 0)2"+1

ar (2n +1)!

2, sin(2") (0) (x — 0)?"
th (2n)!

sin(x) =

n=0

sin (2"+1) (0) (x _ 0)2n+1
(2n +1)!

> sin(0) =0
(A.5)

II
=
ite

252 NO-NONSENSE QUANTUM MECHANICS

We used here that every even derivative of sin(x) (ie., sin@”))
is again sin(x) or — sin(x). Therefore the second term vanishes
since sin(0) = 0. The remaining terms are odd derivatives of
sin(x), which are all proportional to cos(x). We now use

sin(x)) = cos(x)

sin(x)®) = cos’(x) = —sin(x)
sin(x)°) = — sin’(x) = —cos(x)
sin(x)4) = — cos!(x) = sin(x)
sin(x)©) = sin’(x) = cos(x)

The general pattern is
sin "+0 (x) = (—1)" cos(x) (A.6)

as you can check by putting some integer values for n into the
4sin™ (x) = sin? (x) = formula‘.
(—1)° cos(x) = cos(x), sin®) (x) =
sin 141) (x) = (—1)! cos(x) =

—~cos(x) Thus, we can rewrite Eq. A.5 as
00 sin(2"+1) (0) (x _ 0)2"+1
> Eq. A6
Yd _ y" (—1)" cos(0)(x — 0)2"+1

eS (2n +1)!
> cos(0) =1

_ » (=1)"(x)"tt 1)"(x )en+1 (A 7)

~ (2n+1)- :

This is the Taylor expansion of sin(x), which we can also use as
a definition of the sine function.


B

Fourier Transform

“One can Fourier transform anything - often meaningfully.” - John
Tukey

What the Fourier transform does to a function is basically the
same that a prism does to sunlight:

When white sunlight enters a prism we get a rainbow full of
colored light’. In this sense the white sunlight consists of all
this colored light and what the prism does is to reveal these

basic constituents.

Now it’s not sunlight that enters the Fourier transform, but a
function. However, the result is basically the same:

* This is a result of the fact that
light of different wavelengths get
diffracted differently.

254 NO-NONSENSE QUANTUM MECHANICS

—7

Analogous to a prism the Fourier transform breaks the incom-
ing function into its basic constituents. The pieces that we get as
the result of a Fourier transform are periodic functions (cosines,
sines) with different frequencies. The Fourier transform tells us
how much of each basic building block is needed to build the
original function.

Formulated a bit differently, the basic idea of the Fourier trans-
form is analogous to the idea that we can express any vector 7
in terms of basis vectors ( @1, @2, @3). The most common choice
for these basis vectors are

1 0
é:=|]0], @&=]1], &=|0 (B.1)
0 1

We can write any three-dimensional vector @ in terms of these
basis vectors:

al
U= | vo | = 018, + 0222 + 0323
03
> Egq.B1
1 0 0
=0,;)/0]/4+02]1] +273] 0
0 0 1

Now we do the same thing for real functions. We have in-
finitely many basis functions: sin(kx) and cos(kx), where k is
any real number. Using this basis we can write every periodic
function f(x) as

fo]

f(x) = Yo (ag cos(kx) + by sin(kx)) (B.2)
k=0

with constant coefficients a, and by.

For complex functions we use the basis e!** and e~*** and use
an integral instead of a sum?.
f(x) = [ * ak (aye + de®), (B.3)
which we can rewrite as?
fx) = [ akfe™, (B.4)

Now the expansion coefficients f; are usually denoted by f(k)
and called the Fourier transform of f(x). It’s also possible to
invert the whole procedure:*

iW == [- axfoe™, Bs)

In physical terms we can understand the Fourier expansion as a
basis change from the position basis x to the momentum basis k.

FOURIER TRANSFORM 255

? Recall that an integral is, in some
sense, a finely grained sum.

3 Take note that now our integral
goes from —oo to ov.

4 The factor 271 is a normalization
factor that makes sure that if we
combine the Fourier expansion
formula and the inverse formula we
really end up with the function we
started with.

C

Delta Distribution

The easiest way to understand the delta distribution’ (or Dirac
delta) is to recall a simpler but analogous mathematical object:
the Kronecker delta Oi, which is defined as follows:

1 ifi=j

C.
0 ifi Fj Cx)

Oi =

In matrix form, the Kronecker delta is simply the unit matrix?.
The Kronecker delta 5; is useful because it allows us to pick one
specific term of any sum. For example, let’s consider the sum

3
ajb; = a,b; + anb; + a3b; (C.3)
i=1

and let’s say we want to extract only the second term. We can
do this by multiplying the sum by the Kronecker delta 65;:

3
Ye baia;b; = 621 ab; + 622 aobj + 693 agb; = azbj. (C.4)

In general, we have

3
- bind; = azbj. (C.5)
i=1

* The delta distribution is not really
a function in the strict mathematical
sense and therefore a new word was
invented: distributions.

? For example, in two-dimensions

1ox2) = (( 4) . (C.2)

258 NO-NONSENSE QUANTUM MECHANICS

The delta distribution 5(x — y) is a generalization of this idea
for integrals instead of sums. So in particular, this means that

we can use the delta distribution to extract specific terms from
any given integral:

[axf(x)ox-y) = F). (C6)

In words, this means that the delta distribution allows us to
extract exactly one term - the term for which x = y - from the
infinitely many terms that we mean by the integral sign. For
example,

| @f(x)5(x -2) = f(2).

Now, one example where the Kronecker delta appears is

Ox;
x = bj. (C.7)
Ox; 4

The derivative of 0xx = 1, whereas 0xy = 0 and 0xz = 0.

Completely analogously, the delta distribution appears as fol-
lows:

Of(Xi) og
af(x;) = 6(x; — x)). (C.8)

The delta distribution is also often introduced by the following
definition
_ jo ifx=y,
5(x o-{5 ifxéy ' (C.9)

which is somewhat analogous to the definition of the Kronecker
delta in Eq. C.1. Moreover, when we use a constant function in
Eq. C.6, for example, f(x) = 1 we get the following remarkable
equation

[arto —y)=1. (C.10)

Eq. C.6 tells us that if we have the delta distribution 6(x — y)
together with a function under an integral, the result is the
value of the function at y = x. In Eq. C.10, we have a constant
function and its value at y = x is simply 1.

In words, these properties mean that the delta distribution is an
infinitely thin (only non-zero at y = x) but also infinitely high
function that yields exactly one if we integrate it all over space.

This is also why the delta distribution is so important in quan-
tum mechanics. In quantum mechanics, we describe particles
using wave packets and the delta distribution is like an in-
finitely thin wave packet. In physical terms this means that the
delta distribution describes a particle that is localized at exactly
one point without any uncertainty. However, at the same time
the momentum uncertainty is infinite. This comes about since
we can understand the delta distribution as a infinite sum of all
possible plane waves}. Each plane wave corresponds to exactly
one specific momentum value. Since we need all possible plane
waves, the delta distribution is a superposition of all possible
momentum values:
6(x—y) = = / * eilx—Dkag (C.11)

y 27 J—co , .
This is known as the integral representation of the delta distri-
bution.

This can be motivated by putting the formula for the inverse
Fourier transformation (Eq. B.5)

Fk) = — [. dxf (x)el**, (C.12)

—Co

into the normal Fourier expansion formula (Eq. B.4):

f(x) = [ake

_ [@ Vf? ery ike! \ (ike
= [a(S [af ye""* Je

= [Pae' ([et)

—co 27

> Eq.C.12

Now compare this with the defining equation (Eq. C.6) which I
recite here for convenience4

f(x) = [ dx! f(x!)o(2" — 2). (C3)

If we identify the last objects in these equations, we end up with
the integral representation of the delta distribution (Eq. C.11).

DELTA DISTRIBUTION 259

3 A plane wave looks mathemati-
cally like this: e'**.

41 changed the notation x — x’ and
y — x to make the analogy clearer.

Bibliography

J. E. Baggott. The quantum story : a history in 40 moments. Ox-
ford University Press, Oxford England New York, 2011. ISBN
978-0199566846.

L. E. Ballentine. The statistical interpretation of quan-
tum mechanics. Rev. Mod. Phys., 42:358-381, 1970. DOI:
10.1103 /RevModPhys.42.358.

Leslie Ballentine. Quantum mechanics : a modern development.
World Scientific, Singapore River Edge, NJ, 2000. ISBN
9789810241056.

Adam Becker. What is real? : the unfinished quest for the meaning
of quantum physics. Basic Books, New York, NY, 2018. ISBN
978-0465096053.

Felix Bloch. Heisenberg and the early days of quantum me-
chanics. Physics Today, December 1976.

David Bohm. Quantum theory. Dover Publications, New York,
1989. ISBN 978-0486659695.

Siegmund Brandt. The picture book of quantum mechanics.
Springer, New York, NY, 2012. ISBN 9781461439509.

Bernard d’Espagnat. Conceptual foundations of quantum mechan-
ics. Advanced Book Program, Perseus Books, Reading, Mass,
1999. ISBN 978-0738201047.

P. A. M. Dirac. The principles of quantum mechanics. Clarendon
Press, Oxford England, 1981. ISBN 9780198520115.

262 NO-NONSENSE QUANTUM MECHANICS

Richard Feynman. Quantum mechanics and path integrals. Dover
Publications, Mineola, N.Y, 2010. ISBN 978-0486477220.

Richard Feynman. The Feynman lectures on physics. Basic Books,
a member of the Perseus Books Group, New York, 2011. ISBN
978-0465025015.

Richard Feynman. QED : the strange theory of light and matter.
Princeton University Press, Princeton, NJ, 2014. ISBN 978-
0691164090.

Christopher A. Fuchs and Asher Peres. Quantum theory needs
no ‘interpretation’. Physics Today, 53(3):70-71, March 2000. Dot:
10.1063 / 1.883004.

V. M. Galitski. Exploring quantum mechanics : a collection of 700+
solved problems for students, lecturers, and researchers. Oxford
University Press, Oxford, 2013. ISBN 9780199232727.

F. Gieres. Dirac’s formalism and mathematical surprises in
quantum mechanics. Rept. Prog. Phys., 63:1893, 2000. DOI:
10.1088 /0034-4885 /63/12/201.

David Griffiths. Introduction to quantum mechanics. Pear-
son Prentice Hall, Upper Saddle River, NJ, 2005. ISBN
9780131118928.

Brian Hall. Quantum theory for mathematicians. Springer, New
York, 2013. ISBN 9781489993625.

Peter Holland. The quantum theory of motion : an account of
the de Broglie-Bohm causal interpretation of quantum mechanics.
Cambridge University Press, Cambridge England New York,
NY, 1995. ISBN 978-0521485432.

E. T. Jaynes. Probability Theory as Logic, pages 1-16. Springer
Netherlands, Dordrecht, 1990. ISBN 978-94-009-0683-9.

Robert Klauber. Student friendly quantum field theory : basic prin-
ciples and quantum electrodynamics. Sandtrove Press, Fairfield,
Iowa, 2014. ISBN 9780984513956.

Sanjoy Mahajan. The art of insight in science and engineering
: mastering complexity. The MIT Press, Cambridge, Mas-
sachusetts, 2014. ISBN 978-0262526548.

BIBLIOGRAPHY

Albert Messiah. Quantum mechanics. North-Holland, Amster-
dam, 1965. ISBN 9780471597667.

J. E. Moyal. Quantum mechanics as a statistical the-
ory. Proc. Cambridge Phil. Soc., 45:99-124, 1949. DOT:
10.1017/50305004100000487.

Edward Nelson. Review of stochastic mechanics. Journal
of Physics: Conference Series, 361(1):012011, 2012. URL http:
//stacks.iop.org/1742-6596/361/i=1/a=012011.

Hrvoje Nikolic. Quantum mechanics: Myths and facts. Found.
Phys., 37:1563-1611, 2007. DOI: 10.1007/810701-007-9176-y.

Travis Norsen. Foundations of quantum mechanics : an exploration
of the physical meaning of quantum theory. Springer, Cham,
Switzerland, 2017. ISBN 978-3319658667.

Roland Omnes. The interpretation of quantum mechanics.
Princeton University Press, Princeton, N.J, 1994. ISBN 978-
0691036694.

Yoav Peleg. Quantum mechanics : based on Schaum’s outline of
theory and problems of quantum mechanics. McGraw-Hill, New
York, 2006. ISBN 9780071455336.

Roger Penrose. The emperor’s new mind : concerning computers,
minds and the laws of physics. Oxford University Press, Oxford,
2016. ISBN 9780198784920.

Asher Peres. Quantum theory : concepts and methods. Kluwer
Academic, Dordrecht Boston, 1993. ISBN 978-0-7923-2549-9.

Carlo Rovelli. Space is blue and birds fly through it. 2018. Dot:
10.1098 /rsta.2017.0312.

J. J. Sakurai. Modern quantum mechanics. Pearson India Educa-
tion Services, Noida, India, 2014. ISBN 9789332519008.

Paul Schilpp. Albert Einstein, philosopher-scientist. Open Court,
La Salle, Ill, 1970. ISBN 979-0875482865.

Maximilian Schlosshauer. Elegance and enigma : the quantum
interviews. Springer, New York, 2011. ISBN 978-3642208799.

263

264 NO-NONSENSE QUANTUM MECHANICS

Jakob Schwichtenberg. Physics from Symmetry. Springer, Cham,
Switzerland, 2018. ISBN 978-3319666303.

Jakob Schwichtenberg. No-Nonsense Classical Mechanics : a
student-friendly introduction. No-Nonsense Books, Karlsruhe,
Germany, 2019. ISBN 9781096195382.

James Sethna. Statistical mechanics: entropy, order parameters, and
complexity. Oxford University Press, Oxford New York, 2006.
ISBN 9780198566779.

Ravi Shankar. Principles of Quantum Mechanics. Springer Verlag,
City, 2014. ISBN 9781461576754.

F Strocchi. An introduction to the mathematical structure of quan-
tum mechanics : a short course for mathematicians. World Scien-
tific, Hackensack, N.J, 2008. ISBN 9789812835222.

Claude Tannoudji. Quantum mechanics. Wiley, New York, 1977.
ISBN 9780471164333.

Bernd Thaller. Visual quantum mechanics : selected topics with
computer-generated animations of quantum-mechanical phenomena.
Springer/TELOS, New York, 2000. ISBN 9780387989297.

Peter Woit. Quantum theory, groups and representations : an
introduction. Springer, Cham, Switzerland, 2017. ISBN
9783319646107.

Cosmas Zachos. Quantum mechanics in phase space. World
Scientific, New Jersey London, 2005. ISBN 9812383840.

A Zee. Quantum field theory in a nutshell. Princeton University
Press, Princeton, N.J, 2010. ISBN 9780691140346.

Index

Angular Momentum, 84
Algebra, 84
Commutation Relation, 84
Operator, 84

Angular Momentum Algebra, 84

Basis Change, 61
Basis Expansion, 57
Born Approximation, 178

Canonical Commutation Relation,
75

Classical Limit, 95, 215

Classical Path, 215

Clebsch-Gordan Coefficients, 162

Commutator, 74

Configuration Space, 188

Constructive Interference, 218

Continuity Equation, 223

Destructive Interference, 218
Double Slit Experiment
Path Integral Description, 205
Pilot Wave Description, 202
Double-Slit Experiment, 33

Ehrenfest’s theorem, 96
Eigenvalue, 82
Eigenvector, 82

Energy Operator, 71, 72
Euler’s Formula, 212
Expectation Value, 51

Expectation Value Quantum Me-
chanics, 58

Fermi’s Golden Rule, 178
Fourier Transform, 253

Gaussian Wave Packet, 81
Generator, 71
Group Theory, 68

Hamilton Operator, 77

Hamiltonian Formulation, 196

Harmonic Oscillator, 141
Algebraic Method, 144
Driven, 167

Heisenberg Mechanics, 229

Hilbert Space, 195

Hydrogen Atom, 127

Interpretations of Quantum Me-
chanics, 233
Copenhagen, 235
Many Worlds, 236
Statistical, 238
Stochastic, 238

Ket, 47
Koopman-von-Neumann Formu-
lation, 196

Ladder Operators, 144
Lagrangian Formulation, 196

266 NO-NONSENSE QUANTUM MECHANICS

Liouville’s Equation, 222

Mathematical Arenas, 187
Momentum Operator, 71, 72
Moyal Bracket, 228

Newtonian Formulation, 196
Noether’s Theorem, 66

Partial Wave Analysis, 178
Particle
Box Scattering, 131
Finite Box, 121
Free, 79
Infinite Box, 115
Perturbations, 176
Spherical Potential, 164
Three Dimensional Box, 164
Path Integral, 209
Path Integral Formulation, 196,
204, 231
Pauli Matrices, 86
Perturbation Theory, 170
Degenerate, 177
General, 171
Time-Dependent, 177
Phase Space, 193
Filamentation, 226
Flow, 220
Compressible, 225
Incompressible, 224
Phase Space Formulation, 196,
219, 231
Physical Space, 187
Pilot-Wave Formulation, 196, 199,
231
Plank Constant, 72
Poisson Bracket, 221
Origin, 228
Probability Density, 221

Explicit, 223
Product Space, 189

Quantum Numbers, 91
Quantum Operators, 66
Quantum Pendulum, 166
Quantum Potential, 202
Quantum Tunneling, 124
Quantum Waves, 79

Scattering Amplitude, 178
Schrédinger Equation
Classification of Solutions, 111
Stationary, 109
Time-Independent, 109
Schrédinger equation, 77
Schrédinger’s Cat, 234
Spin, 85, 153
Addition, 161
Algebra, 90
Commutation Relation, 89
Measurements, 155
State Vector, 47
States, 47
Statistical Tools, 54
Stern-Gerlach Experiment, 88, 155
Superposition, 80
Symmetries, 67

Taylor Expansion, 249
Time Evolution, 75
Time Evolution Operator, 78

Uncertainty, 43

Wave Function, 60

Wave Function Formulation, 196,
231

WKB Method, 181